人工智能;;卡斯帕罗夫：围棋，你的时间不多了象棋大师Garry Kasparov 因20年前败给超级计算机深蓝而备受瞩目，最近他对即将到来的围棋人机大战进行了一番点评。我分别于1996年和1997年两次对战象棋超级计算机深蓝，这两次对战被称为「人类大脑的最后一战」，从月球登陆到终结者电影，对战被与一切事情进行比较。第一次是我赢得了比赛，当然更出名的是，一年后我输掉了复赛，那时，IBM关闭了这个项目。&nbsp;每次有类似挑战上头条时，我的新闻和社交媒体上的艾特就会井喷。&nbsp;最近突然同时发生的一连串事件原因在于谷歌支持的人工智能AlphaGo与韩国围棋冠军李世石的比赛，此前AlphaGo刚刚以5:0的成绩战胜欧洲冠军樊麾。我不会下这种古老的中国围棋游戏，所以并没有资格预测比赛结果，但是，我的确知道结果可能取决于什么因素，以及围棋会拥有怎样的未来。&nbsp;计算机擅长完美计算，我们的大脑则擅长通用的（generalities）、长期计划，将通用主题适用于新情况。当人类和机器势均力敌时，这种对比让人类和机器对弈变得有趣起来，就像20年前的象棋，当然，也像今天的围棋一样。&nbsp;早期象棋机器会有盲点和可加利用的弱点，而且吸引棋手的是将（利用）这些（弱点）作为目标，而不是正儿八经对弈。对战深蓝时，我就没有抵挡住这一诱惑。心智（Mind）运动，比如象棋和围棋，需要高度集中的精神，当你的注意力被试图对计算机耍花招打乱时，最终就是诱惑自己下出客观上并不可靠的棋招。随着机器变得强大，这些做法会受到惩罚。&nbsp;但是，肉体和硅之间的关键差异就在于平凡机器有着不间断地保持前后一致的优势。计算机不会犯下大错，至少在象棋中不会，而人类则失之毫厘谬以千里。机器也不会苦于骄傲自满、焦虑和筋疲力尽。1997年当我与深蓝对战输掉了决定性的第六场比赛时，压力非常大，而且下棋也是这种状态。这是我职业生涯中最糟糕的一场对弈。&nbsp;尽管如此，那是一个激动的时刻，对机械掌握这门游戏的兴趣巅峰，可以追溯到18世纪骗人的象棋机器Turk（Mechanical Turk，是中世纪的一件震动欧洲的发明。一位发明家号称发明了一种具有人类智能的机器人，能够跟人下国际象棋，并且真的带着这个机器人横扫欧洲的各位象棋大师。一位不信邪的国外下令拆掉这台机器，结果发现里头真的藏着一个土耳其象棋大师。于是这台机器，或者说这位土耳其人 Turk，就被称为Mechanical Turk。——译者）。今天，AlphaGo代表了一个有着真正人工智能应用的机器学习项目，值得广泛关注。&nbsp;李世石可能比AlphaGo强很多，以致于人类出错可能性还不具有决定性。围棋的每一轮都比象棋有多得多的可能走法而且动态程度也存在差异，这两个因素都不利于机器获胜。但是，我恐怕看到了不祥之兆（the writing is on the wall）。如今，一台相当好的笔记本上运行的免费象棋程序都能战胜深蓝和任何人类大师。象棋机器从可预测、薄弱的状态到强大得可怕，这样飞跃只花了十几年。&nbsp;&nbsp;围棋，你的时间不多了。
围棋;;卡斯帕罗夫：围棋，你的时间不多了象棋大师Garry Kasparov 因20年前败给超级计算机深蓝而备受瞩目，最近他对即将到来的围棋人机大战进行了一番点评。我分别于1996年和1997年两次对战象棋超级计算机深蓝，这两次对战被称为「人类大脑的最后一战」，从月球登陆到终结者电影，对战被与一切事情进行比较。第一次是我赢得了比赛，当然更出名的是，一年后我输掉了复赛，那时，IBM关闭了这个项目。&nbsp;每次有类似挑战上头条时，我的新闻和社交媒体上的艾特就会井喷。&nbsp;最近突然同时发生的一连串事件原因在于谷歌支持的人工智能AlphaGo与韩国围棋冠军李世石的比赛，此前AlphaGo刚刚以5:0的成绩战胜欧洲冠军樊麾。我不会下这种古老的中国围棋游戏，所以并没有资格预测比赛结果，但是，我的确知道结果可能取决于什么因素，以及围棋会拥有怎样的未来。&nbsp;计算机擅长完美计算，我们的大脑则擅长通用的（generalities）、长期计划，将通用主题适用于新情况。当人类和机器势均力敌时，这种对比让人类和机器对弈变得有趣起来，就像20年前的象棋，当然，也像今天的围棋一样。&nbsp;早期象棋机器会有盲点和可加利用的弱点，而且吸引棋手的是将（利用）这些（弱点）作为目标，而不是正儿八经对弈。对战深蓝时，我就没有抵挡住这一诱惑。心智（Mind）运动，比如象棋和围棋，需要高度集中的精神，当你的注意力被试图对计算机耍花招打乱时，最终就是诱惑自己下出客观上并不可靠的棋招。随着机器变得强大，这些做法会受到惩罚。&nbsp;但是，肉体和硅之间的关键差异就在于平凡机器有着不间断地保持前后一致的优势。计算机不会犯下大错，至少在象棋中不会，而人类则失之毫厘谬以千里。机器也不会苦于骄傲自满、焦虑和筋疲力尽。1997年当我与深蓝对战输掉了决定性的第六场比赛时，压力非常大，而且下棋也是这种状态。这是我职业生涯中最糟糕的一场对弈。&nbsp;尽管如此，那是一个激动的时刻，对机械掌握这门游戏的兴趣巅峰，可以追溯到18世纪骗人的象棋机器Turk（Mechanical Turk，是中世纪的一件震动欧洲的发明。一位发明家号称发明了一种具有人类智能的机器人，能够跟人下国际象棋，并且真的带着这个机器人横扫欧洲的各位象棋大师。一位不信邪的国外下令拆掉这台机器，结果发现里头真的藏着一个土耳其象棋大师。于是这台机器，或者说这位土耳其人 Turk，就被称为Mechanical Turk。——译者）。今天，AlphaGo代表了一个有着真正人工智能应用的机器学习项目，值得广泛关注。&nbsp;李世石可能比AlphaGo强很多，以致于人类出错可能性还不具有决定性。围棋的每一轮都比象棋有多得多的可能走法而且动态程度也存在差异，这两个因素都不利于机器获胜。但是，我恐怕看到了不祥之兆（the writing is on the wall）。如今，一台相当好的笔记本上运行的免费象棋程序都能战胜深蓝和任何人类大师。象棋机器从可预测、薄弱的状态到强大得可怕，这样飞跃只花了十几年。&nbsp;&nbsp;围棋，你的时间不多了。
"围棋;;日报 | AlphaGo 全球排名升至第二，仅次于柯洁...2030年将有4亿人选择共享无人车、中国提出深度学习处理器架构、AlphaGo 全球排名升至第二，仅次于柯洁、谷歌探月竞赛纪录片《Moon Shot》在Play Store上架……机器之心日报，精选一天前沿科技优质内容。2030年将有4亿人选择共享无人车目前，新型汽车共享经济已经开始生根发芽，随着无人驾驶汽车的不断发展并且进入市场，这种趋势还会继续增长。根据市场调研公司 ABI Research 最新发布的一份报告显示，到了 2030 年，全世界范围内将会有 4 亿人依赖于无人驾驶汽车的共享服务。该公司的副总裁 Dominique Bonte 称汽车共享经济是众包的典型例子。
Dominique Bonte 认为，汽车共享服务将推动无人驾驶汽车的发展，汽车可以自主接送客户。Uber 公司首席执行官 Travis Kalanick 曾经表示，他们将会购买特斯拉生产的所有无人驾驶汽车。
而特斯拉的 CEO 马斯克则计划在 2020 年让自家的无人驾驶汽车正式上路，但是他并没有透露到时候将会生产多少辆无人驾驶汽车。
外媒 ComputerWorld 报道称，无人驾驶汽车服务将会改变整个汽车行业，从而降低汽车的拥有权，同时模糊公共和私人交通之间的界线、增强社会的流动性、开发新的娱乐模式以及实现对汽车行业的全面整合。Facebook建地图：用人工智能详细标记哪些地方有人居住Facebook近日大秀在计算领域的肌肉，创建了能显示有那些人生活居住且他们的网络连接情况的地图。该地图项目由Facebook的Connectivity Labs推进负责，能够帮助公司更好为全球10%依然没有网络连接的公民提供更契合的连接解决方案。该实验室致力于通过无人机、卫星、激光等各种手段来为偏远地区提供网络连接。
通过建立更加完善的地图，公司能够决定在哪些地方部署WiFi热点或者蜂窝网络技术，从而帮助他们连接到网络中。为了生成该地图 ，Connectivity Labs联合Facebook的数据科学部门、基础框架机构、机器学习和人工智能集团共同合作，分析覆盖了2160万平方公里超过20个城市的总容量超过350TB的卫星地图数据。
在计算机图形技术的辅助下（包括Facebook的图像识别引擎）能够识别人类创建的设施，公司表示在此过程中并未使用任何Facebook上图片来创建数据。Facebook同样还表示在地图创建过程中部署了机器学习和人工智能技术，能够“成功识别建筑的轮廓并具备非常高的精准度。最古老人类DNA测序揭示尼安德特人的秘密Max Planck演化人类学研究所分子生物学家Matthias Meyer领导的团队成功测序了距今43万年的最古老人类DNA的部分序列，论文发表在《自然》期刊上。他们测序的古代人类DNA来自在西班牙北部一个洞穴内发现的早期尼安德特人骨骼，DNA已经降解和受到污染，研究人员设法从骨骼样本中恢复和测序了少量线粒体和核DNA。测序结果显示，现代人类的祖先与尼安德特人的祖先是在大约 55万到76.5万前之间分开的；早期尼安德特人和丹尼索瓦人携带了相同的线粒体DNA，但在后期的尼安德特人中消失了，研究人员推测可能是另一个未知的人类分支离开非洲进入欧亚大陆后与尼安德特人杂交，取代了曾共享的线粒体DNA谱系。谷歌探月竞赛纪录片《Moon Shot》在Play Store上架近日，谷歌在SXSW上为Lunar XPRIZE探月竞赛项目纪录片举行了一场世界首映礼。纪录片叫《Moon Shot》，由奥斯卡最佳记录长片提名导演Orlando von Einsiedel执导，《星球大战：原力觉醒》导演J.J Abrams则为该片的执行制片人。该竞赛于2007年推出，将在明年结束，据悉，最初竞赛队伍有29支，现在还剩下16支，并且已经有2支队伍确定了发射合同。中国提出深度学习处理器架构日前，中科院计算所陈云霁、陈天石课题组在国际上首先提出了深度学习处理器架构寒武纪。本月他们提出的深度学习处理器指令集DianNaoYu被计算机体系结构领域顶级国际会议ISCA2016所接收，其评分排名为近300篇投稿中的第一名。论文第一作者为刘少礼博士。
陈云霁、陈天石课题组的深度学习处理器指令集——DianNaoYu直接面对大规模神经元和突触的处理，一条指令即可完成一组神经元的处理。陈天石解释说，与谷歌采用的通用处理器不同，我们设计的处理器芯片专门面向深度学习技术。“通用处理器做深度学习好比是用瑞士军刀切肉，而我们设计专门的切肉刀来切。”AlphaGo 全球排名升至第二，仅次于柯洁快科技消息，Google Alphago 与韩国九段李世石的围棋大战于昨日落下了帷幕，AlphaGo 最终 4:1 取得了胜利，而由于第四场负于李世石，AlphaGo 也拥有了正式的 WHR 等级分数和排名。第四场比赛后 AlphaGo 的分数是 3533，排名世界第四，领先李世石一名，而昨天的比赛结束后，AlphaGo 凭借胜利，分数增加到 3586，排名上升至第二，超越了韩国的朴永训和日本的井山裕太，仅次于中国棋王柯洁（3621分）。WHR 等级分制是根据棋手在正式比赛中的输赢，使用贝叶斯公式计算出来的，因此选手必须至少输一局才会有排名，随着参加比赛次数的增加，等级分数也会越来越接近选手的真实水平。"
"AlphaGo;;日报 | AlphaGo 全球排名升至第二，仅次于柯洁...2030年将有4亿人选择共享无人车、中国提出深度学习处理器架构、AlphaGo 全球排名升至第二，仅次于柯洁、谷歌探月竞赛纪录片《Moon Shot》在Play Store上架……机器之心日报，精选一天前沿科技优质内容。2030年将有4亿人选择共享无人车目前，新型汽车共享经济已经开始生根发芽，随着无人驾驶汽车的不断发展并且进入市场，这种趋势还会继续增长。根据市场调研公司 ABI Research 最新发布的一份报告显示，到了 2030 年，全世界范围内将会有 4 亿人依赖于无人驾驶汽车的共享服务。该公司的副总裁 Dominique Bonte 称汽车共享经济是众包的典型例子。
Dominique Bonte 认为，汽车共享服务将推动无人驾驶汽车的发展，汽车可以自主接送客户。Uber 公司首席执行官 Travis Kalanick 曾经表示，他们将会购买特斯拉生产的所有无人驾驶汽车。
而特斯拉的 CEO 马斯克则计划在 2020 年让自家的无人驾驶汽车正式上路，但是他并没有透露到时候将会生产多少辆无人驾驶汽车。
外媒 ComputerWorld 报道称，无人驾驶汽车服务将会改变整个汽车行业，从而降低汽车的拥有权，同时模糊公共和私人交通之间的界线、增强社会的流动性、开发新的娱乐模式以及实现对汽车行业的全面整合。Facebook建地图：用人工智能详细标记哪些地方有人居住Facebook近日大秀在计算领域的肌肉，创建了能显示有那些人生活居住且他们的网络连接情况的地图。该地图项目由Facebook的Connectivity Labs推进负责，能够帮助公司更好为全球10%依然没有网络连接的公民提供更契合的连接解决方案。该实验室致力于通过无人机、卫星、激光等各种手段来为偏远地区提供网络连接。
通过建立更加完善的地图，公司能够决定在哪些地方部署WiFi热点或者蜂窝网络技术，从而帮助他们连接到网络中。为了生成该地图 ，Connectivity Labs联合Facebook的数据科学部门、基础框架机构、机器学习和人工智能集团共同合作，分析覆盖了2160万平方公里超过20个城市的总容量超过350TB的卫星地图数据。
在计算机图形技术的辅助下（包括Facebook的图像识别引擎）能够识别人类创建的设施，公司表示在此过程中并未使用任何Facebook上图片来创建数据。Facebook同样还表示在地图创建过程中部署了机器学习和人工智能技术，能够“成功识别建筑的轮廓并具备非常高的精准度。最古老人类DNA测序揭示尼安德特人的秘密Max Planck演化人类学研究所分子生物学家Matthias Meyer领导的团队成功测序了距今43万年的最古老人类DNA的部分序列，论文发表在《自然》期刊上。他们测序的古代人类DNA来自在西班牙北部一个洞穴内发现的早期尼安德特人骨骼，DNA已经降解和受到污染，研究人员设法从骨骼样本中恢复和测序了少量线粒体和核DNA。测序结果显示，现代人类的祖先与尼安德特人的祖先是在大约 55万到76.5万前之间分开的；早期尼安德特人和丹尼索瓦人携带了相同的线粒体DNA，但在后期的尼安德特人中消失了，研究人员推测可能是另一个未知的人类分支离开非洲进入欧亚大陆后与尼安德特人杂交，取代了曾共享的线粒体DNA谱系。谷歌探月竞赛纪录片《Moon Shot》在Play Store上架近日，谷歌在SXSW上为Lunar XPRIZE探月竞赛项目纪录片举行了一场世界首映礼。纪录片叫《Moon Shot》，由奥斯卡最佳记录长片提名导演Orlando von Einsiedel执导，《星球大战：原力觉醒》导演J.J Abrams则为该片的执行制片人。该竞赛于2007年推出，将在明年结束，据悉，最初竞赛队伍有29支，现在还剩下16支，并且已经有2支队伍确定了发射合同。中国提出深度学习处理器架构日前，中科院计算所陈云霁、陈天石课题组在国际上首先提出了深度学习处理器架构寒武纪。本月他们提出的深度学习处理器指令集DianNaoYu被计算机体系结构领域顶级国际会议ISCA2016所接收，其评分排名为近300篇投稿中的第一名。论文第一作者为刘少礼博士。
陈云霁、陈天石课题组的深度学习处理器指令集——DianNaoYu直接面对大规模神经元和突触的处理，一条指令即可完成一组神经元的处理。陈天石解释说，与谷歌采用的通用处理器不同，我们设计的处理器芯片专门面向深度学习技术。“通用处理器做深度学习好比是用瑞士军刀切肉，而我们设计专门的切肉刀来切。”AlphaGo 全球排名升至第二，仅次于柯洁快科技消息，Google Alphago 与韩国九段李世石的围棋大战于昨日落下了帷幕，AlphaGo 最终 4:1 取得了胜利，而由于第四场负于李世石，AlphaGo 也拥有了正式的 WHR 等级分数和排名。第四场比赛后 AlphaGo 的分数是 3533，排名世界第四，领先李世石一名，而昨天的比赛结束后，AlphaGo 凭借胜利，分数增加到 3586，排名上升至第二，超越了韩国的朴永训和日本的井山裕太，仅次于中国棋王柯洁（3621分）。WHR 等级分制是根据棋手在正式比赛中的输赢，使用贝叶斯公式计算出来的，因此选手必须至少输一局才会有排名，随着参加比赛次数的增加，等级分数也会越来越接近选手的真实水平。"
"日报;;【日报】谷歌推新机器学习平台、微软开发了个聊天机器人谷歌推出全新机器学习平台、微软开发新型聊天机器人、Red Hat成为第一家20亿美元收入的开源公司......机器之心日报，精选一天前沿科技优质内容。谷歌推出全新基于云端的机器学习平台谷歌昨天在主题为「NEXT Google Cloud Platform」大会上宣布多项新产品，其中就包括全新基于云端的机器学习平台。正如谷歌董事会主席Eric Schmidt所言，谷歌认为机器学习将成为「未来」。谷歌机器学习负责人杰夫·迪恩（Jeff Dean）随后介绍称，随着近年来机器学习技术的逐渐成熟，谷歌正加快步伐在主要平台部署机器学习技术。

平台将为开发者提供两方面服务：允许开发者利用自有数据建立机器学习模型，以及为开发者提供谷歌自己的「预训练」模型。借助这个新平台，第三方开发者可以更简单地使用谷歌开发并投入自身产品中的多项机器学习技术，比如谷歌Inbox 的Smart Reply。谷歌云平台的官方博客写道：基于云端的机器学习将成为机器学习的主流，让数据科学家和第三方开发者更好地开发出智能应用程序。据了解，开发者可以调用Google Now、Google 相册、Google语音搜索的API。谷歌还开放了自己的语音识别API，即谷歌语音搜索和语音输入的支持技术。Google Cloud SPeech API一开始将免费提供，以后再进行收费。这一应用包括了80多种语言，适用于各种实时语音识别与翻译应用。在语音识别领域，谷歌目前的主要竞争对手包括Nuance和微软。Nuance曾是苹果语音助手Siri背后的技术支持，也得到了诸多创业公司的广泛运用。但谷歌此次免费提供语音识别技术，可能会给Nuance这样的独立技术提供商带来明显冲击。按照谷歌的惯例，后期收费价格也会低于行业。保罗·艾伦成立一家以自己名字命名的前沿技术公司微软联合创始人保罗·艾伦(Paul Allen)今天宣布捐献1亿美元成立以他名字命名的保罗·艾伦前沿集团。这项新计划致力于通过资助研发中心和独立研究人员来推动科学前沿的发展。目前该集团已经分别在斯坦福大学和塔夫茨大学成立了研究中心，在未来4年两家研究中心都将会获得1000万美元的研发资金，并在接下来的4年中获得2000万美元的更多投入。斯坦福大学科研中心由Markus Covert负责带领，使用计算机模型来研究数以万计被沙门氏菌感染的交互白血细胞。而位于塔夫茨大学的科研中心则由Michael Levin和来自哈弗大学的研究专家共同合作，共同研究能够控制组织的生物信号。微软开发了个聊天机器人据科技博客TheVerge报道，微软正设法开发一种能够达到青少年聊天水平的人工智能技术，该公司研究团队在周三推出了一款聊天机器人Tay，旨在测试和改进微软产品在对话语言上的理解能力。Tay面向Twitter、群聊服务GroupMe、社交软件Kik开放使用。在Twitter上，用户只需在推文中@TayandYou就能获得Tay的回复。Tay由微软技术研究团队和必应团队联合开发。微软称，Tay的对话能力基于“对相关公开数据的挖掘”，并整合了编辑人员的文字输入，包括即兴喜剧演员。它将会在对话中学习和改进，所以从理论上讲，随着时间的推移，它的理解能力将提升，对话更为自然。 除了直截了当地聊天外，Tay还能对少数具体请求作出回应，它能说笑话，讲故事，占卜星象等。用户还可以与它玩一些怪异的表情符号猜谜游戏。下图为Tay与Twitter用户聊天：三星正在开发新物联网操作系统据PCWorld报道，三星正在针对该领域开发一款新的操作系统。详情将会在三星下个月在旧金山举行的开发者大会上公布。大会的一个技术讲习会的议程显示，「三星将会公布我们全新的开源实时物联网操作系统（RTOS），它拥有丰富的功能，同时也能高效运行，不失轻巧。」实时操作系统能够快速处理数据，几乎没有延时。这样的例子包括英特尔应用于Mars Rover火星探测器的VxWorks。三星将开源该操作系统，以促进它的普及，以及让更多的物联网设备实现互通。MIT的Tega教育机器人能与孩子进行互动 近日麻省理工学院研发了一款名为Tega的教育机器人，不但能与孩子进行互动，在经过一段时间后还能学会激发这些孩子的学习兴趣。Tega由安装在其内部装有定制软件的两部Android手机操控，这部手机包含了机器人需要的传感器，操作Tega的一切行为 。MIT表示与其他社交机器人不同的是，Tega拥有「情感计算」功能，拥有类似于人类一样的观察、理解和生成各种情感特征的能力。MIT研究人员希望通过将科技与教育设备相结合，为每个学生提供个性化的学习伙伴。 在经历过与38位3-5岁的幼儿园孩子8周的亲密互动后，Tega以其聪慧的头脑和灵活柔软的外形，成为了孩子们的好伙伴。Red Hat成为第一家20亿美元收入的开源公司Red Hat四年前成为第一家10亿美元收入的开源公司，现在它又成为了第一家20亿美元收入的开源公司，它的市值则超过了130亿美元。Red Hat的第四季度收入5.44亿美元，同比增长17%，服务订购费用4.8亿美元，同比增长18%。它的订购服务占了总收入的88%，去年的总收入20.5亿美元。Red Hat的收入主要来自向企业提供支持服务，它的软件基本上是免费的，它是Linux内核开发的主要资助者，雇佣了大量内核开发者，旗下的社区发行版CentOS是最受欢迎的服务器发行版之一。"
谷歌;;详解谷歌神经网络图像压缩技术：高质量地将图像压缩得更小谷歌 Research Blog 今日发布文章解读了其不久前在论文《Full Resolution Image Compression with Recurrent Neural Networks》中报告的神经网络图像压缩技术。数据压缩已经在互联网上无处不在。你在网上看的视频、图片，听的音乐，甚至现在正在阅读的这篇文章的背后都有使用到数据压缩技术。压缩技术让我们可以更快更高效地分享内容。如果没有数据压缩，获取你需要的信息的时间和带宽成本将会高得吓死个人！在论文《Full Resolution Image Compression with Recurrent Neural Networks》中，我们在我们之前的使用神经网络的数据压缩的研究上进行了延展，探索了机器学习是否能够像在图像识别和文本总结上一样提供更好的图像压缩结果。此外，我们也通过 TensorFlow 发布了我们的压缩模型，这样你也可以使用我们的网络实验压缩你自己的图像。发布地址：https://github.com/tensorflow/models/tree/master/compression我们介绍了一种新架构——该架构使用了门控循环单元（Gated Recurrent Unit，一种允许单元保存激活和处理序列的 RNN）的一种新变体「残差门控循环单元（Residual GRU: Residual Gated Recurrent Unit）」。我们的 Residual GRU 将已有的 GRU 和论文《Deep Residual Learning for Image Recognition》中介绍的残差连接（residual connections）结合了起来，从而在给定的压缩率下实现了显著的图像质量增益。我们没有和今天所用的许多压缩方法一样使用 DCT 来生成新的位表示（bit representation），而是训练了两组神经网络——一组用于创造图像的编码（编码器（encoder）），另一组用于从这些编码中创造图像（解码器（decoder））。我们的系统可以迭代式地细化原始图像的重建，其中的编码器和解码器都使用了 Residual GRU 层，这使得更多的信息可以从一次迭代传递到下一次迭代。每一次迭代都会给编码增加更多比特，从而可以实现更高质量的重建。从概念上讲，该网络的工作方式如下：初始残差 R[0] 对应于原始图像 I ：R[0]=I第一次迭代，设 i=1第 [i] 次迭代以 R[i-1] 作为输入，并运行编码器和二值化器（binarizer）将该图像压缩成 B[i] 第 [i] 次迭代在 B[i] 上运行解码器以生成一个重建出的图像 P[i]计算出第 [i] 次迭代的残差：R[i] = I - P[i]设 i=i+1，然后转到第 3 步（直到达到所需的迭代次数）残差图像（residual image）表示了当前版本的压缩图像与原始图像之间的差异。然后该图像被用作该网络的输入，以便为压缩图像的下一个版本移除压缩误差。现在压缩图像被表示成了 B[1] 到 B[N] 的级联。对于更大的 N 值，解码器可在减少误差和生成更高质量的原始图像的重建上获得更多的信息。为了了解其工作方式，可以看一下下面这个图像压缩网络的前两次迭代的例子，如下图所示。我们从一张灯塔的图像开始。在该网络的第一次前向通过中，原始图像作为输入（R[0]=I）。P[1] 是重建的图像。原始图像和编码图像之间的差异是残差 R[1]，其表示了压缩过程中的误差。左图：原始图像 I=R[0]；中图：重建的图像 P[1]；右图：残差 R[1]，其表示压缩中所产生的误差在该网络的第二次前向通过中，R[1] 作为该网络的输入（见下图），然后创造出一张更高质量的图像 P[2]。所以该系统是如何从残差 R[1] 中创造出一张如此高质量的图像（下面的中图 P[2]）的呢？因为该模型使用了带有记忆的循环节点（recurrent nodes with memory），所以该网络会保存每一次迭代的信息以便在下一次迭代中使用。它在第 [1] 次迭代中从原始图像上学到的东西被用在了对 R[1] 的处理上，从而可以从 B[2] 中生成更好的 P[2]。最后，通过从原始图像中减去 P[2]，该网络生成了一个新的残差 R[2]（右图）。这一次的残差更小，因为原始图像和重建的图像之间的差异更小了。该网络的第二次前向通过。左图：用作输入的 R[1]；中图：更高质量的重建 P[2]；右图：原始图像减去 P[2] 所得到的更小的残差 R[2]在更进一步的每次迭代中，该网络都会获得更多有关压缩中所引入的误差的信息（这些信息可在残差图像中获取）。如果其可以使用这些信息来预测残差（即使只有一点点），那也能得到更好的重建。我们的模型可以使用额外的比特，直到达到收益递减的程度——此时该网络的表达力（representational power）就耗尽了。为了验证文件大小和质量差异，我们使用了一种日本犬种 Vash 的一张照片生成了两张压缩图像：一张 JPEG，一张 Residual GRU。这两张图像的目标都是达到 0.9 MS-SSIM 的感知相似度（perceptual similarity）——该感知质量标准如果达到 1.0 则表示完全等同。我们训练好的模型所生成的图像的文件大小比 JPEG 小 25%。左图：原始图片（1419 KB PNG）~1.0 MS-SSIM；中图：JPEG（33 KB）~0.9 MS-SSIM；右图：Residual GRU（24 KB）~0.9 MS-SSIM。图像质量差不多的情况下，图像大小减小了 25%。观察一下图中狗的鼻子和嘴巴，我们发现我们的方法在图像中不会产生红色块和噪声。这是由于 JPEG 产生的块效应（blocking artifacts），然而我们的压缩网络一次性地在整个图像上起作用。我们的模型会在细节上有所权衡，图像中的纹理会丢失，但在消除块效应上，该系统显示出了极大的潜力。左图：原始图片；中图：JPEG；右图：Residual GRU虽然如今的编解码器表现很好，但我们的研究表明使用神经网络压缩图片能得到更高的质量和更小的文件大小。想要了解关于该研究的更多内容，可以阅读下面的论文：论文：Full Resolution Image Compression with Recurrent Neural Networks摘要：本论文提出了一套基于神经网络的全分辨率有损图像压缩方法。这些我们所描述的每一种架构都可以在实施过程中提供可变的压缩率，而不需要对网络进行再训练（retraining）：每个网络只需要训练一次。我们所有的架构都由一个基于循环神经网络（RNN：recurrent neural network）的编码器和解码器、一个 binarizer 和一个用于熵编码（entropy coding）的神经网络构成。我们对 RNN 的类型（LSTM、关联 LSTM（associative LSTM）进行了比较，并引入了一种新的 GRU 和 ResNet 的混合结构。我们还研究了 one-shot 与附加重建架构（additive reconstruction architectures）的对比，并引入了一种新的扩展过的附加框架。对比之前的研究成果，我们的成果显示出了 4.3%-8.8% AUC（率失真曲线下的区域）提升，具体数字取决于所用的感知标准（perceptual metric）。就我们所知，在 Kodak 数据集图像的率失真曲线（rate-distortion curve）的大部分比特率的图像压缩上，这是第一个表现优于 JPEG 的神经网络架构，不管有没有熵编码的辅助。
神经网络;;详解谷歌神经网络图像压缩技术：高质量地将图像压缩得更小谷歌 Research Blog 今日发布文章解读了其不久前在论文《Full Resolution Image Compression with Recurrent Neural Networks》中报告的神经网络图像压缩技术。数据压缩已经在互联网上无处不在。你在网上看的视频、图片，听的音乐，甚至现在正在阅读的这篇文章的背后都有使用到数据压缩技术。压缩技术让我们可以更快更高效地分享内容。如果没有数据压缩，获取你需要的信息的时间和带宽成本将会高得吓死个人！在论文《Full Resolution Image Compression with Recurrent Neural Networks》中，我们在我们之前的使用神经网络的数据压缩的研究上进行了延展，探索了机器学习是否能够像在图像识别和文本总结上一样提供更好的图像压缩结果。此外，我们也通过 TensorFlow 发布了我们的压缩模型，这样你也可以使用我们的网络实验压缩你自己的图像。发布地址：https://github.com/tensorflow/models/tree/master/compression我们介绍了一种新架构——该架构使用了门控循环单元（Gated Recurrent Unit，一种允许单元保存激活和处理序列的 RNN）的一种新变体「残差门控循环单元（Residual GRU: Residual Gated Recurrent Unit）」。我们的 Residual GRU 将已有的 GRU 和论文《Deep Residual Learning for Image Recognition》中介绍的残差连接（residual connections）结合了起来，从而在给定的压缩率下实现了显著的图像质量增益。我们没有和今天所用的许多压缩方法一样使用 DCT 来生成新的位表示（bit representation），而是训练了两组神经网络——一组用于创造图像的编码（编码器（encoder）），另一组用于从这些编码中创造图像（解码器（decoder））。我们的系统可以迭代式地细化原始图像的重建，其中的编码器和解码器都使用了 Residual GRU 层，这使得更多的信息可以从一次迭代传递到下一次迭代。每一次迭代都会给编码增加更多比特，从而可以实现更高质量的重建。从概念上讲，该网络的工作方式如下：初始残差 R[0] 对应于原始图像 I ：R[0]=I第一次迭代，设 i=1第 [i] 次迭代以 R[i-1] 作为输入，并运行编码器和二值化器（binarizer）将该图像压缩成 B[i] 第 [i] 次迭代在 B[i] 上运行解码器以生成一个重建出的图像 P[i]计算出第 [i] 次迭代的残差：R[i] = I - P[i]设 i=i+1，然后转到第 3 步（直到达到所需的迭代次数）残差图像（residual image）表示了当前版本的压缩图像与原始图像之间的差异。然后该图像被用作该网络的输入，以便为压缩图像的下一个版本移除压缩误差。现在压缩图像被表示成了 B[1] 到 B[N] 的级联。对于更大的 N 值，解码器可在减少误差和生成更高质量的原始图像的重建上获得更多的信息。为了了解其工作方式，可以看一下下面这个图像压缩网络的前两次迭代的例子，如下图所示。我们从一张灯塔的图像开始。在该网络的第一次前向通过中，原始图像作为输入（R[0]=I）。P[1] 是重建的图像。原始图像和编码图像之间的差异是残差 R[1]，其表示了压缩过程中的误差。左图：原始图像 I=R[0]；中图：重建的图像 P[1]；右图：残差 R[1]，其表示压缩中所产生的误差在该网络的第二次前向通过中，R[1] 作为该网络的输入（见下图），然后创造出一张更高质量的图像 P[2]。所以该系统是如何从残差 R[1] 中创造出一张如此高质量的图像（下面的中图 P[2]）的呢？因为该模型使用了带有记忆的循环节点（recurrent nodes with memory），所以该网络会保存每一次迭代的信息以便在下一次迭代中使用。它在第 [1] 次迭代中从原始图像上学到的东西被用在了对 R[1] 的处理上，从而可以从 B[2] 中生成更好的 P[2]。最后，通过从原始图像中减去 P[2]，该网络生成了一个新的残差 R[2]（右图）。这一次的残差更小，因为原始图像和重建的图像之间的差异更小了。该网络的第二次前向通过。左图：用作输入的 R[1]；中图：更高质量的重建 P[2]；右图：原始图像减去 P[2] 所得到的更小的残差 R[2]在更进一步的每次迭代中，该网络都会获得更多有关压缩中所引入的误差的信息（这些信息可在残差图像中获取）。如果其可以使用这些信息来预测残差（即使只有一点点），那也能得到更好的重建。我们的模型可以使用额外的比特，直到达到收益递减的程度——此时该网络的表达力（representational power）就耗尽了。为了验证文件大小和质量差异，我们使用了一种日本犬种 Vash 的一张照片生成了两张压缩图像：一张 JPEG，一张 Residual GRU。这两张图像的目标都是达到 0.9 MS-SSIM 的感知相似度（perceptual similarity）——该感知质量标准如果达到 1.0 则表示完全等同。我们训练好的模型所生成的图像的文件大小比 JPEG 小 25%。左图：原始图片（1419 KB PNG）~1.0 MS-SSIM；中图：JPEG（33 KB）~0.9 MS-SSIM；右图：Residual GRU（24 KB）~0.9 MS-SSIM。图像质量差不多的情况下，图像大小减小了 25%。观察一下图中狗的鼻子和嘴巴，我们发现我们的方法在图像中不会产生红色块和噪声。这是由于 JPEG 产生的块效应（blocking artifacts），然而我们的压缩网络一次性地在整个图像上起作用。我们的模型会在细节上有所权衡，图像中的纹理会丢失，但在消除块效应上，该系统显示出了极大的潜力。左图：原始图片；中图：JPEG；右图：Residual GRU虽然如今的编解码器表现很好，但我们的研究表明使用神经网络压缩图片能得到更高的质量和更小的文件大小。想要了解关于该研究的更多内容，可以阅读下面的论文：论文：Full Resolution Image Compression with Recurrent Neural Networks摘要：本论文提出了一套基于神经网络的全分辨率有损图像压缩方法。这些我们所描述的每一种架构都可以在实施过程中提供可变的压缩率，而不需要对网络进行再训练（retraining）：每个网络只需要训练一次。我们所有的架构都由一个基于循环神经网络（RNN：recurrent neural network）的编码器和解码器、一个 binarizer 和一个用于熵编码（entropy coding）的神经网络构成。我们对 RNN 的类型（LSTM、关联 LSTM（associative LSTM）进行了比较，并引入了一种新的 GRU 和 ResNet 的混合结构。我们还研究了 one-shot 与附加重建架构（additive reconstruction architectures）的对比，并引入了一种新的扩展过的附加框架。对比之前的研究成果，我们的成果显示出了 4.3%-8.8% AUC（率失真曲线下的区域）提升，具体数字取决于所用的感知标准（perceptual metric）。就我们所知，在 Kodak 数据集图像的率失真曲线（rate-distortion curve）的大部分比特率的图像压缩上，这是第一个表现优于 JPEG 的神经网络架构，不管有没有熵编码的辅助。
图像压缩;;详解谷歌神经网络图像压缩技术：高质量地将图像压缩得更小谷歌 Research Blog 今日发布文章解读了其不久前在论文《Full Resolution Image Compression with Recurrent Neural Networks》中报告的神经网络图像压缩技术。数据压缩已经在互联网上无处不在。你在网上看的视频、图片，听的音乐，甚至现在正在阅读的这篇文章的背后都有使用到数据压缩技术。压缩技术让我们可以更快更高效地分享内容。如果没有数据压缩，获取你需要的信息的时间和带宽成本将会高得吓死个人！在论文《Full Resolution Image Compression with Recurrent Neural Networks》中，我们在我们之前的使用神经网络的数据压缩的研究上进行了延展，探索了机器学习是否能够像在图像识别和文本总结上一样提供更好的图像压缩结果。此外，我们也通过 TensorFlow 发布了我们的压缩模型，这样你也可以使用我们的网络实验压缩你自己的图像。发布地址：https://github.com/tensorflow/models/tree/master/compression我们介绍了一种新架构——该架构使用了门控循环单元（Gated Recurrent Unit，一种允许单元保存激活和处理序列的 RNN）的一种新变体「残差门控循环单元（Residual GRU: Residual Gated Recurrent Unit）」。我们的 Residual GRU 将已有的 GRU 和论文《Deep Residual Learning for Image Recognition》中介绍的残差连接（residual connections）结合了起来，从而在给定的压缩率下实现了显著的图像质量增益。我们没有和今天所用的许多压缩方法一样使用 DCT 来生成新的位表示（bit representation），而是训练了两组神经网络——一组用于创造图像的编码（编码器（encoder）），另一组用于从这些编码中创造图像（解码器（decoder））。我们的系统可以迭代式地细化原始图像的重建，其中的编码器和解码器都使用了 Residual GRU 层，这使得更多的信息可以从一次迭代传递到下一次迭代。每一次迭代都会给编码增加更多比特，从而可以实现更高质量的重建。从概念上讲，该网络的工作方式如下：初始残差 R[0] 对应于原始图像 I ：R[0]=I第一次迭代，设 i=1第 [i] 次迭代以 R[i-1] 作为输入，并运行编码器和二值化器（binarizer）将该图像压缩成 B[i] 第 [i] 次迭代在 B[i] 上运行解码器以生成一个重建出的图像 P[i]计算出第 [i] 次迭代的残差：R[i] = I - P[i]设 i=i+1，然后转到第 3 步（直到达到所需的迭代次数）残差图像（residual image）表示了当前版本的压缩图像与原始图像之间的差异。然后该图像被用作该网络的输入，以便为压缩图像的下一个版本移除压缩误差。现在压缩图像被表示成了 B[1] 到 B[N] 的级联。对于更大的 N 值，解码器可在减少误差和生成更高质量的原始图像的重建上获得更多的信息。为了了解其工作方式，可以看一下下面这个图像压缩网络的前两次迭代的例子，如下图所示。我们从一张灯塔的图像开始。在该网络的第一次前向通过中，原始图像作为输入（R[0]=I）。P[1] 是重建的图像。原始图像和编码图像之间的差异是残差 R[1]，其表示了压缩过程中的误差。左图：原始图像 I=R[0]；中图：重建的图像 P[1]；右图：残差 R[1]，其表示压缩中所产生的误差在该网络的第二次前向通过中，R[1] 作为该网络的输入（见下图），然后创造出一张更高质量的图像 P[2]。所以该系统是如何从残差 R[1] 中创造出一张如此高质量的图像（下面的中图 P[2]）的呢？因为该模型使用了带有记忆的循环节点（recurrent nodes with memory），所以该网络会保存每一次迭代的信息以便在下一次迭代中使用。它在第 [1] 次迭代中从原始图像上学到的东西被用在了对 R[1] 的处理上，从而可以从 B[2] 中生成更好的 P[2]。最后，通过从原始图像中减去 P[2]，该网络生成了一个新的残差 R[2]（右图）。这一次的残差更小，因为原始图像和重建的图像之间的差异更小了。该网络的第二次前向通过。左图：用作输入的 R[1]；中图：更高质量的重建 P[2]；右图：原始图像减去 P[2] 所得到的更小的残差 R[2]在更进一步的每次迭代中，该网络都会获得更多有关压缩中所引入的误差的信息（这些信息可在残差图像中获取）。如果其可以使用这些信息来预测残差（即使只有一点点），那也能得到更好的重建。我们的模型可以使用额外的比特，直到达到收益递减的程度——此时该网络的表达力（representational power）就耗尽了。为了验证文件大小和质量差异，我们使用了一种日本犬种 Vash 的一张照片生成了两张压缩图像：一张 JPEG，一张 Residual GRU。这两张图像的目标都是达到 0.9 MS-SSIM 的感知相似度（perceptual similarity）——该感知质量标准如果达到 1.0 则表示完全等同。我们训练好的模型所生成的图像的文件大小比 JPEG 小 25%。左图：原始图片（1419 KB PNG）~1.0 MS-SSIM；中图：JPEG（33 KB）~0.9 MS-SSIM；右图：Residual GRU（24 KB）~0.9 MS-SSIM。图像质量差不多的情况下，图像大小减小了 25%。观察一下图中狗的鼻子和嘴巴，我们发现我们的方法在图像中不会产生红色块和噪声。这是由于 JPEG 产生的块效应（blocking artifacts），然而我们的压缩网络一次性地在整个图像上起作用。我们的模型会在细节上有所权衡，图像中的纹理会丢失，但在消除块效应上，该系统显示出了极大的潜力。左图：原始图片；中图：JPEG；右图：Residual GRU虽然如今的编解码器表现很好，但我们的研究表明使用神经网络压缩图片能得到更高的质量和更小的文件大小。想要了解关于该研究的更多内容，可以阅读下面的论文：论文：Full Resolution Image Compression with Recurrent Neural Networks摘要：本论文提出了一套基于神经网络的全分辨率有损图像压缩方法。这些我们所描述的每一种架构都可以在实施过程中提供可变的压缩率，而不需要对网络进行再训练（retraining）：每个网络只需要训练一次。我们所有的架构都由一个基于循环神经网络（RNN：recurrent neural network）的编码器和解码器、一个 binarizer 和一个用于熵编码（entropy coding）的神经网络构成。我们对 RNN 的类型（LSTM、关联 LSTM（associative LSTM）进行了比较，并引入了一种新的 GRU 和 ResNet 的混合结构。我们还研究了 one-shot 与附加重建架构（additive reconstruction architectures）的对比，并引入了一种新的扩展过的附加框架。对比之前的研究成果，我们的成果显示出了 4.3%-8.8% AUC（率失真曲线下的区域）提升，具体数字取决于所用的感知标准（perceptual metric）。就我们所知，在 Kodak 数据集图像的率失真曲线（rate-distortion curve）的大部分比特率的图像压缩上，这是第一个表现优于 JPEG 的神经网络架构，不管有没有熵编码的辅助。
理论;;详解谷歌神经网络图像压缩技术：高质量地将图像压缩得更小谷歌 Research Blog 今日发布文章解读了其不久前在论文《Full Resolution Image Compression with Recurrent Neural Networks》中报告的神经网络图像压缩技术。数据压缩已经在互联网上无处不在。你在网上看的视频、图片，听的音乐，甚至现在正在阅读的这篇文章的背后都有使用到数据压缩技术。压缩技术让我们可以更快更高效地分享内容。如果没有数据压缩，获取你需要的信息的时间和带宽成本将会高得吓死个人！在论文《Full Resolution Image Compression with Recurrent Neural Networks》中，我们在我们之前的使用神经网络的数据压缩的研究上进行了延展，探索了机器学习是否能够像在图像识别和文本总结上一样提供更好的图像压缩结果。此外，我们也通过 TensorFlow 发布了我们的压缩模型，这样你也可以使用我们的网络实验压缩你自己的图像。发布地址：https://github.com/tensorflow/models/tree/master/compression我们介绍了一种新架构——该架构使用了门控循环单元（Gated Recurrent Unit，一种允许单元保存激活和处理序列的 RNN）的一种新变体「残差门控循环单元（Residual GRU: Residual Gated Recurrent Unit）」。我们的 Residual GRU 将已有的 GRU 和论文《Deep Residual Learning for Image Recognition》中介绍的残差连接（residual connections）结合了起来，从而在给定的压缩率下实现了显著的图像质量增益。我们没有和今天所用的许多压缩方法一样使用 DCT 来生成新的位表示（bit representation），而是训练了两组神经网络——一组用于创造图像的编码（编码器（encoder）），另一组用于从这些编码中创造图像（解码器（decoder））。我们的系统可以迭代式地细化原始图像的重建，其中的编码器和解码器都使用了 Residual GRU 层，这使得更多的信息可以从一次迭代传递到下一次迭代。每一次迭代都会给编码增加更多比特，从而可以实现更高质量的重建。从概念上讲，该网络的工作方式如下：初始残差 R[0] 对应于原始图像 I ：R[0]=I第一次迭代，设 i=1第 [i] 次迭代以 R[i-1] 作为输入，并运行编码器和二值化器（binarizer）将该图像压缩成 B[i] 第 [i] 次迭代在 B[i] 上运行解码器以生成一个重建出的图像 P[i]计算出第 [i] 次迭代的残差：R[i] = I - P[i]设 i=i+1，然后转到第 3 步（直到达到所需的迭代次数）残差图像（residual image）表示了当前版本的压缩图像与原始图像之间的差异。然后该图像被用作该网络的输入，以便为压缩图像的下一个版本移除压缩误差。现在压缩图像被表示成了 B[1] 到 B[N] 的级联。对于更大的 N 值，解码器可在减少误差和生成更高质量的原始图像的重建上获得更多的信息。为了了解其工作方式，可以看一下下面这个图像压缩网络的前两次迭代的例子，如下图所示。我们从一张灯塔的图像开始。在该网络的第一次前向通过中，原始图像作为输入（R[0]=I）。P[1] 是重建的图像。原始图像和编码图像之间的差异是残差 R[1]，其表示了压缩过程中的误差。左图：原始图像 I=R[0]；中图：重建的图像 P[1]；右图：残差 R[1]，其表示压缩中所产生的误差在该网络的第二次前向通过中，R[1] 作为该网络的输入（见下图），然后创造出一张更高质量的图像 P[2]。所以该系统是如何从残差 R[1] 中创造出一张如此高质量的图像（下面的中图 P[2]）的呢？因为该模型使用了带有记忆的循环节点（recurrent nodes with memory），所以该网络会保存每一次迭代的信息以便在下一次迭代中使用。它在第 [1] 次迭代中从原始图像上学到的东西被用在了对 R[1] 的处理上，从而可以从 B[2] 中生成更好的 P[2]。最后，通过从原始图像中减去 P[2]，该网络生成了一个新的残差 R[2]（右图）。这一次的残差更小，因为原始图像和重建的图像之间的差异更小了。该网络的第二次前向通过。左图：用作输入的 R[1]；中图：更高质量的重建 P[2]；右图：原始图像减去 P[2] 所得到的更小的残差 R[2]在更进一步的每次迭代中，该网络都会获得更多有关压缩中所引入的误差的信息（这些信息可在残差图像中获取）。如果其可以使用这些信息来预测残差（即使只有一点点），那也能得到更好的重建。我们的模型可以使用额外的比特，直到达到收益递减的程度——此时该网络的表达力（representational power）就耗尽了。为了验证文件大小和质量差异，我们使用了一种日本犬种 Vash 的一张照片生成了两张压缩图像：一张 JPEG，一张 Residual GRU。这两张图像的目标都是达到 0.9 MS-SSIM 的感知相似度（perceptual similarity）——该感知质量标准如果达到 1.0 则表示完全等同。我们训练好的模型所生成的图像的文件大小比 JPEG 小 25%。左图：原始图片（1419 KB PNG）~1.0 MS-SSIM；中图：JPEG（33 KB）~0.9 MS-SSIM；右图：Residual GRU（24 KB）~0.9 MS-SSIM。图像质量差不多的情况下，图像大小减小了 25%。观察一下图中狗的鼻子和嘴巴，我们发现我们的方法在图像中不会产生红色块和噪声。这是由于 JPEG 产生的块效应（blocking artifacts），然而我们的压缩网络一次性地在整个图像上起作用。我们的模型会在细节上有所权衡，图像中的纹理会丢失，但在消除块效应上，该系统显示出了极大的潜力。左图：原始图片；中图：JPEG；右图：Residual GRU虽然如今的编解码器表现很好，但我们的研究表明使用神经网络压缩图片能得到更高的质量和更小的文件大小。想要了解关于该研究的更多内容，可以阅读下面的论文：论文：Full Resolution Image Compression with Recurrent Neural Networks摘要：本论文提出了一套基于神经网络的全分辨率有损图像压缩方法。这些我们所描述的每一种架构都可以在实施过程中提供可变的压缩率，而不需要对网络进行再训练（retraining）：每个网络只需要训练一次。我们所有的架构都由一个基于循环神经网络（RNN：recurrent neural network）的编码器和解码器、一个 binarizer 和一个用于熵编码（entropy coding）的神经网络构成。我们对 RNN 的类型（LSTM、关联 LSTM（associative LSTM）进行了比较，并引入了一种新的 GRU 和 ResNet 的混合结构。我们还研究了 one-shot 与附加重建架构（additive reconstruction architectures）的对比，并引入了一种新的扩展过的附加框架。对比之前的研究成果，我们的成果显示出了 4.3%-8.8% AUC（率失真曲线下的区域）提升，具体数字取决于所用的感知标准（perceptual metric）。就我们所知，在 Kodak 数据集图像的率失真曲线（rate-distortion curve）的大部分比特率的图像压缩上，这是第一个表现优于 JPEG 的神经网络架构，不管有没有熵编码的辅助。
论文;;详解谷歌神经网络图像压缩技术：高质量地将图像压缩得更小谷歌 Research Blog 今日发布文章解读了其不久前在论文《Full Resolution Image Compression with Recurrent Neural Networks》中报告的神经网络图像压缩技术。数据压缩已经在互联网上无处不在。你在网上看的视频、图片，听的音乐，甚至现在正在阅读的这篇文章的背后都有使用到数据压缩技术。压缩技术让我们可以更快更高效地分享内容。如果没有数据压缩，获取你需要的信息的时间和带宽成本将会高得吓死个人！在论文《Full Resolution Image Compression with Recurrent Neural Networks》中，我们在我们之前的使用神经网络的数据压缩的研究上进行了延展，探索了机器学习是否能够像在图像识别和文本总结上一样提供更好的图像压缩结果。此外，我们也通过 TensorFlow 发布了我们的压缩模型，这样你也可以使用我们的网络实验压缩你自己的图像。发布地址：https://github.com/tensorflow/models/tree/master/compression我们介绍了一种新架构——该架构使用了门控循环单元（Gated Recurrent Unit，一种允许单元保存激活和处理序列的 RNN）的一种新变体「残差门控循环单元（Residual GRU: Residual Gated Recurrent Unit）」。我们的 Residual GRU 将已有的 GRU 和论文《Deep Residual Learning for Image Recognition》中介绍的残差连接（residual connections）结合了起来，从而在给定的压缩率下实现了显著的图像质量增益。我们没有和今天所用的许多压缩方法一样使用 DCT 来生成新的位表示（bit representation），而是训练了两组神经网络——一组用于创造图像的编码（编码器（encoder）），另一组用于从这些编码中创造图像（解码器（decoder））。我们的系统可以迭代式地细化原始图像的重建，其中的编码器和解码器都使用了 Residual GRU 层，这使得更多的信息可以从一次迭代传递到下一次迭代。每一次迭代都会给编码增加更多比特，从而可以实现更高质量的重建。从概念上讲，该网络的工作方式如下：初始残差 R[0] 对应于原始图像 I ：R[0]=I第一次迭代，设 i=1第 [i] 次迭代以 R[i-1] 作为输入，并运行编码器和二值化器（binarizer）将该图像压缩成 B[i] 第 [i] 次迭代在 B[i] 上运行解码器以生成一个重建出的图像 P[i]计算出第 [i] 次迭代的残差：R[i] = I - P[i]设 i=i+1，然后转到第 3 步（直到达到所需的迭代次数）残差图像（residual image）表示了当前版本的压缩图像与原始图像之间的差异。然后该图像被用作该网络的输入，以便为压缩图像的下一个版本移除压缩误差。现在压缩图像被表示成了 B[1] 到 B[N] 的级联。对于更大的 N 值，解码器可在减少误差和生成更高质量的原始图像的重建上获得更多的信息。为了了解其工作方式，可以看一下下面这个图像压缩网络的前两次迭代的例子，如下图所示。我们从一张灯塔的图像开始。在该网络的第一次前向通过中，原始图像作为输入（R[0]=I）。P[1] 是重建的图像。原始图像和编码图像之间的差异是残差 R[1]，其表示了压缩过程中的误差。左图：原始图像 I=R[0]；中图：重建的图像 P[1]；右图：残差 R[1]，其表示压缩中所产生的误差在该网络的第二次前向通过中，R[1] 作为该网络的输入（见下图），然后创造出一张更高质量的图像 P[2]。所以该系统是如何从残差 R[1] 中创造出一张如此高质量的图像（下面的中图 P[2]）的呢？因为该模型使用了带有记忆的循环节点（recurrent nodes with memory），所以该网络会保存每一次迭代的信息以便在下一次迭代中使用。它在第 [1] 次迭代中从原始图像上学到的东西被用在了对 R[1] 的处理上，从而可以从 B[2] 中生成更好的 P[2]。最后，通过从原始图像中减去 P[2]，该网络生成了一个新的残差 R[2]（右图）。这一次的残差更小，因为原始图像和重建的图像之间的差异更小了。该网络的第二次前向通过。左图：用作输入的 R[1]；中图：更高质量的重建 P[2]；右图：原始图像减去 P[2] 所得到的更小的残差 R[2]在更进一步的每次迭代中，该网络都会获得更多有关压缩中所引入的误差的信息（这些信息可在残差图像中获取）。如果其可以使用这些信息来预测残差（即使只有一点点），那也能得到更好的重建。我们的模型可以使用额外的比特，直到达到收益递减的程度——此时该网络的表达力（representational power）就耗尽了。为了验证文件大小和质量差异，我们使用了一种日本犬种 Vash 的一张照片生成了两张压缩图像：一张 JPEG，一张 Residual GRU。这两张图像的目标都是达到 0.9 MS-SSIM 的感知相似度（perceptual similarity）——该感知质量标准如果达到 1.0 则表示完全等同。我们训练好的模型所生成的图像的文件大小比 JPEG 小 25%。左图：原始图片（1419 KB PNG）~1.0 MS-SSIM；中图：JPEG（33 KB）~0.9 MS-SSIM；右图：Residual GRU（24 KB）~0.9 MS-SSIM。图像质量差不多的情况下，图像大小减小了 25%。观察一下图中狗的鼻子和嘴巴，我们发现我们的方法在图像中不会产生红色块和噪声。这是由于 JPEG 产生的块效应（blocking artifacts），然而我们的压缩网络一次性地在整个图像上起作用。我们的模型会在细节上有所权衡，图像中的纹理会丢失，但在消除块效应上，该系统显示出了极大的潜力。左图：原始图片；中图：JPEG；右图：Residual GRU虽然如今的编解码器表现很好，但我们的研究表明使用神经网络压缩图片能得到更高的质量和更小的文件大小。想要了解关于该研究的更多内容，可以阅读下面的论文：论文：Full Resolution Image Compression with Recurrent Neural Networks摘要：本论文提出了一套基于神经网络的全分辨率有损图像压缩方法。这些我们所描述的每一种架构都可以在实施过程中提供可变的压缩率，而不需要对网络进行再训练（retraining）：每个网络只需要训练一次。我们所有的架构都由一个基于循环神经网络（RNN：recurrent neural network）的编码器和解码器、一个 binarizer 和一个用于熵编码（entropy coding）的神经网络构成。我们对 RNN 的类型（LSTM、关联 LSTM（associative LSTM）进行了比较，并引入了一种新的 GRU 和 ResNet 的混合结构。我们还研究了 one-shot 与附加重建架构（additive reconstruction architectures）的对比，并引入了一种新的扩展过的附加框架。对比之前的研究成果，我们的成果显示出了 4.3%-8.8% AUC（率失真曲线下的区域）提升，具体数字取决于所用的感知标准（perceptual metric）。就我们所知，在 Kodak 数据集图像的率失真曲线（rate-distortion curve）的大部分比特率的图像压缩上，这是第一个表现优于 JPEG 的神经网络架构，不管有没有熵编码的辅助。
"人工智能;;人工智能教育领域的应用：学习分析、教材整合、虚拟导师在 支持教育企业和研发创新性的教育技术解决方案之时，我已经锻炼了自己对使用技术（using technology）「会是什么样子」的预见力。我目前担任宾夕法尼亚大学研究生教育学院的学术创新执行主任及教育高级研究员，在这里，我还运行着 Milken-GSE 商业计划竞赛并主管EDSi（教育设计工作室）。在这之前，作为Educorp 顾问公司的总经理，我向教育实体提供战略咨询；而作为WorldSage的执行副总裁，我在欧盟创造了一个全球网络的高等教育机构。曾经作为Curriki的执行主任，我建造了最具创新与健全的全球开源教育社区之一。我之前还是一家教育投资机构Core Learning的联合CEO，同时还担任bigchalk项目的首席学术官。我目前服务于几家教育公司的董事会，为教育技术公司提供前期支持。正如我们所知，我们的世界正在全力发展人工智能：Siri管理着我们的日程；Facebook向我们推荐好友；计算机帮助我们进行股票交易；汽车可以自动泊车；空中交通管制几乎是全自动化的。从军事到医疗到制造业，几乎每一个领域都得益于人工智能的进步。

然而，最近人工智能的发展几乎没有改善教育产业。为什么教育落后了呢？为什么人工智能在教育产业的推进似乎在过去几年毫无起色？

伍尔夫（Woolf）等人在AI Magazine的一期特刊中，提出了一些人工智能应用于教育产业需要解决的「巨大挑战」，包括：每一个学生的虚拟导师：将用户模型、社交模拟和知识展现整合起来的无处不在的支持。定位21世纪的技能：帮助学生掌握自我导向、自我评估、团队建设等技能。互动数据的分析：将大量有关个人学习、社交文本、学习内容和个人兴趣的数据整合起来。提供参与全球化课堂的机会：增加世界范围内课堂的互联互通。扩展生命长度与宽度的技术：将学习从课堂扩展到课外，扩展到学校之外，扩展到学生的生活之中。在过去十年，人工智能的应用已经解决了学习的几大挑战，包括语言处理、推理、计划和认知模型（Woolf，2009）。有一些计算机软件被称为智能导师系统，能够在解决问题期间跟踪学生的「心智步骤」，来确定学生对相关领域的误解并评估学生对之的理解。智能导师系统也能够向学生提供及时的指导、反馈和解释，培养学生高效的学习习惯，比如自我调节、自我监测和自我解释。

另外，智能导师系统也能够在不同等级的困难程度上设定学习活动，并提供最适合学生的学习内容。（Azevedo &amp; Hadwin, 2005; Shute, 2008; VanLehn, 2006）。这些系统可模拟一对一教学的益处，部分系统在特定主题上甚至超过了未经训练的导师，达到专业导师的水平（VanLehn, 2011）。

这些智能导师系统中值得注意的包括 Tabtor， Carnegie Learning 和 Front Row。做过的一次元分析比较了使用智能导师系统的结果与使用其他教学方法的结果，在普遍情况下，使用智能导师系统进行学习能够得到更高的分数。（Ma等，2014）。

在另一款学习应用中，人工智能能够对内容进行组织、综合进而传授。正如所知的深度学习系统，能够阅读、书写，并能模拟人类行为。比如 Scott R. Parfitt 博士的 CTI（Content Technologies, Inc.)公司的产品，能够让教育工作者综合定制的教科书内容。教育工作者导入课程，CTI的引擎转存出一份综合了核心内容的文本。&nbsp;人工智能和机器学习的进展令人印象深刻，但在使学习科学进步方面还有许多工作需要做。虽然做出一些如同上文介绍的人工智能在教育领域的应用，但这些努力和非教育领域的进展相比就显得黯然失色了。&nbsp;2015年，大多人工智能的突破都在教育领域之外。比如，亚马逊和UPS（美国快递公司）开始使用无人机为客户配送包裹和其他货物；谷歌花了大约5亿美元收购了一家英国人工智能创业公司DeepMind，为其分配了140多名计算机学家，他们做出的软件教会了它自己如何掌握49款复古视频游戏，并不断地超越人类选手；谷歌也在测试他们的无人驾驶汽车；来自康奈尔大学的机器人PR2学会了如何执行不同的小型任务，之后教会了另一个来自布朗大学的机器人Baxter如何执行这些任务；另一个机器人ConceptNet 4进行了一次智商测试，测试内容包括词汇、比较和理解，结果显示它的智商与4岁儿童持平。

我相信人工智能在逐渐发展的学习分析、课程材料质量评估、适应性学习和推荐引擎领域将会扮演重要角色。人工智能也有潜力在大型开放式网络课程、混合学习、在线学习方面为每一个学生打造独一无二的学习方法（Chaudhry, et al., 2013）。

人工智能在各种领域做出贡献的可能性都非常巨大，而教育不应该落在后面。（想要了解更多有关人工智能在这些领域的潜力，参见最近的AI Magazine上的一期特刊）；"
"人工智能应用;;人工智能教育领域的应用：学习分析、教材整合、虚拟导师在 支持教育企业和研发创新性的教育技术解决方案之时，我已经锻炼了自己对使用技术（using technology）「会是什么样子」的预见力。我目前担任宾夕法尼亚大学研究生教育学院的学术创新执行主任及教育高级研究员，在这里，我还运行着 Milken-GSE 商业计划竞赛并主管EDSi（教育设计工作室）。在这之前，作为Educorp 顾问公司的总经理，我向教育实体提供战略咨询；而作为WorldSage的执行副总裁，我在欧盟创造了一个全球网络的高等教育机构。曾经作为Curriki的执行主任，我建造了最具创新与健全的全球开源教育社区之一。我之前还是一家教育投资机构Core Learning的联合CEO，同时还担任bigchalk项目的首席学术官。我目前服务于几家教育公司的董事会，为教育技术公司提供前期支持。正如我们所知，我们的世界正在全力发展人工智能：Siri管理着我们的日程；Facebook向我们推荐好友；计算机帮助我们进行股票交易；汽车可以自动泊车；空中交通管制几乎是全自动化的。从军事到医疗到制造业，几乎每一个领域都得益于人工智能的进步。

然而，最近人工智能的发展几乎没有改善教育产业。为什么教育落后了呢？为什么人工智能在教育产业的推进似乎在过去几年毫无起色？

伍尔夫（Woolf）等人在AI Magazine的一期特刊中，提出了一些人工智能应用于教育产业需要解决的「巨大挑战」，包括：每一个学生的虚拟导师：将用户模型、社交模拟和知识展现整合起来的无处不在的支持。定位21世纪的技能：帮助学生掌握自我导向、自我评估、团队建设等技能。互动数据的分析：将大量有关个人学习、社交文本、学习内容和个人兴趣的数据整合起来。提供参与全球化课堂的机会：增加世界范围内课堂的互联互通。扩展生命长度与宽度的技术：将学习从课堂扩展到课外，扩展到学校之外，扩展到学生的生活之中。在过去十年，人工智能的应用已经解决了学习的几大挑战，包括语言处理、推理、计划和认知模型（Woolf，2009）。有一些计算机软件被称为智能导师系统，能够在解决问题期间跟踪学生的「心智步骤」，来确定学生对相关领域的误解并评估学生对之的理解。智能导师系统也能够向学生提供及时的指导、反馈和解释，培养学生高效的学习习惯，比如自我调节、自我监测和自我解释。

另外，智能导师系统也能够在不同等级的困难程度上设定学习活动，并提供最适合学生的学习内容。（Azevedo &amp; Hadwin, 2005; Shute, 2008; VanLehn, 2006）。这些系统可模拟一对一教学的益处，部分系统在特定主题上甚至超过了未经训练的导师，达到专业导师的水平（VanLehn, 2011）。

这些智能导师系统中值得注意的包括 Tabtor， Carnegie Learning 和 Front Row。做过的一次元分析比较了使用智能导师系统的结果与使用其他教学方法的结果，在普遍情况下，使用智能导师系统进行学习能够得到更高的分数。（Ma等，2014）。

在另一款学习应用中，人工智能能够对内容进行组织、综合进而传授。正如所知的深度学习系统，能够阅读、书写，并能模拟人类行为。比如 Scott R. Parfitt 博士的 CTI（Content Technologies, Inc.)公司的产品，能够让教育工作者综合定制的教科书内容。教育工作者导入课程，CTI的引擎转存出一份综合了核心内容的文本。&nbsp;人工智能和机器学习的进展令人印象深刻，但在使学习科学进步方面还有许多工作需要做。虽然做出一些如同上文介绍的人工智能在教育领域的应用，但这些努力和非教育领域的进展相比就显得黯然失色了。&nbsp;2015年，大多人工智能的突破都在教育领域之外。比如，亚马逊和UPS（美国快递公司）开始使用无人机为客户配送包裹和其他货物；谷歌花了大约5亿美元收购了一家英国人工智能创业公司DeepMind，为其分配了140多名计算机学家，他们做出的软件教会了它自己如何掌握49款复古视频游戏，并不断地超越人类选手；谷歌也在测试他们的无人驾驶汽车；来自康奈尔大学的机器人PR2学会了如何执行不同的小型任务，之后教会了另一个来自布朗大学的机器人Baxter如何执行这些任务；另一个机器人ConceptNet 4进行了一次智商测试，测试内容包括词汇、比较和理解，结果显示它的智商与4岁儿童持平。

我相信人工智能在逐渐发展的学习分析、课程材料质量评估、适应性学习和推荐引擎领域将会扮演重要角色。人工智能也有潜力在大型开放式网络课程、混合学习、在线学习方面为每一个学生打造独一无二的学习方法（Chaudhry, et al., 2013）。

人工智能在各种领域做出贡献的可能性都非常巨大，而教育不应该落在后面。（想要了解更多有关人工智能在这些领域的潜力，参见最近的AI Magazine上的一期特刊）；"
日报;;【日报】创新工场重点投资人工智能创新工场重点投资人工智能、Twitter十岁了、NASA向太空发送3D打印工厂，机器之心日报，精选一天前沿科技优质内容。李开复：创新工场今年要重点投资人工智能创新工场创始人兼CEO李开复日前在接受专访时表示，对于创新工场而言，今年将重点投资的领域是：文体娱乐、互联网教育、AI和智能硬件、O2O和B2B。李开复说，人工智能在未来5年会有非常多的应用爆发。从5年的时间展望会非常乐观，将有越来越多的AI辅助人类工作。李开复认为，目前AI还不会有自我意识，都是非常听话的人类仆人，长远来讲也无法预测AI什么时间点会产生意识。Twitter十年十年前，年仅29岁的程序员杰克·多西（Jack Dorsey）在一个网站敲出了“just setting up my twttr”（意为开设我的Twitter账号）并成功发送，从此，一个新时代开启了。首份《中国 VR 用户行为研究报告》出炉，居然有 2.86 亿 VR 潜在用户暴风魔镜、知萌咨询与国家广告研究院联合发布了首份《中国 VR 用户行为研究报告》 (http://pan.baidu.com/s/1c1h8uD6)。调查数据显示，15 到 39 岁人群中，听说过 VR 产品或相关知识，并且对 VR 非常感兴趣的用户，占比达 68.5%。第六次人口普查数据显示，2014 年全国 15 岁至 39 岁人口为 4.18 亿。综合上面两个数据，这个人群中 VR 潜在用户为 2.86 亿。中印美工人相信AI和机器人将能取代他们ADP Research Institute对13个国家工人的调查（PDF） 显示，中国、荷兰、印度和美国的绝大部分被调查者相信，人工智能、机器人和其它自动化技术将取代他们，或者至少是在重复性任务上取代他们。相比之下，德 国、智利、新加坡、英国和法国只有少部分工人相信AI会在重复性工作上取代他们。IBM Watson 识别照片内容的能力再进一步今年早些时候，IBM宣布其沃森人工智能有越来越高的图像识别能力。现在IBM提供了一个地址，可以让用户上传图片，来看看沃森人工智能在识别照片内容方面令人印象深刻的进展。这个网址让用户选择上传图片，或者给出图片的URL地址，它会在几秒钟之后显示识别结果。有用户使用手头的照片测试了沃森人工智能识别能力，发现沃森人工智能的准确率相当惊人。它可以弄清楚什风景照片当中的景物，动物品种甚至有什么背景。NASA下周二将发送3D打印工厂至太空2014年9月21日，NASA的首台零重力3D打印机搭乘Falcon 9火箭前往国际空间站，两个月后，完成了首个太空3D打印项目。NASA在国际空间站安装3D打印机为了测试宇航员在微重力下自主制造零部件和工具的可行性，测试的目的是将从地球向太空运送零部件和工具的次数降至最低，加快空间站的自给自足。
"机器人;;令人失望发布会上，苹果还「发布」了第一个机器人苹果现在生产机器人。更重要的是，该公司名叫Liam 的新回收机器人，可能是推动实现自动化生产iPhone的佐证。

在苹果周一略微单调的发布会上，公司展示了Liam机器人小心拆除回收iPhone的视频。这个精心制作的视频显示机器人拧开iPhone外壳，用吸盘拆除不同的电子芯片，再把外壳扔进箱子里。虽然苹果一直在自动化回收损坏手机的过程，但Liam最有趣的点不是拆手机。与之相反，它提供的是一览自动装配过程的可能性。

自动化正在快速占领中国传统上依赖低成本手工技艺的制造业，因为自2001年以来，工资正以每年12%的速度上涨，自动化可以提供竞争优势。&nbsp;为了解这种趋势，MIT科技评论的记者近期在中国走访了几家制造商，并看到他们是如何迅速地将机器人加入生产线。这种趋势不可逆装，不仅对于中国制造业，也会对全球制造业产生重大影响。

在Liam视频中看到的技术，正在各个生产阶段变得尤其普遍。例如，苹果的视频展示了相机捕捉自定义机器人手臂如何拿着拆开的iPhone，同时让另一个部件一举移除螺丝。在发布会前，苹果公司发给Mashable的视频显示，，操作过程中，有29个不同的机器人手臂在共同努力拧开，分离，钻孔，和操作旧iPhone。

苹果最大代工厂富士康也在努力推进自动化革命，该公司已经用机器人替换了上万名工人。并且开始销售自己开发的机器人作为革新的一部分。也许某一天，苹果也会为 Liam 召开一场举世瞩目的发布会。 &nbsp;&nbsp;"
"苹果;;令人失望发布会上，苹果还「发布」了第一个机器人苹果现在生产机器人。更重要的是，该公司名叫Liam 的新回收机器人，可能是推动实现自动化生产iPhone的佐证。

在苹果周一略微单调的发布会上，公司展示了Liam机器人小心拆除回收iPhone的视频。这个精心制作的视频显示机器人拧开iPhone外壳，用吸盘拆除不同的电子芯片，再把外壳扔进箱子里。虽然苹果一直在自动化回收损坏手机的过程，但Liam最有趣的点不是拆手机。与之相反，它提供的是一览自动装配过程的可能性。

自动化正在快速占领中国传统上依赖低成本手工技艺的制造业，因为自2001年以来，工资正以每年12%的速度上涨，自动化可以提供竞争优势。&nbsp;为了解这种趋势，MIT科技评论的记者近期在中国走访了几家制造商，并看到他们是如何迅速地将机器人加入生产线。这种趋势不可逆装，不仅对于中国制造业，也会对全球制造业产生重大影响。

在Liam视频中看到的技术，正在各个生产阶段变得尤其普遍。例如，苹果的视频展示了相机捕捉自定义机器人手臂如何拿着拆开的iPhone，同时让另一个部件一举移除螺丝。在发布会前，苹果公司发给Mashable的视频显示，，操作过程中，有29个不同的机器人手臂在共同努力拧开，分离，钻孔，和操作旧iPhone。

苹果最大代工厂富士康也在努力推进自动化革命，该公司已经用机器人替换了上万名工人。并且开始销售自己开发的机器人作为革新的一部分。也许某一天，苹果也会为 Liam 召开一场举世瞩目的发布会。 &nbsp;&nbsp;"
"谷歌;;谷歌人工智能的商业化应用：Inbox智能回复功能最近几年，谷歌在人工智能领域展示了令人刮目相看的能力。无论是智能相册里的自动归类组织还是谷歌文档编辑时的口头命令以及最近大出风头的Alpha Go，他可是打败了人类最顶尖的围棋手之一。使用了人工神经网络的谷歌邮件可以智能回复现在谷歌要将人工智能技术应用在浏览器版本的 Inbox。去年11月的时候，谷歌就公布了这项名叫「Smart Reply」的功能，不管你是通过浏览器还是手机应用使用谷歌简洁的邮件应用Inbox 可帮你自动回复邮件。自动回复默认是关闭的。你从中选择三个默认的回复（该功能仅支持部分邮件，并非全部支持。）而且，如果你愿意，你还可以在标星邮件、编辑或者添加文字的时候使用自动回复。浏览器版本的智能回复（Smart Reply）功能将于本周放出，约四个月后登陆安卓和 iOS 的 Inbox 应用。谷歌的神经网络功不可没，其可通过训练学习行为。在上手测试中，智能回复可区分有效邮件和垃圾邮件，前者提供一键回复，而后者没有。「人工神经网络的第一步与我们使用的垃圾邮件过滤、区分促销邮件和私人邮件的功能非常相似，」Google Brain Team 高级研究科学家 Greg Corrado 说。「我们的网络经过训练后，可预测邮件接收者是否只想简单回复。」智能回复中的一键回复经过三个步骤。智能回复扫描收件箱，决定是否需要回复，利用神经网络生成三个回复。谷歌表示工程师并不能获取邮件实际内容。Corrado 表示最终这项技术的应用远不止帮助用户优化收件箱。

「目前机器智能技术令人兴奋的部分原因在于其理念和应用原则是通用的，即使在特定的系统并不支持的情况下。（比如）智能回复背后的研究理念原本被用于提升机器翻译，而不是邮件自动回复功能。」会说话的机器人上手过程中，我看到的所有自动回复看起来都像人类回复并切中主题，令人印象深刻，但是智能回复也有局限。遇到是/否问题，智能回复表现尚可，但是碰到开放性问题，则会产生滑稽的消极应对的结果。如针对「你想吃什么？」这个问题智能回复会给出三个回复选项：「随便。」「你想吃什么？」和「我不知道。」这样的回复就显得很奇怪。面向普通消费者的产品并未针对选择性问题进行调试，Corrado 表示内部版本可以解决这些问题。比如，「你喜欢在沙拉中加芹菜还是洋蓟？」会产生不明确的回复，「随便一个都可以，」「两个都不错，」以及「你选就好。」其并没有在沙拉和洋蓟中间选一个。不过，这两个我都喜欢，也许在这里人工智能对某事很了解。「『研究级别』版本的智能回复——可说任何想说的——在大多数时候可正确回复这类问题，」Corrado 说，「不幸的是，系统的还会产生一堆其他的回答，有时令人捧腹，还不能供数百万用户稳定使用。」一些开放性的问题能得出恰当的回复。智能回复不会检索你的日历，做出选择，而是以收到的邮件为基础，做出某些决定。Corrado 解释说：「这并不是设计好的，相反，只是因为限制智能回复的权限而得出的结果。将问题抛回其他方的表达通常很简短，由此具有广泛代表性。」比如，「明天你能打电话给我吗？」可得出「当然，什么时间？」「当然可以，什么事？」以及「明天我没空。」的回复。然后重新安排日程，如「下周二怎么样？」而在日历中，我下周二有空，这让我相信 Inbox 确实在检索我的日历，但其实这只是运气罢了：「下周我都有空」和「我随时有空」这另外两个选项并不准确。虽然 Corrado 并未披露任何将日历检索整合进系统的计划，但是他表示这是他希望智能回复能实现的众多功能中的一个。写邮件回复在简单的是/否问题上，智能回复表现最好，当我收到一封邮件问题是否在一辆自行车前双手合一，蹲在地上（rap-squat），Inbox 给出了三个极富热情的回复：「不！我没有！」「是的！」和「对！确实如此！」对于相同的问题，系统也并不会给出相同的回复。随后一封重复该问题的邮件则产生了三个不同的回复：「不！我没有！」「当然！」以及一个明显的不确定回复「我认为是！」随着时间推移，系统可以从用户选择中学习，潜在的回复会更加准确。还有上下文也会影响每个自定回复的语气。Corrado 说正式或非正式的语气取决于接收到的邮件不同。有时会在非正式的回答中加上感叹号，虽然这些决定并非基于个人写作风格。「智能回复并不会将信息和个体连接起来，也不会学习个体行为，」Corrado 说，「风格匹配是人工智能研究一个活跃的领域，但是个人用户风格这一层面的个性化不会整合进智能回复——至少现在不会。」谷歌称 Inbox 移动应用上 10% 的回复都由智能回复驱动。每人都有自己的看法，这可以是技术发展的明证，或表明我们已经变得如此冷漠。Corrado 说智能回复的初衷是节省「回复简单逻辑性邮件」的时间，而不是去取代经过深思熟虑的长邮件。他也希望这能帮助用户在现实世界中争取更多时间。「我用手机回复『一会见』这类邮件的时间越短，我与朋友在街上享受散步的时间就越长，」Corrado 说。"
"人工智能应用;;谷歌人工智能的商业化应用：Inbox智能回复功能最近几年，谷歌在人工智能领域展示了令人刮目相看的能力。无论是智能相册里的自动归类组织还是谷歌文档编辑时的口头命令以及最近大出风头的Alpha Go，他可是打败了人类最顶尖的围棋手之一。使用了人工神经网络的谷歌邮件可以智能回复现在谷歌要将人工智能技术应用在浏览器版本的 Inbox。去年11月的时候，谷歌就公布了这项名叫「Smart Reply」的功能，不管你是通过浏览器还是手机应用使用谷歌简洁的邮件应用Inbox 可帮你自动回复邮件。自动回复默认是关闭的。你从中选择三个默认的回复（该功能仅支持部分邮件，并非全部支持。）而且，如果你愿意，你还可以在标星邮件、编辑或者添加文字的时候使用自动回复。浏览器版本的智能回复（Smart Reply）功能将于本周放出，约四个月后登陆安卓和 iOS 的 Inbox 应用。谷歌的神经网络功不可没，其可通过训练学习行为。在上手测试中，智能回复可区分有效邮件和垃圾邮件，前者提供一键回复，而后者没有。「人工神经网络的第一步与我们使用的垃圾邮件过滤、区分促销邮件和私人邮件的功能非常相似，」Google Brain Team 高级研究科学家 Greg Corrado 说。「我们的网络经过训练后，可预测邮件接收者是否只想简单回复。」智能回复中的一键回复经过三个步骤。智能回复扫描收件箱，决定是否需要回复，利用神经网络生成三个回复。谷歌表示工程师并不能获取邮件实际内容。Corrado 表示最终这项技术的应用远不止帮助用户优化收件箱。

「目前机器智能技术令人兴奋的部分原因在于其理念和应用原则是通用的，即使在特定的系统并不支持的情况下。（比如）智能回复背后的研究理念原本被用于提升机器翻译，而不是邮件自动回复功能。」会说话的机器人上手过程中，我看到的所有自动回复看起来都像人类回复并切中主题，令人印象深刻，但是智能回复也有局限。遇到是/否问题，智能回复表现尚可，但是碰到开放性问题，则会产生滑稽的消极应对的结果。如针对「你想吃什么？」这个问题智能回复会给出三个回复选项：「随便。」「你想吃什么？」和「我不知道。」这样的回复就显得很奇怪。面向普通消费者的产品并未针对选择性问题进行调试，Corrado 表示内部版本可以解决这些问题。比如，「你喜欢在沙拉中加芹菜还是洋蓟？」会产生不明确的回复，「随便一个都可以，」「两个都不错，」以及「你选就好。」其并没有在沙拉和洋蓟中间选一个。不过，这两个我都喜欢，也许在这里人工智能对某事很了解。「『研究级别』版本的智能回复——可说任何想说的——在大多数时候可正确回复这类问题，」Corrado 说，「不幸的是，系统的还会产生一堆其他的回答，有时令人捧腹，还不能供数百万用户稳定使用。」一些开放性的问题能得出恰当的回复。智能回复不会检索你的日历，做出选择，而是以收到的邮件为基础，做出某些决定。Corrado 解释说：「这并不是设计好的，相反，只是因为限制智能回复的权限而得出的结果。将问题抛回其他方的表达通常很简短，由此具有广泛代表性。」比如，「明天你能打电话给我吗？」可得出「当然，什么时间？」「当然可以，什么事？」以及「明天我没空。」的回复。然后重新安排日程，如「下周二怎么样？」而在日历中，我下周二有空，这让我相信 Inbox 确实在检索我的日历，但其实这只是运气罢了：「下周我都有空」和「我随时有空」这另外两个选项并不准确。虽然 Corrado 并未披露任何将日历检索整合进系统的计划，但是他表示这是他希望智能回复能实现的众多功能中的一个。写邮件回复在简单的是/否问题上，智能回复表现最好，当我收到一封邮件问题是否在一辆自行车前双手合一，蹲在地上（rap-squat），Inbox 给出了三个极富热情的回复：「不！我没有！」「是的！」和「对！确实如此！」对于相同的问题，系统也并不会给出相同的回复。随后一封重复该问题的邮件则产生了三个不同的回复：「不！我没有！」「当然！」以及一个明显的不确定回复「我认为是！」随着时间推移，系统可以从用户选择中学习，潜在的回复会更加准确。还有上下文也会影响每个自定回复的语气。Corrado 说正式或非正式的语气取决于接收到的邮件不同。有时会在非正式的回答中加上感叹号，虽然这些决定并非基于个人写作风格。「智能回复并不会将信息和个体连接起来，也不会学习个体行为，」Corrado 说，「风格匹配是人工智能研究一个活跃的领域，但是个人用户风格这一层面的个性化不会整合进智能回复——至少现在不会。」谷歌称 Inbox 移动应用上 10% 的回复都由智能回复驱动。每人都有自己的看法，这可以是技术发展的明证，或表明我们已经变得如此冷漠。Corrado 说智能回复的初衷是节省「回复简单逻辑性邮件」的时间，而不是去取代经过深思熟虑的长邮件。他也希望这能帮助用户在现实世界中争取更多时间。「我用手机回复『一会见』这类邮件的时间越短，我与朋友在街上享受散步的时间就越长，」Corrado 说。"
"深度;;Joaquin Quiñonero Candela谈机器学习Joaquin Quiñonero Candela是Facebook 机器学习应用团队的负责人。他曾在微软剑桥研究院工作，还是微软Bing团队的一员。Joaquin Quiñonero Candela 在Facebook的主要工作是与Facebook 的人工智能实验室、各产品部门紧密合作，将机器学习、语言技术，计算机视觉等技术运用到Facebook的各个产品中，并将产品反馈纳入接下来的研究中。可以说，Joaquin Quiñonero Candela的团队Facebook人工智能从实验室到产品的关键。作为横跨学术界和产业界的机器学习大拿，Candela 在Quora上回答了诸多问题，如何看待机器学习发展的现状、机器学习如何在Facebook变得如此流行以及该如何学习机器学习，这些问题都将在本文中得到解答。Facebook的机器学习团队都在做什么？机器学习应用团队是Facebook应用研究团队的一员。我们的核心工作是机器学习、计算机视觉、计算图像以及语言技术。我们和公司的人工智能研究团队紧密合作，不过相对来说我们的工作更关注应用层面。接下来，我将简单介绍一些我们团队所做的有趣事情，当然，这并非一个完整名单，也并非只是我们一个团队能完成的事情，我们也需要和人工智能团队、核心数据科学团队以及众多产品团队并肩作战。&nbsp;在计算机视觉方面，我们有一套能够处理用户上传的每张照片和每个视频的系统，每天的处理总量超过100万张（个）。利用这套系统，我们可以预测出这张照片的内容，这个用处非常大。比如帮助盲人「看到」图片、自动侦测图片上的敏感信息、提升用户搜索多媒体信息时的准确性等等。我们采用包含数十亿节点的深度卷积网络。这个模型最有趣的地方就是可普遍适用的特性。最近，Facebook的Connectivity实验室和核心数据科学团队通过这些特性，分析了海量的卫星图片，创造了一张高分辨率的世界人口密度地图。

这个团队还有很多有趣的研究，也发布了一些论文：多任务学习、强化学习形成的通用视觉模型（论文）、采用Elastic SGD与时空卷积网络训练的大规模分布式系统对视频的分析（论文）、级连算法在视觉模型的应用（论文）。&nbsp;在语言技术方面，我们正在努力做的一件事情是消除Facebook上的语言壁垒。为了实现这个目标，我们每天处理超过20亿个帖子的翻译需求，超过40个语言的翻译，翻译方向（比如英翻中、中翻英）超过1800个。过去我们采用微软bing的翻译产品，后来我们自己开发或部署相关产品。现在，我们正在讲深度学习纳入到翻译产品中，希望通过神经网络，达到人类翻译的水准。&nbsp;在机器学习和新领域，我们主要聚焦研发和使用一些大规模、实时的机器学习或人工智能算法，用到一些大型机器学习应用程序中。无论用户何时登陆Facebook，这些系统都会用来评估用户时间线上的状态更新（目前的数字为：平均每天超过10亿用户，每个用户1500个状态）、广告和搜索结果（每天的搜索请求超过10亿）、热门趋势信息、拍朋友推荐信息甚至也会评估用户收到的各种提醒以及别人的评论信息。机器学习团队同样利用深度学习打造了一系列「优雅」理解文本的算法。这些算法整合到我们打造的机器学习平台里，用于加快推进和大规模实现从训练到部署的过程。Facebook所有采用机器学习的产品都会使用这个机器学习平台。如果你想理解机器学习在Facebook有多流行，我举个简单例子吧，超过20％Facebook工程师（甚至非工程师）都是这个平台的活跃使用者。我们现在研究的方向包括用于预测事件的深度学习模型、用于稀疏模型、深度学习的分布式复习系统、通过卷积和递归网络进行文本理解的表征学习以及通过多任务学习的模型压缩。关于学习：你学习机器学习的途径是什么？在学习机器学习时，你最喜欢哪一本书？我最初接触机器学习，是在我作为一位电信工程本科生学习高等非线性信号处理的时候。那是在1995至2000年。我非常幸运地拥有一位很赞的导师，他在个人信息在 Prof. Anibal Figueiras-Vidal这网站上。他解释到你可以怎样使用神经网络构建自适应的、受训于观察到的数据的非线性过滤器。于是，我就入坑了！&nbsp;我写的硕士论文是关于稀疏的径向基函数分类器。在那时，支持向量机风行一时，它似乎就像稀疏性是模型为了提高广泛性而应该具备的合乎要求的性质。我还记得你总是会评估你根据UCI repository的数据集创造出的算法。有趣的是在我们后来的学术生涯里，我警告过不谨慎使用稀疏模型的缺点（见see the dangerous uses of sparse Gaussian Process priors），并且我曾在行业里寻求一份gogn zuo，以能生成由机器学习应用程序产生的新的有趣数据。

如果我不得不指出一本非常有影响力的书，那就是 Chris Bishop’的第一本书： Neural Networks for Pattern Recognition (1995)。其中第十章「贝叶斯技术」真的很对我的胃口，也是我至今仍对贝叶斯倾注热情的产物。然而正如我经常所说的，「一位真正的贝叶斯派不可能彻底是贝叶斯派：你需要优先保留一些余地，因为有可能贝叶斯方法不是正确的。」

在我花了6个月时间拜访丹麦科技大学时，我非常幸运地在2000年偶然碰上 Prof. Carl E. Rasmussen 。Carl是一位贝叶斯派，向我介绍了神经网络的贝叶斯处理方法和针对近似推理的蒙特卡洛马尔科夫链抽样方法。他也向我介绍了高斯过程，我写的论文就是关于这个。我最后回到了丹麦，在Carl的指导下攻读博士。&nbsp;这些天，我会犹豫要不要给人们指出特定的书（有太多杰出的书了）。我坚持建议人们观看视频演讲。如果你在YouTube上搜索你想了解的任何主题，你将发现由顶尖学校的一流教授提供的丰富的视频演讲。给你一个具体的例子：我最近需要掌握更多计算图像学知识，找到了Bill Freeman的很赞的入门介绍。我最近还想综述自然语言处理的简介，就找到了Dan Jurafsky 和 Chris Manning的很赞的入门级讲座。&nbsp;如果你坚持读下去，这里是一本极大地激励了我的书，是Jaynes的《概率论：科学的逻辑》（这里是供你阅读的pdf版本： pdf version）那本书提倡使用概率论作为科学推理的语言，在我们如何探讨概率推理方面给人很大的启发，也对机器学习非常重要，而且近来这些天当我们思考人工智能的未来时，也会从这本书获得相关联的哲学启发。&nbsp;我也会鼓励人们立刻动手。如果你是Matlab用户（我以前是！）或者使用Python（当然你会用的），有许多应用程序包基本上是实现所有事情。然而对于很多算法而言，你可以编写你自己的程序工具，那是你真正要学的。团队招人时，你看中的是什么？我看中的是技术实力和性格。寻找的人是这样的：任务驱动型的。人们需要完全投入最终目标。适应不确定性。无私与合作。ML黑客。强大的背景条件。在应用机器学习中，什么是更重要的：数据，基础架构还是算法？首先让我们确定目标：在应用机器学习中，成功意味着将机器学习系统对实际应用的影响最大化。例如，通过我们的广告排名系统将拍卖的总额最大化，广告排名系统是由机器学习系统驱动的，能预测广告与受众的关联程度。拍卖价值将被两件事积极影响：预测的准确性。候选广告的数量。候选广告能通过大多数精确的预测器（经典的是严格的延迟约束器，能更快的激活级联途径，是通过更不精确的预测器精选候选广告）来估价。我们需要将精确度最大化，同时将在服务时间进行预测的计算工作量最小化。让我们现在聚焦于最大化预测精确度。机器学习系统典型地有一个实验组件，旨在设计和训练模型。我们已经发现最重要的属性是实验速度。一个团队能在单位时间内完成的实验越多，他们就能取得更大的进步，建立更好的模型。我们努力应用机器学习，一直以来遵循「每周扬帆前行」的口号，做出了伟大的成果。为了每周至少能给特定应用输送一个生产模型，你需要管理几十个现场实验，每周执行成百上千的线下试验。极佳的基础架构、平台和工具对应用机器学习是必不可少的，既要最大化实验速度，又要最小化在服务时间的预测成本。&nbsp;现在，让我们转向数据和算法问题。我们的哲学理念将问题分出了轻重缓急，下面是按重要性从高到低排列：数据：尽你所能地得到大量数据，确保这些数据是最高质量的。就我们的经验而言，数据会以出乎意料的、不同寻常的方式变得杂乱。我最喜欢的一个故事是，快速重复点击以增加impression（译者注：impression是网站分析的最基本度量之一），这偶然不会起作用，因为存在一个假设是点击被报告给处理impressions的同样的数据中心。特征工程：做大量的和它有关的事。提取你的数据，浓缩为有最大化预测力的信号。构建尽可能自动化的工具（自动化特征选择时常在后台运作，保持CPU的效用最大化）。我必须强调深度学习的来临正改变者游戏：当使用更简单的算法特征工程是关键的时，深度学习的承诺是它允许自动化地学习表征（例如特征）和你能馈送给它原始数据。一些明显的例子是DeepMind的令人惊讶的工作，也就是纯粹基于屏幕上的像素学习玩耍经典的街机游戏，而没有做任何特征工程。深度学习通过自动学习表征也已经引发了计算时间和语言技术的革命。还是那样，在实际应用中，依赖机器学习的产品团队定期通过特征工程仍有重大收获算法：一旦你拥有了针对特征工程的最棒的数据和工具，就要保持提升你的算法能力（同时要保证这些算法是广泛推广的）。在Facebook，我们定期输送新的具备更大生产能力的模型，但是值得注意的是，只有当训练数据的数量一路增长，而且表现力（包括训练和在服务时间的预测）没有退化得太多以致于抵消了增长的精确度带来的益处时，这才有意义。我们总是将来自更复杂模型的精度收益与在做预测时增加的CPU成本相比较。这意味着我们经常使用最简单的可以完成工作的模型（从计算效率角度来说）。总结：在应用机器学习中基础加工是至关重要的。然后，你应该聚焦于拥有尽可能是最好的数据，做大量的特征工程和使用最简单的能完成工作的算法。深度学习如何影响 Facebook 今天的产品？2012年基于深度神经网络的方法在 ImageNet 分类比赛中获胜之后，深度学习引起了很大的反响。神经网络已经在机器学习中应用了相当一段时间，但具备更大容量和远远更多数据的深度神经网络带来了变革并显著击败了其它较浅的模型。这一运动开始于计算机视觉，并快速扩张到了文本理解、机器翻译和语音识别领域。&nbsp;Facebook 拥有一个单一的使命：创造一个更加开放和互联的世界。随着我们开发出让人们可以分享更多的工具和产品，理解用户的内容并向他们提供最大的价值就变得越来越重要。这意味着，高准确度（精度和回调）、低延迟和更快速的创新。深度学习在所有这些方面影响我们的产品。它被用于文本、音频、照片、视频甚至交互的内容理解中。嵌入式的深度学习被无缝整合到许多产品组中，这使得他们能更专注于核心产品，同时又指望我们团队（机器学习应用产品组）提供可用于多种任务的可能最好的嵌入产品。&nbsp;除了提供嵌入产品，深度学习也在被应用在一些端到端产品中，如用于视频字幕的自动语音识别、为盲人配音的核心视觉识别引擎、让你可以将数百种语言翻译成英语的机器翻译。为什么 Facebook 要投资（大量）人工智能/机器学习？没有人工智能/机器学习，Facebook 就不能存在。

人工智能是 Facebook 已有的工程工作的自然延伸，这是向我们的社区提供好体验的关键部分。每天，这个世界都在产生越来越多的数据——文本、图片、视频等等。为了做到有用，我们需要帮助你梳理所有这些信息，这样你就可以看到你想看到的内容，并更高效地和他人交流。&nbsp;回答这一问题以及有关人工智能和机器学习领域更多具体应用研究工作，请见：What are the most interesting things Facebook is doing in ML research?你怎么看待当前深度学习上的炒作？我不认为这是炒作。&nbsp;人们已经在它上面进行了几十年坚持不懈的努力，但有有意义的先验的非常庞大而复杂的神经网络释放了表征学习（RL：representation learning）的力量，得到的结果极其优于那些通过手动输入特征和传统算法的结果。正如Yoshua Bengio 和 Yann LeCun 在他们最近的 NIPS 2015 教程中解释的那样，算力与训练数据的数量和质量的急剧增长是表征学习和深度学习成功的关键。&nbsp;回到表征学习上，它是真实的。过去几年这方面已有许多最新的突破性进展可以归功于表征学习。这些都已经在计算机视觉、语音识别、自然语言处理等领域实现。所有这些领域都拥有一个特征：输入信号是传感器信号。表征学习使用深度神经网络（DNN）架构学习这些传感信号的分层特征表征。这些表征最后表现得比人类施工的和高度精制的功能好非常多。那并不是关键，但这样的架构远远地近似于人类大脑中学习和执行认知任务的方式。&nbsp;比如在Facebook，我的朋友和同事 Ahmad Abdulkader 与我们的广告团队合作开发了能够自动检测出违反我们政策（例如包含暴力、酒精或武器）的有图片广告。在这一任务上使用深度学习在精度上带来了显著的提高，并最终保护了Facebook 社区免受潜在的不良内容的影响。我们的计算机视觉团队已经开发了一个供几十个团队使用的自助服务平台，以帮助他们在通过使用深度学习学到的图像和视频的表征的基础上训练专门的预测模型。Manohar Paluri 可以告诉你更多有关 Facebook 用于计算机视觉的深度学习应用。&nbsp;表征学习也还有一些尚未取得突破的领域，尤其是那些输入不是传感信号的领域。它是否还能取得那样的突破，尚有待观察。

说到这么多，学术界、业界和媒体需要谨慎对待夸大的结果、对可能带给机器的「智能」式未来的过度解读、以及机器是否以某种方式取代人类的严重后果的警告。这更接近科幻而不是现实 :)为大型公司制作可通用机器学习框架所带来的重要经验有哪些？打造通用机器学习框架很艰难。机器学习与人工智能如今进展层出不穷。这让任何通用机器学习框架不停地处在测试之下，甚至许多都已经废弃。另外，灵活性与规模以及灵活性和可用性与之间一直有着强烈的压力。这些都是一个总体框架所有需要考虑的重要权衡。&nbsp;在下面我会分享一些我们在制作Flow的时候的学习经验——也就是我们的通用的机器学习系统。工程师利用Flow去制作机器学习通道，以训练深度学习模型、大规模逻辑回归、决策树等等。Facebook的所有这些模型每周都会从实验环境部署到生产环境进行数次，并且被Facebook的很多团队调用。深入理解你的应用场景：许多通用机器学习框架经常会突出强调某一个场景。在Flow，我们理解我们有两个主要的观众。其中一个写出新的通道，另一个通过添加新数据来消耗它们。我们确定了我们为这些场景中的每一个都提供了良好的体验。打造多层平台：良好的平台会从「use it all」和「lose it all」等场景中保护它们的用户，好的假期会提供很多抽象层。最外层提供最好的经验，但是如果用户不知道他们到底想要什么，他们应该降低级别去达到想要的。速度，速度，速度！对于企业中的机器学习研究，让你设计的想法得到支持和许可都必须在保证速度的前提下。数据经常会很巨大，并带来降低创新的瓶颈。默认可重用：无论何时工程师在Flow写了新的东西，都可以被公司里的其他人所重新利用。这意味着工程师有着超越以前的指数式增长的创新力。准备写第二个版本吧：如果这是你的平台第一个版本，准备好去重新写一个吧，因为这里面隐藏着许多错误和坏的概念。不停地探索直至你认为这是个正确的时机去进行重写，但是在这之前要确保你进行了足够的讨论和探索，比如要达到更好的架构。避免过早推广：在你尝试将产品通用化之前，确保你有2到3个具体的重度使用场景。如果你在未成熟的时候就通用化，你也许会失去一些重要的价值，减慢发展速度。记住，如果这是你的第一个版本，你总会需要重写的，因此千万不要提前通用化。做一个算法不可知论者：机器学习经常会着眼于一个或另一个机器学习算法。在Flow，我们决定在这个平台上「欢迎所有的算法」。我们支持并创造了几个可用于Facebook的算法。但是平台是对所有算法公开的，因此可帮助Flow通用于任何出现的新算法。统一带来的好处：算法的多样性是极度有利的。也就是说，一个统一连接这些算法的系统会非常强大。比如你研发了一个算法，且这个算法对于广告和搜索结果展示具有神奇的效果，

接着你可以执行一个Flow的有着标准化界面的算法算子（广告和搜索排行通道都调用了这个算子），结果是它会变得更好。再比如你已经研发了这个算法更强力的版本，不需做太多改变，你就可以用所有通道上的新算法进行实验，调用算子并方便地使用它。由此，我们的应用研究员可以将它们的影响力迅速扩大至整个公司。如果你的余生只能够用一个机器学习算法，你会选择哪一个？我真希望我身在能够回答这个问题的时候！解决机器学习的问题仍然需要人类在整个进程中绝对的参与：制定机器学习任务、定义度量以进行优化、预测数量、评估可用数据和收集附加数据，选择适合于手头的预测任务的模型池中的模型。当然，然后还会有计算有效性的考虑。如果模型需要作为机器学习的一部分在生产中运行，边际计算复杂度所附加的任何精确性都必须超过附加成本的消耗。换句话说，精确度不仅仅是唯一的标准：计算成本也是重要的一个。

我在剑桥大学的朋友与前同事所做出的一个令人振奋的努力正是我希望机器学习所前进的方向。他们的想法是自动化数据分析。另一个激动人心的方向则是ICML2015工作室所激发的「Auto ML」趋势，后者旨在尽可能自动化人类在机器学习中的参与。

没有任何理由能够说明，我们不能创造一个基于模型和预测任务的自动化数据分析和机器学习的人工智能。&nbsp;在一个更有趣的发现中，我逐渐开始使用许多模型中的高斯法和贝叶斯法，如果后期和预测分布难以实现时，这些方法可以利用MCMC以获得近似推理。我的兴趣仍然在于利用这些模型以及推理方法。尽管这并没有让它们成为我会在余生中唯一使用的算法，但是它们一定是很有趣的算法，并且回馈以大量的智力乐趣。产业领域里的机器学习研究和学术领域的机器学习研究，有什么不同？产业和学术领域的机器学习研究，很多相同点和不同点。我近十年来都在产业领域工作，因此，接下来的观点将更多地受到产业观点影响（多过学术领域）。不过，需要注意的是，我和学术领域保持着密切联系，也欣赏我们团队发表的论文，热衷组织和参与研讨会和会议。&nbsp;现在谈观点：&nbsp;数据：产业领域接触到的数据通常比学术领域多得多。不过，随着互联网的发展，这种差异在日益减少，但还是有一定差距。这也意味着学术机构的研究侧重于小规模的数据集，无法反映产业需要的解决问题。不过硬币的另一面则是，这些小数据集可以更方便迭代，从而帮助学术机构更快地获取研究灵感。

工具和基础设施：企业能够投入更多资源构建工具，能够保证在应对大规模需求时还能快速进行原型设计。在企业里，你可以更方便低于工程师和机基础设施专家合作，他们将帮助你搭建一个更坚固的研究基础平台。大量稳定的工具也可以保证你的研究可以快速移植。&nbsp;速度：对产业领域来说，时间就是金钱，因此速度非常重要。这里的工程师和研究人员通常会优先考虑速度和产品部署的频率，因为一个产品的目标就是一段时间内，在总体上最大化产品的影响。更快的迭代可以让你探索更多新的可能性并忽略一些没有承诺的开发方向。&nbsp;目标驱动力：产业研究有着非常明确的目标驱动力。这就是通过实现研究的商业化，来进一步推动产业对于研究的投入。在可落地实施的范围而后，综合考虑成本以及如何与现有产品体验的融合，是产业对于创新和研究投入的重要考量点。这里必须要提到一点，研究机构在创新方面的重要作用，由于产业倾向于一些短期技术的研究，研究机构承担了大量颠覆性技术的研发和创新。&nbsp;简单：在学术界，发表论文是主要的衡量成功的方式。论文作为一种强制作用，以一种结构化方式帮助新观点产生效果，也鼓励了那些在实践中运行良好的新奇事物。产业界往往在简单的一面犯错，因为大规模操控复杂系统是花费不菲的。&nbsp;对上述事情持非黑即白的观点总是错误的，因为在产业领域有一些让人惊羡的研究者，在学术界也有令人佩服的工程师，这使得不同领域的重大突破成为可能。理想的化学组合是产业和学术共同合作，取其所长，推进领域发展。你如何在工作日程中安排长跑？我每年跑几次马拉松和超级马拉松。也喜欢和朋友跑步。&nbsp;这些天我平均一周跑50多英里，让跑步和工作安排不冲突的方法就是很早起来跑步。几乎每天，我都是在日出左右开始跑步，有时从家里开始，有时和一些爱跑步和喜欢早期的同事从单位开始跑。我们在工作地点淋浴，而且我喜欢跑步后在公司吃早餐。&nbsp;清晨跑步，首先对我来说是有利的，完全清理了我的内心，这有点像冥想，然后我以宁静、安详的状态开始这一天。许多问题在前天晚上看上去似乎很可怕，跑完后，似乎完全在掌控中。对励志在产业领域从事ML/CV研究的PhD候选人，给予一些指导。为产业研究职位做准备的一条最佳方法是，当一次或更多次的暑期实习生。这会让你走出只需要做论文研究的学校氛围，进入这样一个环境，其中，影响力、快速成型和与其他团队深入交往不仅普遍而且重要。&nbsp;产业实习生允许你与其他有经验的导师工作，得到广泛经验，学到更多技术。有时，实习经历只会写入你未来的出版物中，但是，有时你将对一个重要的新功能或能力做出贡献。提前询问实习机会，这对你很重要。&nbsp;在实习期间，还有在学术研究期间，你会在扎实的软件工程实践中变得熟练。一条途径是使用和贡献开源软件。你的同辈将给你反馈你的代码质量和可用性如何。试着在团队中做一些你的研究。产业研究很少独立完成，因为有太多外部因素需要团结合作去创造真正的影响力（例如：输送新性能或产品）。试着做一些项目，所以你能得以拓展你的科技知识。最后，就你的工作向大量听众举办大量演讲，一些听众可能不是你专长领域内的人。但能推销你的工作给非专业领域内的人（包括非专业领域的导师），对你成功的产业研究至关重要。

如果你打算追求学术生涯（终身教授职位），那么在某个主题上非常专业且在某个理论上很善长，而不是精通动手操作和实验，这是非常好的，但这对于大多数产业研究职位而言，并非特别有用。你如何看待开放人工智能？我们欢迎他们来到这一社区，期待看到研究进展以及它们的最终回馈。&nbsp;不过，我会补充说，我们取得的人工智能进展，现在已经是一个非常公开的过程。科学研究力求研究者的交流促进。互动社区越大，进步也就越快。&nbsp;在Facebook，我们想要让人工智能研究者更容易分享方法和技术。我们有一个大体上支持开源软件和硬件的文化，而且FAIR（Facebook人工智能研究）和AML（应用机器学习）已经继续兑这一文化承诺：以学术论文的形式发表他们的发现，开放网站上可免费获取。我们绝大多数的项目代码成为开放资源，最近也开放了一个人工智能硬件设计。对机器学习非常陌生的工程师/学生而言，什么才是最关键的？机器学习包含非常广（且深的）科学和工程学科子集。所以想通透了解该领域就要花费点时间，需要常年累月持续学习，特别是当新算法和想法正不断被研究时。&nbsp;在某种程度上，机器学习类似于统计数据，试图从大量数据中推断出结论或者模式。但另一方面，它更像计算机科学，需求高效的算法和表达方式。&nbsp;我个人最喜欢的是Chris Bishop的《 Pattern Neural Networks for Pattern Recognition 》。当然，还有一些其他很棒的书，包括来自Coursera, Udacity, edX等的在线课程。但是，如果自己不做很多实验，几乎不可能学会机器学习。&nbsp;尝试书本或者讲座上布置的练习，花些时间。貌似投入很多，但是，如果你想长期呆在这个领域，你需要积累很多知识和直觉，知道适合每个问题的技巧和方法。你也要持续学习，因此，获取学习新材料才能然后吸收之并付诸实践会非常重要。&nbsp;变得精通合适的实验和证实方法。在某些工程领域，你可以遵循指导手册或者通过非形式推理验证正确性。在机器学习中，「正确答案」往往很少。因为你所做的就是从不完全信息中做出最好的推断（打趣地说法就是「做出最好的猜想」）。你不仅要设计出综合数据的单元测试，挑出代码中明显的bug，还要在更大的数据集中不断测试。这是一个非常大的挑战，因为得到正确答案非常的难（这叫做标记数据）。 &nbsp;最后，紧跟最新研究，积极参加这个领域的年会。如果你刚步入这一领域，这是一种非常棒的方法了解这一领域的研究和技术深度。（年会往往会有很好的导师会议）如果你有经验，你可以借此建立与研究人员和从业者的社交网络，从而了解最新的技术和科研成果。Facebook机器学习团队不招非PhD？不，并非如此。虽然在多数情况下，PhD能帮助你学习如何做研究。Facebook的每个团队都有非PhD的人做机器学习，方向都不同。&nbsp;我们想知道，诸如Facebook有先进的机器学习算法的地方，是否还需要一些更加简单的算法？&nbsp;在Facebook中，我们尽可能用最简单的算法完成工作。如果预测精度有效，简单的算法就意味着更低的计算成本和更简单的调试。同时，创造性的简单算法也可能惊人的准确。在我们有关广告数据实验的论文中，我们对这些结果做过解释。&nbsp;就像我的朋友艾哈迈德·阿卜杜尔卡达尔(Ahmad Abdulkader)说的，「总有对更简单算法的需求。」事实上，更加简单算法比复杂算法更受人推崇。复杂算法总是要靠准确性的大幅度提升予以合理化。&nbsp;也有一些领域，更简单的算法也受到欢迎，即使它们的准确性不如复杂算法。比如，较之复杂算法，在很多机器上分布一个LR学习算法要容易地多。结果，LR胜出。&nbsp;简单的说，我们在需要时才用复杂算法：一些实例应用的领域，比如计算机视觉、机器翻译、文本理解和语言认知等。在这些领域，深度神经网络在预测准确性上有大步提升，所以使用它们无可厚非。在Facebook，有哪些不明显使用机器学习的地方？在《What are the most interesting things Facebook is doing in ML research?》中，我曾经给出过几个明显或不明显使用机器学习的例子。

我分享一个可能不那么明显的使用机器学习的例子。&nbsp;Facebook的 Accessibility team已经运作四年了，最初是专注于让Facebook已有产品让每个人都能使用。但是现在，它专注于为残障人士打造新产品。这个团队关注的一个对象就是盲人和视力丧失群体。因为Facebook是一种视觉上的体验（如同大部分互联网），我们需要尽可能的在创新上做投资，让Facebook的体验更好。我们在AI领域，以及诸如物体识别这些计算机视觉特定领域的投资，能够让更多人接触到科技。你的生活平衡地很好，如何做到的？哇，这个问题的前提假设是我已经很好地平衡了我的生活！:-)

我不断地尝试平衡我的生活。有三件是对我很重要：我的家庭我的工作保持身体上的健康我觉得关键词是效率。依靠「习惯的力量」让我变得有效率。每天早晨我都会按固定路线跑步，有时会和朋友一起跑。同样的跑步习惯（时间、地点）让我们不需要花费时间做计划。在家里，我和妻子会提前协调好家庭与工作时间，避免突发事件。&nbsp;最后，我认为抽时间做计划是很重要的。为了看到更远的场景，后退一步是有必要的。你想要什么？什么事你会高兴的拒绝？（为了得到重要的一些东西，对很多事你都要说no。)你会怎么描述Facebook文化？我在这里工作最喜欢的就是Facebook的文化。我经常把我们的文化和价值观分享给新职员。&nbsp;我们的价值观很好的体现到了我们的文化：建立社会价值观：我们是一家任务非常明确的公司。我们每天早上来到这里工作不只是为了让这个世界更加的开放与连接，而是为了在人类生活中创造价值。在Facebook中有个团体叫「Go 365!」我就是这个帮助、鼓励跑步新手的团体中的一员。我加入两年了，总能见到队员对马拉松新手的鼓励和支持。快速行动：我们是建造者（builder）文化。我们会尝试、会思索。我们也会犯错误，事实上我们也鼓励犯错。你如何进步？我看到很多很棒的系统在快速力量驱动下成长起来。如果它们值得构建，我们会重点查看缺陷之处，往最佳的方向改善。大胆：「最大的危险是不冒危险。」有一个有趣的不对称现象，我们人类倾向于高估我们不了解的现状。这是棘手的，因为我们周围的世界变化得太快，而且我们目前的解决方案、产品或系统可能在新环境中不再有关联或是最适宜的。引用一个我欣赏的例子，Amazon的几年前做出大胆举动，大举投资Kindle。这个产品直接地攻击了他们既有的商业模式。保持开放：这可能是我最爱的价值观。保持开放帮助我们利用集体智慧，因为没有人有所有的答案。它也帮助减少意外，增加信任（记住，「意外是信任的敌人」）。最后，一个开放的反馈式的文化帮助每个人得到提升，变得更好。关注影响力：总是有很多事情要去关注，但是就像大自然教给我们的一样的，将我们投入的大量精力的影响力最大化，非常重要。在Facebook，我们努力建立自下而上的文化，每个人都感到有责任理解围绕他们的影响力在哪里，并将自己的工作朝向它。最后，在Facebook，我们有一种「传播爱（ship love）」的文化，这是一种方式，说出我们在这里服务于15亿依赖我们构建工具和产品的社区。如果我们不爱这些人，我们不可能为他们服务。有了H2O.ai（用于商业引擎的人工智能）、Azure机器学习、数据机器人，你如何看待机器学习大众化浪潮？许多研究表明，机器学习工程师/研究员供需存在巨大缺口。一些人甚至预期这个缺口将继续扩大直到2019年。结果，机器学习「大众化」的努力可能造成巨大的影响，而且对这些工具而言，也可能意味着巨大商机。&nbsp;现有的成套工具似乎早已意欲达到这样的平民化。他们倾向于将重点放在帮助数据科学家达到他们的目标，主要是在企业环境里。&nbsp;在Facebook，我们在 AutoML这个方向做出了认真的努力。AutoML也是在许多机器学习领域（ICML，CodaLab等）获得了大量关注。这似乎是更有前途的方向，而且我的朋友和同事Ahmad Abductkader正积极地与我们的一些产品小组合作，致力于让国内机器学习大众化，尤其是帮助新的小型团队落地机器学习。Facebook 的各种应用中使用了怎样的神经网络拓扑结构：有多少层，等等？在Facebook，我们的目标是用最好的人工智能技术驱动产品。最好的有时候就是已经存在的，很多时候都是我们内部为 Facebook 量身定制的。有时候我所在团队（机器学习应用组，我们的应用研究机构）和 Facebook 的人工智能研究组（FAIR）肩并肩合作，我们也与我们的产品团队有密切的合作。&nbsp;我们使用的神经网络拓扑结构和我们在各自领域首次展示中所发布的类似。它们根据应用的不同存在差异，基本上都是深度卷积网络、全连接网络和递归神经网络。在基于文本、照片和视频、语音等应用上，我们也使用它们的组合。

我们的这些团队必须解决许多有趣的挑战。比如，我们通常将我们的数据视作一种流，而不是将其看作是几百万个样本的静态数据集。这让我们能够随时间学习更大的模型，拓扑结构也随之不断进化。另一个有趣的挑战是可能最好的模型也许并不是大规模运行时可行的模型。所以，我们总是会在模型的容量和计算与精度之间进行权衡。&nbsp;我们已经公布了各种研究结果，并且我们对组成链式或树状的多个模型的拓扑结构非常感兴趣，在这样的结构中，更快但精度更低的模型先运行，然后再给更慢但更精确的评估数据的子集的模型让路。这是一个正在进行中的研究课题，也是一个我们因为我们的数据规模而必须要解决的重要问题。另一个例子是视频，在这一应用中，可以应用基于图像的模型，我们可以使用一个连续的模型融合来自视频帧的信息，或我们可以慢慢地使用空间-时间卷积融合时间和空间信息。&nbsp;我们发表了使用这样的网络的学习功能上的发现，并展示了其通用化的能力。总之，随着我们研究越来越多并尝试找到精度、速度和内存之间的平衡，我们的拓扑结构也一直在不停变化；而我们也将积极公布这些发现。毕业之后有哪些好的机器学习课程可以参加？http://videolectures.net/是一个很赞的资源，上面有很多关于「机器学习」、「人工智能」、「大数据」、「计算机视觉」、「自然语言处理」以及更多与机器学习相近的主题。&nbsp;Udacity 和 Coursera 提供了完整成熟的课程，一个人可以以有限的知识开始一个领域的学习并在课程结束后取得相当的进步。我个人很喜欢吴恩达、Jeff Hinton 和 Daphne Koller 教授的课程，但我确信随着深度学习和机器学习在业界变得越来越重要，这些课程设置也在不断进化，资源也在不断增长。我问了问我们团队其他人最喜欢的课程，我的朋友和同事 Manohar Paluri 向我指出，比如说，乔治亚理工大学在线课程Pushkar Kolhe 和 Charles Isbell 与 Udacity 联合教授覆盖了机器学习的基础知识。&nbsp;爽的是大多数/所有这些资源都是免费的！在学习这些视频时，另外还很重要的是要亲自动手鼓捣代码，看这些东西是如何运作的。鉴于Torch、Caffe、Theano、TensorFlow这些工具已经可供下载，而且同时支持GPU和CPU，实验就是很简单的事情了。深入到这些代码中始终是快速学习的好方法。你怎么看待对话引擎（conversational engine）的未来？对于对话和口语接口来说，现在是一个激动人心的时刻。但还仍然非常早期。Siri 和 Cortana 这样的个人助手提供了简单的任务完成和搜索引擎和自然接口。对于 Facebook，我们相信大机会在人们与 Facebook 本身的交互之中。如果你想想人们使用 Facebook 的方式，这里每天都发生着数百万计的多路对话。使用对话理解和会话技术，Facebook 自己可能就能参与到这些对话中，而不只是被动地协助他们；我们还希望通过挖掘存储在 Facebook 图片库中的海量知识来增加价值。

如果你对 Facebook 的对话引擎和语言技术感兴趣，你可以在 Quora 上关注我的朋友和同事 Alan Packer.Facebook 目前怎么使用计算机视觉，又计划在未来怎么使用它？最近几年 Facebook 上的媒体内容分享和消费出现了巨大的增长。人们从文本转向了照片，而且从照片转向视频的过程正在进行，而且我们已经看见了虚拟现实/增强现实的影子。过渡到照片标志着计算机视觉作为一种重要工具的出现，而且随着我们转向视频和虚拟现实/增强现实，计算机视觉的发展动力还在不断快速增长。计算机视觉将在理解这些内容的公司中扮演至关重要的角色。它将不只能帮助理解，还能提供更加丰富和更具创造力的方式来分享你的经历（视频防抖、实时美颜等）。&nbsp;目前，有许多产品组使用了由计算机视觉系统提供的技术。这项技术被用于更好的搜索、用于辅助的图像字幕、打击垃圾和不良内容、筛选出违反我们政策的广告给人工审核、制作人口密度图、确定 Instagram 趋势、检测纪念日和重要时刻相似的照片等。每一个接触照片、视频和虚拟现实/增强现实的产品组都会利用来自计算机视觉组的信号。&nbsp;计算机视觉未来也将在 Facebook 及其各种产品的使用中发挥巨大的作用。想象一个简单的例子：我们向部分人开放了视频直播并已经取得了良好的使用。当我们将其开放给我们网络上的十多亿人时，将会出现数百万个并行的频道。这种信息爆炸意味着让用户能在相似的频道间切换和基于文本搜索直播视频等是非常重要的。&nbsp;Facebook 的本地搜索由人们的经历驱动，我们可以很出色地完成给出旅行、餐厅和周边事物的个性化建议的工作。围绕这一工作的大部分内容都是照片和视频。下一代虚拟现实可以使用由内而外的跟踪，这是计算机视觉的核心问题。随着计算机视觉越来越好，随着我们了解照片和视频中内容并开发出强大的视觉表征，我们将有能力推动目前甚至还没在 Facebook 平台上出现的新领域。&nbsp;如果你想询问关于计算机视觉及其在 Facebook 应用的具体问题，可以试试在 Quora 上向我的朋友兼同事 Manohar Paluri 提问！&nbsp;我们以前使用的是微软必应翻译服务，但最近我们已经使用我们自己的数据训练的自己的机器翻译技术进行了替代。我们这么做的主要原因是我们发现 Facebook 帖子和评论的语言与其它网络都不同：它非常俚语化，非常区域化，是非正式的人与人之间的交流而非文件或专业写作。所以，调整这项技术适应 Facebook 的语言并训练我们自己的数据让我们可以开发出更为精准的机器翻译。Facebook 怎么识别照片中的人？当你将照片上传到 Facebook 时，我们专门的面部识别服务器会将其选出进行处理。&nbsp;第一步是定位图像中所有的脸（也被称作人脸检测）。这一步的结果是一组线条框将每张脸圈了起来，非常类似于我们网站上作为标记体验的一部分的标记框。现在我们知道了图像中所有脸的具体位置，我们继续第 2 步——识别。

对每一张脸我们运行专门为这一任务训练的机器学习神经网络。这一网络会为每张脸输出一个数字表示。一种思考这种表示的好方法是将其作为高维空间中的一个点（坐标列表）。一个好的表示方法可以将同一个人的不同面部照片映射到这一空间中的同一区域，同时还能保持这些区域（其中每一个都代表不同的个体）之间很远的间隔。我们实际上为每一个人都创建了一个专门的模型，这样我们可以快速确定一张给出的新面部照片是该位于这个区域之内还是之外。&nbsp;最后一步是收集你和你朋友所有可用的面部识别模型，然后将上传的照片中每一张脸的上述表示和这些模型进行比较，然后选出最佳匹配的候选标签作为你的标记建议。所有这些处理在上传后很快就完成了，足够及时让你在写你的帖子时看到这些标记建议。

如果你想了解更多关于 Facebook 的面部识别的信息和我们接下来的开发计划，可以试试在 Quora 上向我的朋友兼同事 Tommer Leyvand 提问。"
"机器学习;;Joaquin Quiñonero Candela谈机器学习Joaquin Quiñonero Candela是Facebook 机器学习应用团队的负责人。他曾在微软剑桥研究院工作，还是微软Bing团队的一员。Joaquin Quiñonero Candela 在Facebook的主要工作是与Facebook 的人工智能实验室、各产品部门紧密合作，将机器学习、语言技术，计算机视觉等技术运用到Facebook的各个产品中，并将产品反馈纳入接下来的研究中。可以说，Joaquin Quiñonero Candela的团队Facebook人工智能从实验室到产品的关键。作为横跨学术界和产业界的机器学习大拿，Candela 在Quora上回答了诸多问题，如何看待机器学习发展的现状、机器学习如何在Facebook变得如此流行以及该如何学习机器学习，这些问题都将在本文中得到解答。Facebook的机器学习团队都在做什么？机器学习应用团队是Facebook应用研究团队的一员。我们的核心工作是机器学习、计算机视觉、计算图像以及语言技术。我们和公司的人工智能研究团队紧密合作，不过相对来说我们的工作更关注应用层面。接下来，我将简单介绍一些我们团队所做的有趣事情，当然，这并非一个完整名单，也并非只是我们一个团队能完成的事情，我们也需要和人工智能团队、核心数据科学团队以及众多产品团队并肩作战。&nbsp;在计算机视觉方面，我们有一套能够处理用户上传的每张照片和每个视频的系统，每天的处理总量超过100万张（个）。利用这套系统，我们可以预测出这张照片的内容，这个用处非常大。比如帮助盲人「看到」图片、自动侦测图片上的敏感信息、提升用户搜索多媒体信息时的准确性等等。我们采用包含数十亿节点的深度卷积网络。这个模型最有趣的地方就是可普遍适用的特性。最近，Facebook的Connectivity实验室和核心数据科学团队通过这些特性，分析了海量的卫星图片，创造了一张高分辨率的世界人口密度地图。

这个团队还有很多有趣的研究，也发布了一些论文：多任务学习、强化学习形成的通用视觉模型（论文）、采用Elastic SGD与时空卷积网络训练的大规模分布式系统对视频的分析（论文）、级连算法在视觉模型的应用（论文）。&nbsp;在语言技术方面，我们正在努力做的一件事情是消除Facebook上的语言壁垒。为了实现这个目标，我们每天处理超过20亿个帖子的翻译需求，超过40个语言的翻译，翻译方向（比如英翻中、中翻英）超过1800个。过去我们采用微软bing的翻译产品，后来我们自己开发或部署相关产品。现在，我们正在讲深度学习纳入到翻译产品中，希望通过神经网络，达到人类翻译的水准。&nbsp;在机器学习和新领域，我们主要聚焦研发和使用一些大规模、实时的机器学习或人工智能算法，用到一些大型机器学习应用程序中。无论用户何时登陆Facebook，这些系统都会用来评估用户时间线上的状态更新（目前的数字为：平均每天超过10亿用户，每个用户1500个状态）、广告和搜索结果（每天的搜索请求超过10亿）、热门趋势信息、拍朋友推荐信息甚至也会评估用户收到的各种提醒以及别人的评论信息。机器学习团队同样利用深度学习打造了一系列「优雅」理解文本的算法。这些算法整合到我们打造的机器学习平台里，用于加快推进和大规模实现从训练到部署的过程。Facebook所有采用机器学习的产品都会使用这个机器学习平台。如果你想理解机器学习在Facebook有多流行，我举个简单例子吧，超过20％Facebook工程师（甚至非工程师）都是这个平台的活跃使用者。我们现在研究的方向包括用于预测事件的深度学习模型、用于稀疏模型、深度学习的分布式复习系统、通过卷积和递归网络进行文本理解的表征学习以及通过多任务学习的模型压缩。关于学习：你学习机器学习的途径是什么？在学习机器学习时，你最喜欢哪一本书？我最初接触机器学习，是在我作为一位电信工程本科生学习高等非线性信号处理的时候。那是在1995至2000年。我非常幸运地拥有一位很赞的导师，他在个人信息在 Prof. Anibal Figueiras-Vidal这网站上。他解释到你可以怎样使用神经网络构建自适应的、受训于观察到的数据的非线性过滤器。于是，我就入坑了！&nbsp;我写的硕士论文是关于稀疏的径向基函数分类器。在那时，支持向量机风行一时，它似乎就像稀疏性是模型为了提高广泛性而应该具备的合乎要求的性质。我还记得你总是会评估你根据UCI repository的数据集创造出的算法。有趣的是在我们后来的学术生涯里，我警告过不谨慎使用稀疏模型的缺点（见see the dangerous uses of sparse Gaussian Process priors），并且我曾在行业里寻求一份gogn zuo，以能生成由机器学习应用程序产生的新的有趣数据。

如果我不得不指出一本非常有影响力的书，那就是 Chris Bishop’的第一本书： Neural Networks for Pattern Recognition (1995)。其中第十章「贝叶斯技术」真的很对我的胃口，也是我至今仍对贝叶斯倾注热情的产物。然而正如我经常所说的，「一位真正的贝叶斯派不可能彻底是贝叶斯派：你需要优先保留一些余地，因为有可能贝叶斯方法不是正确的。」

在我花了6个月时间拜访丹麦科技大学时，我非常幸运地在2000年偶然碰上 Prof. Carl E. Rasmussen 。Carl是一位贝叶斯派，向我介绍了神经网络的贝叶斯处理方法和针对近似推理的蒙特卡洛马尔科夫链抽样方法。他也向我介绍了高斯过程，我写的论文就是关于这个。我最后回到了丹麦，在Carl的指导下攻读博士。&nbsp;这些天，我会犹豫要不要给人们指出特定的书（有太多杰出的书了）。我坚持建议人们观看视频演讲。如果你在YouTube上搜索你想了解的任何主题，你将发现由顶尖学校的一流教授提供的丰富的视频演讲。给你一个具体的例子：我最近需要掌握更多计算图像学知识，找到了Bill Freeman的很赞的入门介绍。我最近还想综述自然语言处理的简介，就找到了Dan Jurafsky 和 Chris Manning的很赞的入门级讲座。&nbsp;如果你坚持读下去，这里是一本极大地激励了我的书，是Jaynes的《概率论：科学的逻辑》（这里是供你阅读的pdf版本： pdf version）那本书提倡使用概率论作为科学推理的语言，在我们如何探讨概率推理方面给人很大的启发，也对机器学习非常重要，而且近来这些天当我们思考人工智能的未来时，也会从这本书获得相关联的哲学启发。&nbsp;我也会鼓励人们立刻动手。如果你是Matlab用户（我以前是！）或者使用Python（当然你会用的），有许多应用程序包基本上是实现所有事情。然而对于很多算法而言，你可以编写你自己的程序工具，那是你真正要学的。团队招人时，你看中的是什么？我看中的是技术实力和性格。寻找的人是这样的：任务驱动型的。人们需要完全投入最终目标。适应不确定性。无私与合作。ML黑客。强大的背景条件。在应用机器学习中，什么是更重要的：数据，基础架构还是算法？首先让我们确定目标：在应用机器学习中，成功意味着将机器学习系统对实际应用的影响最大化。例如，通过我们的广告排名系统将拍卖的总额最大化，广告排名系统是由机器学习系统驱动的，能预测广告与受众的关联程度。拍卖价值将被两件事积极影响：预测的准确性。候选广告的数量。候选广告能通过大多数精确的预测器（经典的是严格的延迟约束器，能更快的激活级联途径，是通过更不精确的预测器精选候选广告）来估价。我们需要将精确度最大化，同时将在服务时间进行预测的计算工作量最小化。让我们现在聚焦于最大化预测精确度。机器学习系统典型地有一个实验组件，旨在设计和训练模型。我们已经发现最重要的属性是实验速度。一个团队能在单位时间内完成的实验越多，他们就能取得更大的进步，建立更好的模型。我们努力应用机器学习，一直以来遵循「每周扬帆前行」的口号，做出了伟大的成果。为了每周至少能给特定应用输送一个生产模型，你需要管理几十个现场实验，每周执行成百上千的线下试验。极佳的基础架构、平台和工具对应用机器学习是必不可少的，既要最大化实验速度，又要最小化在服务时间的预测成本。&nbsp;现在，让我们转向数据和算法问题。我们的哲学理念将问题分出了轻重缓急，下面是按重要性从高到低排列：数据：尽你所能地得到大量数据，确保这些数据是最高质量的。就我们的经验而言，数据会以出乎意料的、不同寻常的方式变得杂乱。我最喜欢的一个故事是，快速重复点击以增加impression（译者注：impression是网站分析的最基本度量之一），这偶然不会起作用，因为存在一个假设是点击被报告给处理impressions的同样的数据中心。特征工程：做大量的和它有关的事。提取你的数据，浓缩为有最大化预测力的信号。构建尽可能自动化的工具（自动化特征选择时常在后台运作，保持CPU的效用最大化）。我必须强调深度学习的来临正改变者游戏：当使用更简单的算法特征工程是关键的时，深度学习的承诺是它允许自动化地学习表征（例如特征）和你能馈送给它原始数据。一些明显的例子是DeepMind的令人惊讶的工作，也就是纯粹基于屏幕上的像素学习玩耍经典的街机游戏，而没有做任何特征工程。深度学习通过自动学习表征也已经引发了计算时间和语言技术的革命。还是那样，在实际应用中，依赖机器学习的产品团队定期通过特征工程仍有重大收获算法：一旦你拥有了针对特征工程的最棒的数据和工具，就要保持提升你的算法能力（同时要保证这些算法是广泛推广的）。在Facebook，我们定期输送新的具备更大生产能力的模型，但是值得注意的是，只有当训练数据的数量一路增长，而且表现力（包括训练和在服务时间的预测）没有退化得太多以致于抵消了增长的精确度带来的益处时，这才有意义。我们总是将来自更复杂模型的精度收益与在做预测时增加的CPU成本相比较。这意味着我们经常使用最简单的可以完成工作的模型（从计算效率角度来说）。总结：在应用机器学习中基础加工是至关重要的。然后，你应该聚焦于拥有尽可能是最好的数据，做大量的特征工程和使用最简单的能完成工作的算法。深度学习如何影响 Facebook 今天的产品？2012年基于深度神经网络的方法在 ImageNet 分类比赛中获胜之后，深度学习引起了很大的反响。神经网络已经在机器学习中应用了相当一段时间，但具备更大容量和远远更多数据的深度神经网络带来了变革并显著击败了其它较浅的模型。这一运动开始于计算机视觉，并快速扩张到了文本理解、机器翻译和语音识别领域。&nbsp;Facebook 拥有一个单一的使命：创造一个更加开放和互联的世界。随着我们开发出让人们可以分享更多的工具和产品，理解用户的内容并向他们提供最大的价值就变得越来越重要。这意味着，高准确度（精度和回调）、低延迟和更快速的创新。深度学习在所有这些方面影响我们的产品。它被用于文本、音频、照片、视频甚至交互的内容理解中。嵌入式的深度学习被无缝整合到许多产品组中，这使得他们能更专注于核心产品，同时又指望我们团队（机器学习应用产品组）提供可用于多种任务的可能最好的嵌入产品。&nbsp;除了提供嵌入产品，深度学习也在被应用在一些端到端产品中，如用于视频字幕的自动语音识别、为盲人配音的核心视觉识别引擎、让你可以将数百种语言翻译成英语的机器翻译。为什么 Facebook 要投资（大量）人工智能/机器学习？没有人工智能/机器学习，Facebook 就不能存在。

人工智能是 Facebook 已有的工程工作的自然延伸，这是向我们的社区提供好体验的关键部分。每天，这个世界都在产生越来越多的数据——文本、图片、视频等等。为了做到有用，我们需要帮助你梳理所有这些信息，这样你就可以看到你想看到的内容，并更高效地和他人交流。&nbsp;回答这一问题以及有关人工智能和机器学习领域更多具体应用研究工作，请见：What are the most interesting things Facebook is doing in ML research?你怎么看待当前深度学习上的炒作？我不认为这是炒作。&nbsp;人们已经在它上面进行了几十年坚持不懈的努力，但有有意义的先验的非常庞大而复杂的神经网络释放了表征学习（RL：representation learning）的力量，得到的结果极其优于那些通过手动输入特征和传统算法的结果。正如Yoshua Bengio 和 Yann LeCun 在他们最近的 NIPS 2015 教程中解释的那样，算力与训练数据的数量和质量的急剧增长是表征学习和深度学习成功的关键。&nbsp;回到表征学习上，它是真实的。过去几年这方面已有许多最新的突破性进展可以归功于表征学习。这些都已经在计算机视觉、语音识别、自然语言处理等领域实现。所有这些领域都拥有一个特征：输入信号是传感器信号。表征学习使用深度神经网络（DNN）架构学习这些传感信号的分层特征表征。这些表征最后表现得比人类施工的和高度精制的功能好非常多。那并不是关键，但这样的架构远远地近似于人类大脑中学习和执行认知任务的方式。&nbsp;比如在Facebook，我的朋友和同事 Ahmad Abdulkader 与我们的广告团队合作开发了能够自动检测出违反我们政策（例如包含暴力、酒精或武器）的有图片广告。在这一任务上使用深度学习在精度上带来了显著的提高，并最终保护了Facebook 社区免受潜在的不良内容的影响。我们的计算机视觉团队已经开发了一个供几十个团队使用的自助服务平台，以帮助他们在通过使用深度学习学到的图像和视频的表征的基础上训练专门的预测模型。Manohar Paluri 可以告诉你更多有关 Facebook 用于计算机视觉的深度学习应用。&nbsp;表征学习也还有一些尚未取得突破的领域，尤其是那些输入不是传感信号的领域。它是否还能取得那样的突破，尚有待观察。

说到这么多，学术界、业界和媒体需要谨慎对待夸大的结果、对可能带给机器的「智能」式未来的过度解读、以及机器是否以某种方式取代人类的严重后果的警告。这更接近科幻而不是现实 :)为大型公司制作可通用机器学习框架所带来的重要经验有哪些？打造通用机器学习框架很艰难。机器学习与人工智能如今进展层出不穷。这让任何通用机器学习框架不停地处在测试之下，甚至许多都已经废弃。另外，灵活性与规模以及灵活性和可用性与之间一直有着强烈的压力。这些都是一个总体框架所有需要考虑的重要权衡。&nbsp;在下面我会分享一些我们在制作Flow的时候的学习经验——也就是我们的通用的机器学习系统。工程师利用Flow去制作机器学习通道，以训练深度学习模型、大规模逻辑回归、决策树等等。Facebook的所有这些模型每周都会从实验环境部署到生产环境进行数次，并且被Facebook的很多团队调用。深入理解你的应用场景：许多通用机器学习框架经常会突出强调某一个场景。在Flow，我们理解我们有两个主要的观众。其中一个写出新的通道，另一个通过添加新数据来消耗它们。我们确定了我们为这些场景中的每一个都提供了良好的体验。打造多层平台：良好的平台会从「use it all」和「lose it all」等场景中保护它们的用户，好的假期会提供很多抽象层。最外层提供最好的经验，但是如果用户不知道他们到底想要什么，他们应该降低级别去达到想要的。速度，速度，速度！对于企业中的机器学习研究，让你设计的想法得到支持和许可都必须在保证速度的前提下。数据经常会很巨大，并带来降低创新的瓶颈。默认可重用：无论何时工程师在Flow写了新的东西，都可以被公司里的其他人所重新利用。这意味着工程师有着超越以前的指数式增长的创新力。准备写第二个版本吧：如果这是你的平台第一个版本，准备好去重新写一个吧，因为这里面隐藏着许多错误和坏的概念。不停地探索直至你认为这是个正确的时机去进行重写，但是在这之前要确保你进行了足够的讨论和探索，比如要达到更好的架构。避免过早推广：在你尝试将产品通用化之前，确保你有2到3个具体的重度使用场景。如果你在未成熟的时候就通用化，你也许会失去一些重要的价值，减慢发展速度。记住，如果这是你的第一个版本，你总会需要重写的，因此千万不要提前通用化。做一个算法不可知论者：机器学习经常会着眼于一个或另一个机器学习算法。在Flow，我们决定在这个平台上「欢迎所有的算法」。我们支持并创造了几个可用于Facebook的算法。但是平台是对所有算法公开的，因此可帮助Flow通用于任何出现的新算法。统一带来的好处：算法的多样性是极度有利的。也就是说，一个统一连接这些算法的系统会非常强大。比如你研发了一个算法，且这个算法对于广告和搜索结果展示具有神奇的效果，

接着你可以执行一个Flow的有着标准化界面的算法算子（广告和搜索排行通道都调用了这个算子），结果是它会变得更好。再比如你已经研发了这个算法更强力的版本，不需做太多改变，你就可以用所有通道上的新算法进行实验，调用算子并方便地使用它。由此，我们的应用研究员可以将它们的影响力迅速扩大至整个公司。如果你的余生只能够用一个机器学习算法，你会选择哪一个？我真希望我身在能够回答这个问题的时候！解决机器学习的问题仍然需要人类在整个进程中绝对的参与：制定机器学习任务、定义度量以进行优化、预测数量、评估可用数据和收集附加数据，选择适合于手头的预测任务的模型池中的模型。当然，然后还会有计算有效性的考虑。如果模型需要作为机器学习的一部分在生产中运行，边际计算复杂度所附加的任何精确性都必须超过附加成本的消耗。换句话说，精确度不仅仅是唯一的标准：计算成本也是重要的一个。

我在剑桥大学的朋友与前同事所做出的一个令人振奋的努力正是我希望机器学习所前进的方向。他们的想法是自动化数据分析。另一个激动人心的方向则是ICML2015工作室所激发的「Auto ML」趋势，后者旨在尽可能自动化人类在机器学习中的参与。

没有任何理由能够说明，我们不能创造一个基于模型和预测任务的自动化数据分析和机器学习的人工智能。&nbsp;在一个更有趣的发现中，我逐渐开始使用许多模型中的高斯法和贝叶斯法，如果后期和预测分布难以实现时，这些方法可以利用MCMC以获得近似推理。我的兴趣仍然在于利用这些模型以及推理方法。尽管这并没有让它们成为我会在余生中唯一使用的算法，但是它们一定是很有趣的算法，并且回馈以大量的智力乐趣。产业领域里的机器学习研究和学术领域的机器学习研究，有什么不同？产业和学术领域的机器学习研究，很多相同点和不同点。我近十年来都在产业领域工作，因此，接下来的观点将更多地受到产业观点影响（多过学术领域）。不过，需要注意的是，我和学术领域保持着密切联系，也欣赏我们团队发表的论文，热衷组织和参与研讨会和会议。&nbsp;现在谈观点：&nbsp;数据：产业领域接触到的数据通常比学术领域多得多。不过，随着互联网的发展，这种差异在日益减少，但还是有一定差距。这也意味着学术机构的研究侧重于小规模的数据集，无法反映产业需要的解决问题。不过硬币的另一面则是，这些小数据集可以更方便迭代，从而帮助学术机构更快地获取研究灵感。

工具和基础设施：企业能够投入更多资源构建工具，能够保证在应对大规模需求时还能快速进行原型设计。在企业里，你可以更方便低于工程师和机基础设施专家合作，他们将帮助你搭建一个更坚固的研究基础平台。大量稳定的工具也可以保证你的研究可以快速移植。&nbsp;速度：对产业领域来说，时间就是金钱，因此速度非常重要。这里的工程师和研究人员通常会优先考虑速度和产品部署的频率，因为一个产品的目标就是一段时间内，在总体上最大化产品的影响。更快的迭代可以让你探索更多新的可能性并忽略一些没有承诺的开发方向。&nbsp;目标驱动力：产业研究有着非常明确的目标驱动力。这就是通过实现研究的商业化，来进一步推动产业对于研究的投入。在可落地实施的范围而后，综合考虑成本以及如何与现有产品体验的融合，是产业对于创新和研究投入的重要考量点。这里必须要提到一点，研究机构在创新方面的重要作用，由于产业倾向于一些短期技术的研究，研究机构承担了大量颠覆性技术的研发和创新。&nbsp;简单：在学术界，发表论文是主要的衡量成功的方式。论文作为一种强制作用，以一种结构化方式帮助新观点产生效果，也鼓励了那些在实践中运行良好的新奇事物。产业界往往在简单的一面犯错，因为大规模操控复杂系统是花费不菲的。&nbsp;对上述事情持非黑即白的观点总是错误的，因为在产业领域有一些让人惊羡的研究者，在学术界也有令人佩服的工程师，这使得不同领域的重大突破成为可能。理想的化学组合是产业和学术共同合作，取其所长，推进领域发展。你如何在工作日程中安排长跑？我每年跑几次马拉松和超级马拉松。也喜欢和朋友跑步。&nbsp;这些天我平均一周跑50多英里，让跑步和工作安排不冲突的方法就是很早起来跑步。几乎每天，我都是在日出左右开始跑步，有时从家里开始，有时和一些爱跑步和喜欢早期的同事从单位开始跑。我们在工作地点淋浴，而且我喜欢跑步后在公司吃早餐。&nbsp;清晨跑步，首先对我来说是有利的，完全清理了我的内心，这有点像冥想，然后我以宁静、安详的状态开始这一天。许多问题在前天晚上看上去似乎很可怕，跑完后，似乎完全在掌控中。对励志在产业领域从事ML/CV研究的PhD候选人，给予一些指导。为产业研究职位做准备的一条最佳方法是，当一次或更多次的暑期实习生。这会让你走出只需要做论文研究的学校氛围，进入这样一个环境，其中，影响力、快速成型和与其他团队深入交往不仅普遍而且重要。&nbsp;产业实习生允许你与其他有经验的导师工作，得到广泛经验，学到更多技术。有时，实习经历只会写入你未来的出版物中，但是，有时你将对一个重要的新功能或能力做出贡献。提前询问实习机会，这对你很重要。&nbsp;在实习期间，还有在学术研究期间，你会在扎实的软件工程实践中变得熟练。一条途径是使用和贡献开源软件。你的同辈将给你反馈你的代码质量和可用性如何。试着在团队中做一些你的研究。产业研究很少独立完成，因为有太多外部因素需要团结合作去创造真正的影响力（例如：输送新性能或产品）。试着做一些项目，所以你能得以拓展你的科技知识。最后，就你的工作向大量听众举办大量演讲，一些听众可能不是你专长领域内的人。但能推销你的工作给非专业领域内的人（包括非专业领域的导师），对你成功的产业研究至关重要。

如果你打算追求学术生涯（终身教授职位），那么在某个主题上非常专业且在某个理论上很善长，而不是精通动手操作和实验，这是非常好的，但这对于大多数产业研究职位而言，并非特别有用。你如何看待开放人工智能？我们欢迎他们来到这一社区，期待看到研究进展以及它们的最终回馈。&nbsp;不过，我会补充说，我们取得的人工智能进展，现在已经是一个非常公开的过程。科学研究力求研究者的交流促进。互动社区越大，进步也就越快。&nbsp;在Facebook，我们想要让人工智能研究者更容易分享方法和技术。我们有一个大体上支持开源软件和硬件的文化，而且FAIR（Facebook人工智能研究）和AML（应用机器学习）已经继续兑这一文化承诺：以学术论文的形式发表他们的发现，开放网站上可免费获取。我们绝大多数的项目代码成为开放资源，最近也开放了一个人工智能硬件设计。对机器学习非常陌生的工程师/学生而言，什么才是最关键的？机器学习包含非常广（且深的）科学和工程学科子集。所以想通透了解该领域就要花费点时间，需要常年累月持续学习，特别是当新算法和想法正不断被研究时。&nbsp;在某种程度上，机器学习类似于统计数据，试图从大量数据中推断出结论或者模式。但另一方面，它更像计算机科学，需求高效的算法和表达方式。&nbsp;我个人最喜欢的是Chris Bishop的《 Pattern Neural Networks for Pattern Recognition 》。当然，还有一些其他很棒的书，包括来自Coursera, Udacity, edX等的在线课程。但是，如果自己不做很多实验，几乎不可能学会机器学习。&nbsp;尝试书本或者讲座上布置的练习，花些时间。貌似投入很多，但是，如果你想长期呆在这个领域，你需要积累很多知识和直觉，知道适合每个问题的技巧和方法。你也要持续学习，因此，获取学习新材料才能然后吸收之并付诸实践会非常重要。&nbsp;变得精通合适的实验和证实方法。在某些工程领域，你可以遵循指导手册或者通过非形式推理验证正确性。在机器学习中，「正确答案」往往很少。因为你所做的就是从不完全信息中做出最好的推断（打趣地说法就是「做出最好的猜想」）。你不仅要设计出综合数据的单元测试，挑出代码中明显的bug，还要在更大的数据集中不断测试。这是一个非常大的挑战，因为得到正确答案非常的难（这叫做标记数据）。 &nbsp;最后，紧跟最新研究，积极参加这个领域的年会。如果你刚步入这一领域，这是一种非常棒的方法了解这一领域的研究和技术深度。（年会往往会有很好的导师会议）如果你有经验，你可以借此建立与研究人员和从业者的社交网络，从而了解最新的技术和科研成果。Facebook机器学习团队不招非PhD？不，并非如此。虽然在多数情况下，PhD能帮助你学习如何做研究。Facebook的每个团队都有非PhD的人做机器学习，方向都不同。&nbsp;我们想知道，诸如Facebook有先进的机器学习算法的地方，是否还需要一些更加简单的算法？&nbsp;在Facebook中，我们尽可能用最简单的算法完成工作。如果预测精度有效，简单的算法就意味着更低的计算成本和更简单的调试。同时，创造性的简单算法也可能惊人的准确。在我们有关广告数据实验的论文中，我们对这些结果做过解释。&nbsp;就像我的朋友艾哈迈德·阿卜杜尔卡达尔(Ahmad Abdulkader)说的，「总有对更简单算法的需求。」事实上，更加简单算法比复杂算法更受人推崇。复杂算法总是要靠准确性的大幅度提升予以合理化。&nbsp;也有一些领域，更简单的算法也受到欢迎，即使它们的准确性不如复杂算法。比如，较之复杂算法，在很多机器上分布一个LR学习算法要容易地多。结果，LR胜出。&nbsp;简单的说，我们在需要时才用复杂算法：一些实例应用的领域，比如计算机视觉、机器翻译、文本理解和语言认知等。在这些领域，深度神经网络在预测准确性上有大步提升，所以使用它们无可厚非。在Facebook，有哪些不明显使用机器学习的地方？在《What are the most interesting things Facebook is doing in ML research?》中，我曾经给出过几个明显或不明显使用机器学习的例子。

我分享一个可能不那么明显的使用机器学习的例子。&nbsp;Facebook的 Accessibility team已经运作四年了，最初是专注于让Facebook已有产品让每个人都能使用。但是现在，它专注于为残障人士打造新产品。这个团队关注的一个对象就是盲人和视力丧失群体。因为Facebook是一种视觉上的体验（如同大部分互联网），我们需要尽可能的在创新上做投资，让Facebook的体验更好。我们在AI领域，以及诸如物体识别这些计算机视觉特定领域的投资，能够让更多人接触到科技。你的生活平衡地很好，如何做到的？哇，这个问题的前提假设是我已经很好地平衡了我的生活！:-)

我不断地尝试平衡我的生活。有三件是对我很重要：我的家庭我的工作保持身体上的健康我觉得关键词是效率。依靠「习惯的力量」让我变得有效率。每天早晨我都会按固定路线跑步，有时会和朋友一起跑。同样的跑步习惯（时间、地点）让我们不需要花费时间做计划。在家里，我和妻子会提前协调好家庭与工作时间，避免突发事件。&nbsp;最后，我认为抽时间做计划是很重要的。为了看到更远的场景，后退一步是有必要的。你想要什么？什么事你会高兴的拒绝？（为了得到重要的一些东西，对很多事你都要说no。)你会怎么描述Facebook文化？我在这里工作最喜欢的就是Facebook的文化。我经常把我们的文化和价值观分享给新职员。&nbsp;我们的价值观很好的体现到了我们的文化：建立社会价值观：我们是一家任务非常明确的公司。我们每天早上来到这里工作不只是为了让这个世界更加的开放与连接，而是为了在人类生活中创造价值。在Facebook中有个团体叫「Go 365!」我就是这个帮助、鼓励跑步新手的团体中的一员。我加入两年了，总能见到队员对马拉松新手的鼓励和支持。快速行动：我们是建造者（builder）文化。我们会尝试、会思索。我们也会犯错误，事实上我们也鼓励犯错。你如何进步？我看到很多很棒的系统在快速力量驱动下成长起来。如果它们值得构建，我们会重点查看缺陷之处，往最佳的方向改善。大胆：「最大的危险是不冒危险。」有一个有趣的不对称现象，我们人类倾向于高估我们不了解的现状。这是棘手的，因为我们周围的世界变化得太快，而且我们目前的解决方案、产品或系统可能在新环境中不再有关联或是最适宜的。引用一个我欣赏的例子，Amazon的几年前做出大胆举动，大举投资Kindle。这个产品直接地攻击了他们既有的商业模式。保持开放：这可能是我最爱的价值观。保持开放帮助我们利用集体智慧，因为没有人有所有的答案。它也帮助减少意外，增加信任（记住，「意外是信任的敌人」）。最后，一个开放的反馈式的文化帮助每个人得到提升，变得更好。关注影响力：总是有很多事情要去关注，但是就像大自然教给我们的一样的，将我们投入的大量精力的影响力最大化，非常重要。在Facebook，我们努力建立自下而上的文化，每个人都感到有责任理解围绕他们的影响力在哪里，并将自己的工作朝向它。最后，在Facebook，我们有一种「传播爱（ship love）」的文化，这是一种方式，说出我们在这里服务于15亿依赖我们构建工具和产品的社区。如果我们不爱这些人，我们不可能为他们服务。有了H2O.ai（用于商业引擎的人工智能）、Azure机器学习、数据机器人，你如何看待机器学习大众化浪潮？许多研究表明，机器学习工程师/研究员供需存在巨大缺口。一些人甚至预期这个缺口将继续扩大直到2019年。结果，机器学习「大众化」的努力可能造成巨大的影响，而且对这些工具而言，也可能意味着巨大商机。&nbsp;现有的成套工具似乎早已意欲达到这样的平民化。他们倾向于将重点放在帮助数据科学家达到他们的目标，主要是在企业环境里。&nbsp;在Facebook，我们在 AutoML这个方向做出了认真的努力。AutoML也是在许多机器学习领域（ICML，CodaLab等）获得了大量关注。这似乎是更有前途的方向，而且我的朋友和同事Ahmad Abductkader正积极地与我们的一些产品小组合作，致力于让国内机器学习大众化，尤其是帮助新的小型团队落地机器学习。Facebook 的各种应用中使用了怎样的神经网络拓扑结构：有多少层，等等？在Facebook，我们的目标是用最好的人工智能技术驱动产品。最好的有时候就是已经存在的，很多时候都是我们内部为 Facebook 量身定制的。有时候我所在团队（机器学习应用组，我们的应用研究机构）和 Facebook 的人工智能研究组（FAIR）肩并肩合作，我们也与我们的产品团队有密切的合作。&nbsp;我们使用的神经网络拓扑结构和我们在各自领域首次展示中所发布的类似。它们根据应用的不同存在差异，基本上都是深度卷积网络、全连接网络和递归神经网络。在基于文本、照片和视频、语音等应用上，我们也使用它们的组合。

我们的这些团队必须解决许多有趣的挑战。比如，我们通常将我们的数据视作一种流，而不是将其看作是几百万个样本的静态数据集。这让我们能够随时间学习更大的模型，拓扑结构也随之不断进化。另一个有趣的挑战是可能最好的模型也许并不是大规模运行时可行的模型。所以，我们总是会在模型的容量和计算与精度之间进行权衡。&nbsp;我们已经公布了各种研究结果，并且我们对组成链式或树状的多个模型的拓扑结构非常感兴趣，在这样的结构中，更快但精度更低的模型先运行，然后再给更慢但更精确的评估数据的子集的模型让路。这是一个正在进行中的研究课题，也是一个我们因为我们的数据规模而必须要解决的重要问题。另一个例子是视频，在这一应用中，可以应用基于图像的模型，我们可以使用一个连续的模型融合来自视频帧的信息，或我们可以慢慢地使用空间-时间卷积融合时间和空间信息。&nbsp;我们发表了使用这样的网络的学习功能上的发现，并展示了其通用化的能力。总之，随着我们研究越来越多并尝试找到精度、速度和内存之间的平衡，我们的拓扑结构也一直在不停变化；而我们也将积极公布这些发现。毕业之后有哪些好的机器学习课程可以参加？http://videolectures.net/是一个很赞的资源，上面有很多关于「机器学习」、「人工智能」、「大数据」、「计算机视觉」、「自然语言处理」以及更多与机器学习相近的主题。&nbsp;Udacity 和 Coursera 提供了完整成熟的课程，一个人可以以有限的知识开始一个领域的学习并在课程结束后取得相当的进步。我个人很喜欢吴恩达、Jeff Hinton 和 Daphne Koller 教授的课程，但我确信随着深度学习和机器学习在业界变得越来越重要，这些课程设置也在不断进化，资源也在不断增长。我问了问我们团队其他人最喜欢的课程，我的朋友和同事 Manohar Paluri 向我指出，比如说，乔治亚理工大学在线课程Pushkar Kolhe 和 Charles Isbell 与 Udacity 联合教授覆盖了机器学习的基础知识。&nbsp;爽的是大多数/所有这些资源都是免费的！在学习这些视频时，另外还很重要的是要亲自动手鼓捣代码，看这些东西是如何运作的。鉴于Torch、Caffe、Theano、TensorFlow这些工具已经可供下载，而且同时支持GPU和CPU，实验就是很简单的事情了。深入到这些代码中始终是快速学习的好方法。你怎么看待对话引擎（conversational engine）的未来？对于对话和口语接口来说，现在是一个激动人心的时刻。但还仍然非常早期。Siri 和 Cortana 这样的个人助手提供了简单的任务完成和搜索引擎和自然接口。对于 Facebook，我们相信大机会在人们与 Facebook 本身的交互之中。如果你想想人们使用 Facebook 的方式，这里每天都发生着数百万计的多路对话。使用对话理解和会话技术，Facebook 自己可能就能参与到这些对话中，而不只是被动地协助他们；我们还希望通过挖掘存储在 Facebook 图片库中的海量知识来增加价值。

如果你对 Facebook 的对话引擎和语言技术感兴趣，你可以在 Quora 上关注我的朋友和同事 Alan Packer.Facebook 目前怎么使用计算机视觉，又计划在未来怎么使用它？最近几年 Facebook 上的媒体内容分享和消费出现了巨大的增长。人们从文本转向了照片，而且从照片转向视频的过程正在进行，而且我们已经看见了虚拟现实/增强现实的影子。过渡到照片标志着计算机视觉作为一种重要工具的出现，而且随着我们转向视频和虚拟现实/增强现实，计算机视觉的发展动力还在不断快速增长。计算机视觉将在理解这些内容的公司中扮演至关重要的角色。它将不只能帮助理解，还能提供更加丰富和更具创造力的方式来分享你的经历（视频防抖、实时美颜等）。&nbsp;目前，有许多产品组使用了由计算机视觉系统提供的技术。这项技术被用于更好的搜索、用于辅助的图像字幕、打击垃圾和不良内容、筛选出违反我们政策的广告给人工审核、制作人口密度图、确定 Instagram 趋势、检测纪念日和重要时刻相似的照片等。每一个接触照片、视频和虚拟现实/增强现实的产品组都会利用来自计算机视觉组的信号。&nbsp;计算机视觉未来也将在 Facebook 及其各种产品的使用中发挥巨大的作用。想象一个简单的例子：我们向部分人开放了视频直播并已经取得了良好的使用。当我们将其开放给我们网络上的十多亿人时，将会出现数百万个并行的频道。这种信息爆炸意味着让用户能在相似的频道间切换和基于文本搜索直播视频等是非常重要的。&nbsp;Facebook 的本地搜索由人们的经历驱动，我们可以很出色地完成给出旅行、餐厅和周边事物的个性化建议的工作。围绕这一工作的大部分内容都是照片和视频。下一代虚拟现实可以使用由内而外的跟踪，这是计算机视觉的核心问题。随着计算机视觉越来越好，随着我们了解照片和视频中内容并开发出强大的视觉表征，我们将有能力推动目前甚至还没在 Facebook 平台上出现的新领域。&nbsp;如果你想询问关于计算机视觉及其在 Facebook 应用的具体问题，可以试试在 Quora 上向我的朋友兼同事 Manohar Paluri 提问！&nbsp;我们以前使用的是微软必应翻译服务，但最近我们已经使用我们自己的数据训练的自己的机器翻译技术进行了替代。我们这么做的主要原因是我们发现 Facebook 帖子和评论的语言与其它网络都不同：它非常俚语化，非常区域化，是非正式的人与人之间的交流而非文件或专业写作。所以，调整这项技术适应 Facebook 的语言并训练我们自己的数据让我们可以开发出更为精准的机器翻译。Facebook 怎么识别照片中的人？当你将照片上传到 Facebook 时，我们专门的面部识别服务器会将其选出进行处理。&nbsp;第一步是定位图像中所有的脸（也被称作人脸检测）。这一步的结果是一组线条框将每张脸圈了起来，非常类似于我们网站上作为标记体验的一部分的标记框。现在我们知道了图像中所有脸的具体位置，我们继续第 2 步——识别。

对每一张脸我们运行专门为这一任务训练的机器学习神经网络。这一网络会为每张脸输出一个数字表示。一种思考这种表示的好方法是将其作为高维空间中的一个点（坐标列表）。一个好的表示方法可以将同一个人的不同面部照片映射到这一空间中的同一区域，同时还能保持这些区域（其中每一个都代表不同的个体）之间很远的间隔。我们实际上为每一个人都创建了一个专门的模型，这样我们可以快速确定一张给出的新面部照片是该位于这个区域之内还是之外。&nbsp;最后一步是收集你和你朋友所有可用的面部识别模型，然后将上传的照片中每一张脸的上述表示和这些模型进行比较，然后选出最佳匹配的候选标签作为你的标记建议。所有这些处理在上传后很快就完成了，足够及时让你在写你的帖子时看到这些标记建议。

如果你想了解更多关于 Facebook 的面部识别的信息和我们接下来的开发计划，可以试试在 Quora 上向我的朋友兼同事 Tommer Leyvand 提问。"
"Facebook;;Joaquin Quiñonero Candela谈机器学习Joaquin Quiñonero Candela是Facebook 机器学习应用团队的负责人。他曾在微软剑桥研究院工作，还是微软Bing团队的一员。Joaquin Quiñonero Candela 在Facebook的主要工作是与Facebook 的人工智能实验室、各产品部门紧密合作，将机器学习、语言技术，计算机视觉等技术运用到Facebook的各个产品中，并将产品反馈纳入接下来的研究中。可以说，Joaquin Quiñonero Candela的团队Facebook人工智能从实验室到产品的关键。作为横跨学术界和产业界的机器学习大拿，Candela 在Quora上回答了诸多问题，如何看待机器学习发展的现状、机器学习如何在Facebook变得如此流行以及该如何学习机器学习，这些问题都将在本文中得到解答。Facebook的机器学习团队都在做什么？机器学习应用团队是Facebook应用研究团队的一员。我们的核心工作是机器学习、计算机视觉、计算图像以及语言技术。我们和公司的人工智能研究团队紧密合作，不过相对来说我们的工作更关注应用层面。接下来，我将简单介绍一些我们团队所做的有趣事情，当然，这并非一个完整名单，也并非只是我们一个团队能完成的事情，我们也需要和人工智能团队、核心数据科学团队以及众多产品团队并肩作战。&nbsp;在计算机视觉方面，我们有一套能够处理用户上传的每张照片和每个视频的系统，每天的处理总量超过100万张（个）。利用这套系统，我们可以预测出这张照片的内容，这个用处非常大。比如帮助盲人「看到」图片、自动侦测图片上的敏感信息、提升用户搜索多媒体信息时的准确性等等。我们采用包含数十亿节点的深度卷积网络。这个模型最有趣的地方就是可普遍适用的特性。最近，Facebook的Connectivity实验室和核心数据科学团队通过这些特性，分析了海量的卫星图片，创造了一张高分辨率的世界人口密度地图。

这个团队还有很多有趣的研究，也发布了一些论文：多任务学习、强化学习形成的通用视觉模型（论文）、采用Elastic SGD与时空卷积网络训练的大规模分布式系统对视频的分析（论文）、级连算法在视觉模型的应用（论文）。&nbsp;在语言技术方面，我们正在努力做的一件事情是消除Facebook上的语言壁垒。为了实现这个目标，我们每天处理超过20亿个帖子的翻译需求，超过40个语言的翻译，翻译方向（比如英翻中、中翻英）超过1800个。过去我们采用微软bing的翻译产品，后来我们自己开发或部署相关产品。现在，我们正在讲深度学习纳入到翻译产品中，希望通过神经网络，达到人类翻译的水准。&nbsp;在机器学习和新领域，我们主要聚焦研发和使用一些大规模、实时的机器学习或人工智能算法，用到一些大型机器学习应用程序中。无论用户何时登陆Facebook，这些系统都会用来评估用户时间线上的状态更新（目前的数字为：平均每天超过10亿用户，每个用户1500个状态）、广告和搜索结果（每天的搜索请求超过10亿）、热门趋势信息、拍朋友推荐信息甚至也会评估用户收到的各种提醒以及别人的评论信息。机器学习团队同样利用深度学习打造了一系列「优雅」理解文本的算法。这些算法整合到我们打造的机器学习平台里，用于加快推进和大规模实现从训练到部署的过程。Facebook所有采用机器学习的产品都会使用这个机器学习平台。如果你想理解机器学习在Facebook有多流行，我举个简单例子吧，超过20％Facebook工程师（甚至非工程师）都是这个平台的活跃使用者。我们现在研究的方向包括用于预测事件的深度学习模型、用于稀疏模型、深度学习的分布式复习系统、通过卷积和递归网络进行文本理解的表征学习以及通过多任务学习的模型压缩。关于学习：你学习机器学习的途径是什么？在学习机器学习时，你最喜欢哪一本书？我最初接触机器学习，是在我作为一位电信工程本科生学习高等非线性信号处理的时候。那是在1995至2000年。我非常幸运地拥有一位很赞的导师，他在个人信息在 Prof. Anibal Figueiras-Vidal这网站上。他解释到你可以怎样使用神经网络构建自适应的、受训于观察到的数据的非线性过滤器。于是，我就入坑了！&nbsp;我写的硕士论文是关于稀疏的径向基函数分类器。在那时，支持向量机风行一时，它似乎就像稀疏性是模型为了提高广泛性而应该具备的合乎要求的性质。我还记得你总是会评估你根据UCI repository的数据集创造出的算法。有趣的是在我们后来的学术生涯里，我警告过不谨慎使用稀疏模型的缺点（见see the dangerous uses of sparse Gaussian Process priors），并且我曾在行业里寻求一份gogn zuo，以能生成由机器学习应用程序产生的新的有趣数据。

如果我不得不指出一本非常有影响力的书，那就是 Chris Bishop’的第一本书： Neural Networks for Pattern Recognition (1995)。其中第十章「贝叶斯技术」真的很对我的胃口，也是我至今仍对贝叶斯倾注热情的产物。然而正如我经常所说的，「一位真正的贝叶斯派不可能彻底是贝叶斯派：你需要优先保留一些余地，因为有可能贝叶斯方法不是正确的。」

在我花了6个月时间拜访丹麦科技大学时，我非常幸运地在2000年偶然碰上 Prof. Carl E. Rasmussen 。Carl是一位贝叶斯派，向我介绍了神经网络的贝叶斯处理方法和针对近似推理的蒙特卡洛马尔科夫链抽样方法。他也向我介绍了高斯过程，我写的论文就是关于这个。我最后回到了丹麦，在Carl的指导下攻读博士。&nbsp;这些天，我会犹豫要不要给人们指出特定的书（有太多杰出的书了）。我坚持建议人们观看视频演讲。如果你在YouTube上搜索你想了解的任何主题，你将发现由顶尖学校的一流教授提供的丰富的视频演讲。给你一个具体的例子：我最近需要掌握更多计算图像学知识，找到了Bill Freeman的很赞的入门介绍。我最近还想综述自然语言处理的简介，就找到了Dan Jurafsky 和 Chris Manning的很赞的入门级讲座。&nbsp;如果你坚持读下去，这里是一本极大地激励了我的书，是Jaynes的《概率论：科学的逻辑》（这里是供你阅读的pdf版本： pdf version）那本书提倡使用概率论作为科学推理的语言，在我们如何探讨概率推理方面给人很大的启发，也对机器学习非常重要，而且近来这些天当我们思考人工智能的未来时，也会从这本书获得相关联的哲学启发。&nbsp;我也会鼓励人们立刻动手。如果你是Matlab用户（我以前是！）或者使用Python（当然你会用的），有许多应用程序包基本上是实现所有事情。然而对于很多算法而言，你可以编写你自己的程序工具，那是你真正要学的。团队招人时，你看中的是什么？我看中的是技术实力和性格。寻找的人是这样的：任务驱动型的。人们需要完全投入最终目标。适应不确定性。无私与合作。ML黑客。强大的背景条件。在应用机器学习中，什么是更重要的：数据，基础架构还是算法？首先让我们确定目标：在应用机器学习中，成功意味着将机器学习系统对实际应用的影响最大化。例如，通过我们的广告排名系统将拍卖的总额最大化，广告排名系统是由机器学习系统驱动的，能预测广告与受众的关联程度。拍卖价值将被两件事积极影响：预测的准确性。候选广告的数量。候选广告能通过大多数精确的预测器（经典的是严格的延迟约束器，能更快的激活级联途径，是通过更不精确的预测器精选候选广告）来估价。我们需要将精确度最大化，同时将在服务时间进行预测的计算工作量最小化。让我们现在聚焦于最大化预测精确度。机器学习系统典型地有一个实验组件，旨在设计和训练模型。我们已经发现最重要的属性是实验速度。一个团队能在单位时间内完成的实验越多，他们就能取得更大的进步，建立更好的模型。我们努力应用机器学习，一直以来遵循「每周扬帆前行」的口号，做出了伟大的成果。为了每周至少能给特定应用输送一个生产模型，你需要管理几十个现场实验，每周执行成百上千的线下试验。极佳的基础架构、平台和工具对应用机器学习是必不可少的，既要最大化实验速度，又要最小化在服务时间的预测成本。&nbsp;现在，让我们转向数据和算法问题。我们的哲学理念将问题分出了轻重缓急，下面是按重要性从高到低排列：数据：尽你所能地得到大量数据，确保这些数据是最高质量的。就我们的经验而言，数据会以出乎意料的、不同寻常的方式变得杂乱。我最喜欢的一个故事是，快速重复点击以增加impression（译者注：impression是网站分析的最基本度量之一），这偶然不会起作用，因为存在一个假设是点击被报告给处理impressions的同样的数据中心。特征工程：做大量的和它有关的事。提取你的数据，浓缩为有最大化预测力的信号。构建尽可能自动化的工具（自动化特征选择时常在后台运作，保持CPU的效用最大化）。我必须强调深度学习的来临正改变者游戏：当使用更简单的算法特征工程是关键的时，深度学习的承诺是它允许自动化地学习表征（例如特征）和你能馈送给它原始数据。一些明显的例子是DeepMind的令人惊讶的工作，也就是纯粹基于屏幕上的像素学习玩耍经典的街机游戏，而没有做任何特征工程。深度学习通过自动学习表征也已经引发了计算时间和语言技术的革命。还是那样，在实际应用中，依赖机器学习的产品团队定期通过特征工程仍有重大收获算法：一旦你拥有了针对特征工程的最棒的数据和工具，就要保持提升你的算法能力（同时要保证这些算法是广泛推广的）。在Facebook，我们定期输送新的具备更大生产能力的模型，但是值得注意的是，只有当训练数据的数量一路增长，而且表现力（包括训练和在服务时间的预测）没有退化得太多以致于抵消了增长的精确度带来的益处时，这才有意义。我们总是将来自更复杂模型的精度收益与在做预测时增加的CPU成本相比较。这意味着我们经常使用最简单的可以完成工作的模型（从计算效率角度来说）。总结：在应用机器学习中基础加工是至关重要的。然后，你应该聚焦于拥有尽可能是最好的数据，做大量的特征工程和使用最简单的能完成工作的算法。深度学习如何影响 Facebook 今天的产品？2012年基于深度神经网络的方法在 ImageNet 分类比赛中获胜之后，深度学习引起了很大的反响。神经网络已经在机器学习中应用了相当一段时间，但具备更大容量和远远更多数据的深度神经网络带来了变革并显著击败了其它较浅的模型。这一运动开始于计算机视觉，并快速扩张到了文本理解、机器翻译和语音识别领域。&nbsp;Facebook 拥有一个单一的使命：创造一个更加开放和互联的世界。随着我们开发出让人们可以分享更多的工具和产品，理解用户的内容并向他们提供最大的价值就变得越来越重要。这意味着，高准确度（精度和回调）、低延迟和更快速的创新。深度学习在所有这些方面影响我们的产品。它被用于文本、音频、照片、视频甚至交互的内容理解中。嵌入式的深度学习被无缝整合到许多产品组中，这使得他们能更专注于核心产品，同时又指望我们团队（机器学习应用产品组）提供可用于多种任务的可能最好的嵌入产品。&nbsp;除了提供嵌入产品，深度学习也在被应用在一些端到端产品中，如用于视频字幕的自动语音识别、为盲人配音的核心视觉识别引擎、让你可以将数百种语言翻译成英语的机器翻译。为什么 Facebook 要投资（大量）人工智能/机器学习？没有人工智能/机器学习，Facebook 就不能存在。

人工智能是 Facebook 已有的工程工作的自然延伸，这是向我们的社区提供好体验的关键部分。每天，这个世界都在产生越来越多的数据——文本、图片、视频等等。为了做到有用，我们需要帮助你梳理所有这些信息，这样你就可以看到你想看到的内容，并更高效地和他人交流。&nbsp;回答这一问题以及有关人工智能和机器学习领域更多具体应用研究工作，请见：What are the most interesting things Facebook is doing in ML research?你怎么看待当前深度学习上的炒作？我不认为这是炒作。&nbsp;人们已经在它上面进行了几十年坚持不懈的努力，但有有意义的先验的非常庞大而复杂的神经网络释放了表征学习（RL：representation learning）的力量，得到的结果极其优于那些通过手动输入特征和传统算法的结果。正如Yoshua Bengio 和 Yann LeCun 在他们最近的 NIPS 2015 教程中解释的那样，算力与训练数据的数量和质量的急剧增长是表征学习和深度学习成功的关键。&nbsp;回到表征学习上，它是真实的。过去几年这方面已有许多最新的突破性进展可以归功于表征学习。这些都已经在计算机视觉、语音识别、自然语言处理等领域实现。所有这些领域都拥有一个特征：输入信号是传感器信号。表征学习使用深度神经网络（DNN）架构学习这些传感信号的分层特征表征。这些表征最后表现得比人类施工的和高度精制的功能好非常多。那并不是关键，但这样的架构远远地近似于人类大脑中学习和执行认知任务的方式。&nbsp;比如在Facebook，我的朋友和同事 Ahmad Abdulkader 与我们的广告团队合作开发了能够自动检测出违反我们政策（例如包含暴力、酒精或武器）的有图片广告。在这一任务上使用深度学习在精度上带来了显著的提高，并最终保护了Facebook 社区免受潜在的不良内容的影响。我们的计算机视觉团队已经开发了一个供几十个团队使用的自助服务平台，以帮助他们在通过使用深度学习学到的图像和视频的表征的基础上训练专门的预测模型。Manohar Paluri 可以告诉你更多有关 Facebook 用于计算机视觉的深度学习应用。&nbsp;表征学习也还有一些尚未取得突破的领域，尤其是那些输入不是传感信号的领域。它是否还能取得那样的突破，尚有待观察。

说到这么多，学术界、业界和媒体需要谨慎对待夸大的结果、对可能带给机器的「智能」式未来的过度解读、以及机器是否以某种方式取代人类的严重后果的警告。这更接近科幻而不是现实 :)为大型公司制作可通用机器学习框架所带来的重要经验有哪些？打造通用机器学习框架很艰难。机器学习与人工智能如今进展层出不穷。这让任何通用机器学习框架不停地处在测试之下，甚至许多都已经废弃。另外，灵活性与规模以及灵活性和可用性与之间一直有着强烈的压力。这些都是一个总体框架所有需要考虑的重要权衡。&nbsp;在下面我会分享一些我们在制作Flow的时候的学习经验——也就是我们的通用的机器学习系统。工程师利用Flow去制作机器学习通道，以训练深度学习模型、大规模逻辑回归、决策树等等。Facebook的所有这些模型每周都会从实验环境部署到生产环境进行数次，并且被Facebook的很多团队调用。深入理解你的应用场景：许多通用机器学习框架经常会突出强调某一个场景。在Flow，我们理解我们有两个主要的观众。其中一个写出新的通道，另一个通过添加新数据来消耗它们。我们确定了我们为这些场景中的每一个都提供了良好的体验。打造多层平台：良好的平台会从「use it all」和「lose it all」等场景中保护它们的用户，好的假期会提供很多抽象层。最外层提供最好的经验，但是如果用户不知道他们到底想要什么，他们应该降低级别去达到想要的。速度，速度，速度！对于企业中的机器学习研究，让你设计的想法得到支持和许可都必须在保证速度的前提下。数据经常会很巨大，并带来降低创新的瓶颈。默认可重用：无论何时工程师在Flow写了新的东西，都可以被公司里的其他人所重新利用。这意味着工程师有着超越以前的指数式增长的创新力。准备写第二个版本吧：如果这是你的平台第一个版本，准备好去重新写一个吧，因为这里面隐藏着许多错误和坏的概念。不停地探索直至你认为这是个正确的时机去进行重写，但是在这之前要确保你进行了足够的讨论和探索，比如要达到更好的架构。避免过早推广：在你尝试将产品通用化之前，确保你有2到3个具体的重度使用场景。如果你在未成熟的时候就通用化，你也许会失去一些重要的价值，减慢发展速度。记住，如果这是你的第一个版本，你总会需要重写的，因此千万不要提前通用化。做一个算法不可知论者：机器学习经常会着眼于一个或另一个机器学习算法。在Flow，我们决定在这个平台上「欢迎所有的算法」。我们支持并创造了几个可用于Facebook的算法。但是平台是对所有算法公开的，因此可帮助Flow通用于任何出现的新算法。统一带来的好处：算法的多样性是极度有利的。也就是说，一个统一连接这些算法的系统会非常强大。比如你研发了一个算法，且这个算法对于广告和搜索结果展示具有神奇的效果，

接着你可以执行一个Flow的有着标准化界面的算法算子（广告和搜索排行通道都调用了这个算子），结果是它会变得更好。再比如你已经研发了这个算法更强力的版本，不需做太多改变，你就可以用所有通道上的新算法进行实验，调用算子并方便地使用它。由此，我们的应用研究员可以将它们的影响力迅速扩大至整个公司。如果你的余生只能够用一个机器学习算法，你会选择哪一个？我真希望我身在能够回答这个问题的时候！解决机器学习的问题仍然需要人类在整个进程中绝对的参与：制定机器学习任务、定义度量以进行优化、预测数量、评估可用数据和收集附加数据，选择适合于手头的预测任务的模型池中的模型。当然，然后还会有计算有效性的考虑。如果模型需要作为机器学习的一部分在生产中运行，边际计算复杂度所附加的任何精确性都必须超过附加成本的消耗。换句话说，精确度不仅仅是唯一的标准：计算成本也是重要的一个。

我在剑桥大学的朋友与前同事所做出的一个令人振奋的努力正是我希望机器学习所前进的方向。他们的想法是自动化数据分析。另一个激动人心的方向则是ICML2015工作室所激发的「Auto ML」趋势，后者旨在尽可能自动化人类在机器学习中的参与。

没有任何理由能够说明，我们不能创造一个基于模型和预测任务的自动化数据分析和机器学习的人工智能。&nbsp;在一个更有趣的发现中，我逐渐开始使用许多模型中的高斯法和贝叶斯法，如果后期和预测分布难以实现时，这些方法可以利用MCMC以获得近似推理。我的兴趣仍然在于利用这些模型以及推理方法。尽管这并没有让它们成为我会在余生中唯一使用的算法，但是它们一定是很有趣的算法，并且回馈以大量的智力乐趣。产业领域里的机器学习研究和学术领域的机器学习研究，有什么不同？产业和学术领域的机器学习研究，很多相同点和不同点。我近十年来都在产业领域工作，因此，接下来的观点将更多地受到产业观点影响（多过学术领域）。不过，需要注意的是，我和学术领域保持着密切联系，也欣赏我们团队发表的论文，热衷组织和参与研讨会和会议。&nbsp;现在谈观点：&nbsp;数据：产业领域接触到的数据通常比学术领域多得多。不过，随着互联网的发展，这种差异在日益减少，但还是有一定差距。这也意味着学术机构的研究侧重于小规模的数据集，无法反映产业需要的解决问题。不过硬币的另一面则是，这些小数据集可以更方便迭代，从而帮助学术机构更快地获取研究灵感。

工具和基础设施：企业能够投入更多资源构建工具，能够保证在应对大规模需求时还能快速进行原型设计。在企业里，你可以更方便低于工程师和机基础设施专家合作，他们将帮助你搭建一个更坚固的研究基础平台。大量稳定的工具也可以保证你的研究可以快速移植。&nbsp;速度：对产业领域来说，时间就是金钱，因此速度非常重要。这里的工程师和研究人员通常会优先考虑速度和产品部署的频率，因为一个产品的目标就是一段时间内，在总体上最大化产品的影响。更快的迭代可以让你探索更多新的可能性并忽略一些没有承诺的开发方向。&nbsp;目标驱动力：产业研究有着非常明确的目标驱动力。这就是通过实现研究的商业化，来进一步推动产业对于研究的投入。在可落地实施的范围而后，综合考虑成本以及如何与现有产品体验的融合，是产业对于创新和研究投入的重要考量点。这里必须要提到一点，研究机构在创新方面的重要作用，由于产业倾向于一些短期技术的研究，研究机构承担了大量颠覆性技术的研发和创新。&nbsp;简单：在学术界，发表论文是主要的衡量成功的方式。论文作为一种强制作用，以一种结构化方式帮助新观点产生效果，也鼓励了那些在实践中运行良好的新奇事物。产业界往往在简单的一面犯错，因为大规模操控复杂系统是花费不菲的。&nbsp;对上述事情持非黑即白的观点总是错误的，因为在产业领域有一些让人惊羡的研究者，在学术界也有令人佩服的工程师，这使得不同领域的重大突破成为可能。理想的化学组合是产业和学术共同合作，取其所长，推进领域发展。你如何在工作日程中安排长跑？我每年跑几次马拉松和超级马拉松。也喜欢和朋友跑步。&nbsp;这些天我平均一周跑50多英里，让跑步和工作安排不冲突的方法就是很早起来跑步。几乎每天，我都是在日出左右开始跑步，有时从家里开始，有时和一些爱跑步和喜欢早期的同事从单位开始跑。我们在工作地点淋浴，而且我喜欢跑步后在公司吃早餐。&nbsp;清晨跑步，首先对我来说是有利的，完全清理了我的内心，这有点像冥想，然后我以宁静、安详的状态开始这一天。许多问题在前天晚上看上去似乎很可怕，跑完后，似乎完全在掌控中。对励志在产业领域从事ML/CV研究的PhD候选人，给予一些指导。为产业研究职位做准备的一条最佳方法是，当一次或更多次的暑期实习生。这会让你走出只需要做论文研究的学校氛围，进入这样一个环境，其中，影响力、快速成型和与其他团队深入交往不仅普遍而且重要。&nbsp;产业实习生允许你与其他有经验的导师工作，得到广泛经验，学到更多技术。有时，实习经历只会写入你未来的出版物中，但是，有时你将对一个重要的新功能或能力做出贡献。提前询问实习机会，这对你很重要。&nbsp;在实习期间，还有在学术研究期间，你会在扎实的软件工程实践中变得熟练。一条途径是使用和贡献开源软件。你的同辈将给你反馈你的代码质量和可用性如何。试着在团队中做一些你的研究。产业研究很少独立完成，因为有太多外部因素需要团结合作去创造真正的影响力（例如：输送新性能或产品）。试着做一些项目，所以你能得以拓展你的科技知识。最后，就你的工作向大量听众举办大量演讲，一些听众可能不是你专长领域内的人。但能推销你的工作给非专业领域内的人（包括非专业领域的导师），对你成功的产业研究至关重要。

如果你打算追求学术生涯（终身教授职位），那么在某个主题上非常专业且在某个理论上很善长，而不是精通动手操作和实验，这是非常好的，但这对于大多数产业研究职位而言，并非特别有用。你如何看待开放人工智能？我们欢迎他们来到这一社区，期待看到研究进展以及它们的最终回馈。&nbsp;不过，我会补充说，我们取得的人工智能进展，现在已经是一个非常公开的过程。科学研究力求研究者的交流促进。互动社区越大，进步也就越快。&nbsp;在Facebook，我们想要让人工智能研究者更容易分享方法和技术。我们有一个大体上支持开源软件和硬件的文化，而且FAIR（Facebook人工智能研究）和AML（应用机器学习）已经继续兑这一文化承诺：以学术论文的形式发表他们的发现，开放网站上可免费获取。我们绝大多数的项目代码成为开放资源，最近也开放了一个人工智能硬件设计。对机器学习非常陌生的工程师/学生而言，什么才是最关键的？机器学习包含非常广（且深的）科学和工程学科子集。所以想通透了解该领域就要花费点时间，需要常年累月持续学习，特别是当新算法和想法正不断被研究时。&nbsp;在某种程度上，机器学习类似于统计数据，试图从大量数据中推断出结论或者模式。但另一方面，它更像计算机科学，需求高效的算法和表达方式。&nbsp;我个人最喜欢的是Chris Bishop的《 Pattern Neural Networks for Pattern Recognition 》。当然，还有一些其他很棒的书，包括来自Coursera, Udacity, edX等的在线课程。但是，如果自己不做很多实验，几乎不可能学会机器学习。&nbsp;尝试书本或者讲座上布置的练习，花些时间。貌似投入很多，但是，如果你想长期呆在这个领域，你需要积累很多知识和直觉，知道适合每个问题的技巧和方法。你也要持续学习，因此，获取学习新材料才能然后吸收之并付诸实践会非常重要。&nbsp;变得精通合适的实验和证实方法。在某些工程领域，你可以遵循指导手册或者通过非形式推理验证正确性。在机器学习中，「正确答案」往往很少。因为你所做的就是从不完全信息中做出最好的推断（打趣地说法就是「做出最好的猜想」）。你不仅要设计出综合数据的单元测试，挑出代码中明显的bug，还要在更大的数据集中不断测试。这是一个非常大的挑战，因为得到正确答案非常的难（这叫做标记数据）。 &nbsp;最后，紧跟最新研究，积极参加这个领域的年会。如果你刚步入这一领域，这是一种非常棒的方法了解这一领域的研究和技术深度。（年会往往会有很好的导师会议）如果你有经验，你可以借此建立与研究人员和从业者的社交网络，从而了解最新的技术和科研成果。Facebook机器学习团队不招非PhD？不，并非如此。虽然在多数情况下，PhD能帮助你学习如何做研究。Facebook的每个团队都有非PhD的人做机器学习，方向都不同。&nbsp;我们想知道，诸如Facebook有先进的机器学习算法的地方，是否还需要一些更加简单的算法？&nbsp;在Facebook中，我们尽可能用最简单的算法完成工作。如果预测精度有效，简单的算法就意味着更低的计算成本和更简单的调试。同时，创造性的简单算法也可能惊人的准确。在我们有关广告数据实验的论文中，我们对这些结果做过解释。&nbsp;就像我的朋友艾哈迈德·阿卜杜尔卡达尔(Ahmad Abdulkader)说的，「总有对更简单算法的需求。」事实上，更加简单算法比复杂算法更受人推崇。复杂算法总是要靠准确性的大幅度提升予以合理化。&nbsp;也有一些领域，更简单的算法也受到欢迎，即使它们的准确性不如复杂算法。比如，较之复杂算法，在很多机器上分布一个LR学习算法要容易地多。结果，LR胜出。&nbsp;简单的说，我们在需要时才用复杂算法：一些实例应用的领域，比如计算机视觉、机器翻译、文本理解和语言认知等。在这些领域，深度神经网络在预测准确性上有大步提升，所以使用它们无可厚非。在Facebook，有哪些不明显使用机器学习的地方？在《What are the most interesting things Facebook is doing in ML research?》中，我曾经给出过几个明显或不明显使用机器学习的例子。

我分享一个可能不那么明显的使用机器学习的例子。&nbsp;Facebook的 Accessibility team已经运作四年了，最初是专注于让Facebook已有产品让每个人都能使用。但是现在，它专注于为残障人士打造新产品。这个团队关注的一个对象就是盲人和视力丧失群体。因为Facebook是一种视觉上的体验（如同大部分互联网），我们需要尽可能的在创新上做投资，让Facebook的体验更好。我们在AI领域，以及诸如物体识别这些计算机视觉特定领域的投资，能够让更多人接触到科技。你的生活平衡地很好，如何做到的？哇，这个问题的前提假设是我已经很好地平衡了我的生活！:-)

我不断地尝试平衡我的生活。有三件是对我很重要：我的家庭我的工作保持身体上的健康我觉得关键词是效率。依靠「习惯的力量」让我变得有效率。每天早晨我都会按固定路线跑步，有时会和朋友一起跑。同样的跑步习惯（时间、地点）让我们不需要花费时间做计划。在家里，我和妻子会提前协调好家庭与工作时间，避免突发事件。&nbsp;最后，我认为抽时间做计划是很重要的。为了看到更远的场景，后退一步是有必要的。你想要什么？什么事你会高兴的拒绝？（为了得到重要的一些东西，对很多事你都要说no。)你会怎么描述Facebook文化？我在这里工作最喜欢的就是Facebook的文化。我经常把我们的文化和价值观分享给新职员。&nbsp;我们的价值观很好的体现到了我们的文化：建立社会价值观：我们是一家任务非常明确的公司。我们每天早上来到这里工作不只是为了让这个世界更加的开放与连接，而是为了在人类生活中创造价值。在Facebook中有个团体叫「Go 365!」我就是这个帮助、鼓励跑步新手的团体中的一员。我加入两年了，总能见到队员对马拉松新手的鼓励和支持。快速行动：我们是建造者（builder）文化。我们会尝试、会思索。我们也会犯错误，事实上我们也鼓励犯错。你如何进步？我看到很多很棒的系统在快速力量驱动下成长起来。如果它们值得构建，我们会重点查看缺陷之处，往最佳的方向改善。大胆：「最大的危险是不冒危险。」有一个有趣的不对称现象，我们人类倾向于高估我们不了解的现状。这是棘手的，因为我们周围的世界变化得太快，而且我们目前的解决方案、产品或系统可能在新环境中不再有关联或是最适宜的。引用一个我欣赏的例子，Amazon的几年前做出大胆举动，大举投资Kindle。这个产品直接地攻击了他们既有的商业模式。保持开放：这可能是我最爱的价值观。保持开放帮助我们利用集体智慧，因为没有人有所有的答案。它也帮助减少意外，增加信任（记住，「意外是信任的敌人」）。最后，一个开放的反馈式的文化帮助每个人得到提升，变得更好。关注影响力：总是有很多事情要去关注，但是就像大自然教给我们的一样的，将我们投入的大量精力的影响力最大化，非常重要。在Facebook，我们努力建立自下而上的文化，每个人都感到有责任理解围绕他们的影响力在哪里，并将自己的工作朝向它。最后，在Facebook，我们有一种「传播爱（ship love）」的文化，这是一种方式，说出我们在这里服务于15亿依赖我们构建工具和产品的社区。如果我们不爱这些人，我们不可能为他们服务。有了H2O.ai（用于商业引擎的人工智能）、Azure机器学习、数据机器人，你如何看待机器学习大众化浪潮？许多研究表明，机器学习工程师/研究员供需存在巨大缺口。一些人甚至预期这个缺口将继续扩大直到2019年。结果，机器学习「大众化」的努力可能造成巨大的影响，而且对这些工具而言，也可能意味着巨大商机。&nbsp;现有的成套工具似乎早已意欲达到这样的平民化。他们倾向于将重点放在帮助数据科学家达到他们的目标，主要是在企业环境里。&nbsp;在Facebook，我们在 AutoML这个方向做出了认真的努力。AutoML也是在许多机器学习领域（ICML，CodaLab等）获得了大量关注。这似乎是更有前途的方向，而且我的朋友和同事Ahmad Abductkader正积极地与我们的一些产品小组合作，致力于让国内机器学习大众化，尤其是帮助新的小型团队落地机器学习。Facebook 的各种应用中使用了怎样的神经网络拓扑结构：有多少层，等等？在Facebook，我们的目标是用最好的人工智能技术驱动产品。最好的有时候就是已经存在的，很多时候都是我们内部为 Facebook 量身定制的。有时候我所在团队（机器学习应用组，我们的应用研究机构）和 Facebook 的人工智能研究组（FAIR）肩并肩合作，我们也与我们的产品团队有密切的合作。&nbsp;我们使用的神经网络拓扑结构和我们在各自领域首次展示中所发布的类似。它们根据应用的不同存在差异，基本上都是深度卷积网络、全连接网络和递归神经网络。在基于文本、照片和视频、语音等应用上，我们也使用它们的组合。

我们的这些团队必须解决许多有趣的挑战。比如，我们通常将我们的数据视作一种流，而不是将其看作是几百万个样本的静态数据集。这让我们能够随时间学习更大的模型，拓扑结构也随之不断进化。另一个有趣的挑战是可能最好的模型也许并不是大规模运行时可行的模型。所以，我们总是会在模型的容量和计算与精度之间进行权衡。&nbsp;我们已经公布了各种研究结果，并且我们对组成链式或树状的多个模型的拓扑结构非常感兴趣，在这样的结构中，更快但精度更低的模型先运行，然后再给更慢但更精确的评估数据的子集的模型让路。这是一个正在进行中的研究课题，也是一个我们因为我们的数据规模而必须要解决的重要问题。另一个例子是视频，在这一应用中，可以应用基于图像的模型，我们可以使用一个连续的模型融合来自视频帧的信息，或我们可以慢慢地使用空间-时间卷积融合时间和空间信息。&nbsp;我们发表了使用这样的网络的学习功能上的发现，并展示了其通用化的能力。总之，随着我们研究越来越多并尝试找到精度、速度和内存之间的平衡，我们的拓扑结构也一直在不停变化；而我们也将积极公布这些发现。毕业之后有哪些好的机器学习课程可以参加？http://videolectures.net/是一个很赞的资源，上面有很多关于「机器学习」、「人工智能」、「大数据」、「计算机视觉」、「自然语言处理」以及更多与机器学习相近的主题。&nbsp;Udacity 和 Coursera 提供了完整成熟的课程，一个人可以以有限的知识开始一个领域的学习并在课程结束后取得相当的进步。我个人很喜欢吴恩达、Jeff Hinton 和 Daphne Koller 教授的课程，但我确信随着深度学习和机器学习在业界变得越来越重要，这些课程设置也在不断进化，资源也在不断增长。我问了问我们团队其他人最喜欢的课程，我的朋友和同事 Manohar Paluri 向我指出，比如说，乔治亚理工大学在线课程Pushkar Kolhe 和 Charles Isbell 与 Udacity 联合教授覆盖了机器学习的基础知识。&nbsp;爽的是大多数/所有这些资源都是免费的！在学习这些视频时，另外还很重要的是要亲自动手鼓捣代码，看这些东西是如何运作的。鉴于Torch、Caffe、Theano、TensorFlow这些工具已经可供下载，而且同时支持GPU和CPU，实验就是很简单的事情了。深入到这些代码中始终是快速学习的好方法。你怎么看待对话引擎（conversational engine）的未来？对于对话和口语接口来说，现在是一个激动人心的时刻。但还仍然非常早期。Siri 和 Cortana 这样的个人助手提供了简单的任务完成和搜索引擎和自然接口。对于 Facebook，我们相信大机会在人们与 Facebook 本身的交互之中。如果你想想人们使用 Facebook 的方式，这里每天都发生着数百万计的多路对话。使用对话理解和会话技术，Facebook 自己可能就能参与到这些对话中，而不只是被动地协助他们；我们还希望通过挖掘存储在 Facebook 图片库中的海量知识来增加价值。

如果你对 Facebook 的对话引擎和语言技术感兴趣，你可以在 Quora 上关注我的朋友和同事 Alan Packer.Facebook 目前怎么使用计算机视觉，又计划在未来怎么使用它？最近几年 Facebook 上的媒体内容分享和消费出现了巨大的增长。人们从文本转向了照片，而且从照片转向视频的过程正在进行，而且我们已经看见了虚拟现实/增强现实的影子。过渡到照片标志着计算机视觉作为一种重要工具的出现，而且随着我们转向视频和虚拟现实/增强现实，计算机视觉的发展动力还在不断快速增长。计算机视觉将在理解这些内容的公司中扮演至关重要的角色。它将不只能帮助理解，还能提供更加丰富和更具创造力的方式来分享你的经历（视频防抖、实时美颜等）。&nbsp;目前，有许多产品组使用了由计算机视觉系统提供的技术。这项技术被用于更好的搜索、用于辅助的图像字幕、打击垃圾和不良内容、筛选出违反我们政策的广告给人工审核、制作人口密度图、确定 Instagram 趋势、检测纪念日和重要时刻相似的照片等。每一个接触照片、视频和虚拟现实/增强现实的产品组都会利用来自计算机视觉组的信号。&nbsp;计算机视觉未来也将在 Facebook 及其各种产品的使用中发挥巨大的作用。想象一个简单的例子：我们向部分人开放了视频直播并已经取得了良好的使用。当我们将其开放给我们网络上的十多亿人时，将会出现数百万个并行的频道。这种信息爆炸意味着让用户能在相似的频道间切换和基于文本搜索直播视频等是非常重要的。&nbsp;Facebook 的本地搜索由人们的经历驱动，我们可以很出色地完成给出旅行、餐厅和周边事物的个性化建议的工作。围绕这一工作的大部分内容都是照片和视频。下一代虚拟现实可以使用由内而外的跟踪，这是计算机视觉的核心问题。随着计算机视觉越来越好，随着我们了解照片和视频中内容并开发出强大的视觉表征，我们将有能力推动目前甚至还没在 Facebook 平台上出现的新领域。&nbsp;如果你想询问关于计算机视觉及其在 Facebook 应用的具体问题，可以试试在 Quora 上向我的朋友兼同事 Manohar Paluri 提问！&nbsp;我们以前使用的是微软必应翻译服务，但最近我们已经使用我们自己的数据训练的自己的机器翻译技术进行了替代。我们这么做的主要原因是我们发现 Facebook 帖子和评论的语言与其它网络都不同：它非常俚语化，非常区域化，是非正式的人与人之间的交流而非文件或专业写作。所以，调整这项技术适应 Facebook 的语言并训练我们自己的数据让我们可以开发出更为精准的机器翻译。Facebook 怎么识别照片中的人？当你将照片上传到 Facebook 时，我们专门的面部识别服务器会将其选出进行处理。&nbsp;第一步是定位图像中所有的脸（也被称作人脸检测）。这一步的结果是一组线条框将每张脸圈了起来，非常类似于我们网站上作为标记体验的一部分的标记框。现在我们知道了图像中所有脸的具体位置，我们继续第 2 步——识别。

对每一张脸我们运行专门为这一任务训练的机器学习神经网络。这一网络会为每张脸输出一个数字表示。一种思考这种表示的好方法是将其作为高维空间中的一个点（坐标列表）。一个好的表示方法可以将同一个人的不同面部照片映射到这一空间中的同一区域，同时还能保持这些区域（其中每一个都代表不同的个体）之间很远的间隔。我们实际上为每一个人都创建了一个专门的模型，这样我们可以快速确定一张给出的新面部照片是该位于这个区域之内还是之外。&nbsp;最后一步是收集你和你朋友所有可用的面部识别模型，然后将上传的照片中每一张脸的上述表示和这些模型进行比较，然后选出最佳匹配的候选标签作为你的标记建议。所有这些处理在上传后很快就完成了，足够及时让你在写你的帖子时看到这些标记建议。

如果你想了解更多关于 Facebook 的面部识别的信息和我们接下来的开发计划，可以试试在 Quora 上向我的朋友兼同事 Tommer Leyvand 提问。"
"人工智能;;专访Geoffrey Hinton：人工智能会继续发展Geoffrey Hinton 可谓深度学习领域「教父」级的人物，正是他的坚持和创新，使得神经网络再次迎来复兴时代，成为推动人工智能发展的新动力。MACLEANS的Adrian Lee对其进行了专访。在这篇访谈中，Hinton不仅谈到了他对这次人机大战的看法，也解释了深度学习的未来，为什么人们不应该害怕人工智能，以及到目前为止，人工智能所取得的成功是否证明了他的观点和想法是正确的。问：你对Alpha Go 获胜有什么看法？答：激动人心。为了这场比赛，我常常熬夜到凌晨两点看直播。在AlphaGo第一次对局李世乭之前，其实我们根本不知道AlphaGo是不是有些不清楚的致命缺陷。在第四局的时候我们看到了一些它的弱点。总结来说，它非常的让我们振奋。每个团队里的人都在比赛之前认为AlphaGo会赢的，但是没有人确定。幸运的是第一局并没有出现第四局的情况，如果AlphaGo输了第一局，他们会相当紧张的。问题2：人工智能取得了围棋的胜利为什么意义重大？答：围棋很多时候取决于直觉。真正优秀的棋手会在眼中看到哪里适合放置下一个棋子。他们也会做大量推理，也就是算棋，但是他们最出色的还是神乎其神的直觉，而这正是人类觉得计算机无法做到的。但是有了这些神经网络，计算机也可以做到这点。它们可以思考所有可能的落子方法，并依靠直觉决定其中一种优于其他所有。这正是feed point neural network所做的事：它给了这个系统类似于真正棋手的直觉。接着它可以尝试所有的替代方法。神经网络为你提供了好的直觉，这是其他系统所缺少的，这也是人们还没有理解计算机到底能做到什么的原因所在。问题3：在2014年，专家说过人工智能或许在未来有一天能够在围棋中获胜，但是主流思想是在那之前至少需要十年的时间。很显然，他们低估了人工智能。那么你在那时猜想过它会发生吗？答：我当时觉得如果有一个非常优秀的团队，管理有序，然后用一年的时候努力推进这项研究，并且利用神经网络，也许你可以做到，当然这只是一种可能性。但是Deep Mind团队真的做到了，因此我很惊讶他们的速度。问题4：那么下一步，人工智能又想去征服哪一个更加复杂的游戏呢？答：从我们对于棋盘类游戏所得来说，我不认为还有其他——我想这真的是一个里程碑。当然还有很多其他游戏，在这些游戏里你与其他和你对话的人物作出反应。人工智能仍然无法处理这类游戏，因为它们还不能很好地理解自然语言，但是它正在进步之中。现在所用的翻译手段一定会有所改变，因为谷歌承诺会研发更好的机器翻译技术，这是发展理解自然语言的一部分，并且会有着深远影响——它会影响幻想游戏等等，但是它也能让你更好地进行检索，因为它可以更好地理解文件的意思。其实它已经在影响很多东西了——在Gmail里有Smart Reply，后者可以辨别快速回复的邮件，并在它认为合适的时候给你替代选择。它们做的很好。你也许会认为它是一种大量数据存储系统，类似「如果邮件是这样子的，那么这是个不错的回复，如果邮件是那样子的，那么他的这个是个不错的回复」。实际上它合成了邮件里的回复。神经网络处理了邮件中的所有字句，并在神经元中腾置出内部状态，利用这些内部状态生成回复。它已经用大量数据训练过，在这个过程中熟悉各种回复的格式，但是它的确是在生成回复，并且越来越靠近人类做同样的事的方式。问题5：除了游戏，人工智能下一应用可能是什么?答：这取决于你问的那些人（团队）。在我看来，除非我们的系统中有了如同大脑那样的参数，否则无法达到人类的水平。在大脑中，神经元突触之间有链接，而且会发生变化。你所有的知识都储存在这些突触间。10-15岁时，你大脑中大约有千万亿量的突触，这个数字是非常庞大的。所以这不同于我们现有的神经网络。它们相比大脑太小了，我们最大的也只有大约十亿级的突触量。要比大脑小百万倍。问题6：你能为此做个预测吗？答：这个期限会超过5年，我拒绝谈及超过5年的的任何事情，因为我们无法看清5年后的事。你看过去的预测，比如世界上只有5台电脑的市场(据说是由IBM创始人托马斯·沃森所说）。你知道对未来做太久远的预测并不明智。问题7：对AlphaGo有一种比较盛行的看法就是害怕它会比人类更聪明，甚至会统治人类。害怕深度学习造成的结果会不会是一种非常荒谬的看法呢？答：我认为人们需要明白深度学习在背后可以做到很多事，而且做的更好。它已经用于Google 搜索和图片搜索。在Gmail智能回复上也使用了深度学习，就在语音和视觉领域，我相信不久机器翻译也会出现。而且它还将会用于其他像是气象科学、节约能源、基因组学等领域的重点问题上。所以这就像...只要你拥有好的机械技术，你就能像挖掘机在路上挖坑一样做事。当然，挖掘机可能会撞到你脑袋，但你并不会因此不设计挖掘机，这看起来会非常蠢。显然的，如果它们被错误使用，就会产生问题。任何新科技，如果被坏人使用，就会产生坏的影响。但这更像是一个政治问题而非技术问题。我认为，我们必需像看待挖掘机一样看待人工智能。它在很多事情上的表现都要比人类好。而且要比挖掘机的好处多得多，挖掘机只能在挖坑上帮助我们。当然，你能误用它。问题8：还有一种担忧就是人工智能代表着人类即将被淘汰，害怕人类会因此不可避免的失去工作。答：很难预测5年后会发生什么，但我相信5年内不会发生这种事，而且我也相当自信它不会成为我必需解决的问题。人们可以考虑这种事情。但考虑重点并非是因为技术有威胁就限制它的发展，而是如何改进我们政治系统，防止人们用它做坏事。问题9：在深度学习领域，计算能力有多重要？ 答：在深度学习中，我们使用的算法是二十世纪八九十年代开发的版本。当时人们很看好这些算法，但最终显示表现并不好。现在我们明白，当时之所以表现不好事因为计算能力有限，我们没有足够的数据集训练它们。如果我们想要达到人类大脑的水平，我们需要更多的计算，需要更好的硬件。比起20年前，我们更近了一步，但还有很长的路要走。合适的常识推理使得我们可以预测到这些事情。问题10：计算能力的持续增长会不会让深度学习的应用继续扩大？ 答：在过去的20年中，我们经历了计算能力的爆炸式增长、虽然当时人们说它不能持续，它却做到了。但这里也有我们未曾考虑到的事情。比如AlphaGo，我不确定它使用的计算能力的具体细节，但如果说它使用了数百千瓦的功率做计算我也不会感到惊讶。李世石可能就使用了30瓦，这是大脑消耗的，相当于灯泡。所以，做出更大的神经网络硬件会是关键。而且想拥有高质量的常识，我们需要更大的神经网络，这是我的观点。问题11：在上世纪80年代，人工智能领域的科学家曾经放弃了深度学习与神经网络研究，那么是什么改变了呢？ 答：主要原因是它开始有了效果。在那时，大型实用的人工智能问题没有解决，它也没有取代当时的技术。但是在2009年，我们在多伦多研发了针对语音识别的神经网络，比当时的技术要稍好一些，这一点很重要，因为当时的技术有着30年努力研究的基础，而我实验室里的几个研究生用了几个月就鼓捣出来了一个更好的技术。对于聪明人来说，很显然这项技术必定会取代那时的技术。

后来，谷歌首次将相关研究引进了自己的产品中，在2012年，谷歌推出安卓系统，并且在这个系统里语音识别的效果比之前都要好：将错误率降低到接近26%。之后，我实验室里的学生们利用由其他人所研发的技术并进一步提升了它，在那时其他技术最多只能降低错误率到26%，而我们的错误率可以到16%。在我们实现这个之后的一年，人们说「哇哦，这真的有作用」。他们的质疑态度持续了很多年，也发表了论文批评这个技术。但是几年后，这些人全部都抱住了人工智能的大腿。

几年过去，错误率从16%一直降到大约4%。深度学习已经非常非常好了，并且也让大公司和学术界意识到深度学习学习的巨大能量。问题12：这种知识回归的故事似乎只会发生在科学领域里。作家托马斯库恩谈及「范式转换」时，谈到过这个现象——这些科学革命并不必然产生更好的想法，仅仅是不同的想法。文化层面大体似乎已经失去了这一概念。深度学习回归就是这类只会发生在科学领域中的事情吗？&nbsp;答：我认为，这就是科学和宗教的区别所在。在科学领域中，你能看到看似疯狂的事情，但是，长远看来，你可能是对的。我们能获取真正好的证据，最终，研究社区会苏醒过来。你正在与之争论的科学家很有可能不会苏醒过来，但是，年青一代会改变，这就是深度学习领域正在发生的事情。并不是说老的传统人工智能研究人员们相信这个，坚信这个理念的是那些年轻的研究生们，他们都见证着事情发展的方向。

上世纪五十年代，我年轻时，也有过这样一些体验。我父亲是一位昆虫学家，相信大陆漂移说。那个时候，这无异于胡说八道。到了五十年代中期，大陆漂移说流行起来。有位叫做Alfred Wegener的人在三四十年前就想到了大陆漂移说，但是，他没有机会看到这个学说流行起来。这些学说以一些非常天真的想法为基础，比如非洲契合南美洲的方式，地质学家们仅仅投来鄙视的目光。他们认为那种观点纯属垃圾，异想天开。

我记得我父亲曾经卷入一个非常有趣的争论，有关一只无法行进很远也不能飞的龙虱。你能在澳洲的北海岸线看到这些动物，百万年来，他们无法从一个条溪流行进至另一条溪流。而且龙虱出现在了新几内亚的北海岸线，你在这里也看到了相同的龙虱，只有一些略微不同。这种事情能发生的唯一方式就是：新几内亚从澳洲大陆分离出来并转向相反的方向，新几内亚的北海岸线过去与澳洲海岸线相联。看看地质学家对这一观点的反应，是件很有趣的事情，他们认为，「龙虱不能移动大陆。」拒绝看证据。问题13：当面对那些驳回你的想法的论证时，是否想过放弃？答：人们非常非常反对这种想法。当时事情很棘手。但是，我的看法是，大脑一定是按照某种方式运行，它当然不会像普通计算机程序那样运作，特别是，那种认为任何事情都必须编入人工智能的想法很疯狂。你与世界互动，试图搞清楚世界如何运作。在我看来，将许多知识植入人工智能系统唯一的希望就是研发学习算法，允许机器学习这一知识。长期而言，那种方法是唯一有可能成功的办法。结果证明，我是对的。问题14：特别证明了你（的观点和想法是对的）？ 答：是的。我试着不去吹嘘，但是，它看起来不像我和其他一些人长期以来倡导的研究方法，如今真的比传统人工智能管用的多。"
"访谈;;专访Geoffrey Hinton：人工智能会继续发展Geoffrey Hinton 可谓深度学习领域「教父」级的人物，正是他的坚持和创新，使得神经网络再次迎来复兴时代，成为推动人工智能发展的新动力。MACLEANS的Adrian Lee对其进行了专访。在这篇访谈中，Hinton不仅谈到了他对这次人机大战的看法，也解释了深度学习的未来，为什么人们不应该害怕人工智能，以及到目前为止，人工智能所取得的成功是否证明了他的观点和想法是正确的。问：你对Alpha Go 获胜有什么看法？答：激动人心。为了这场比赛，我常常熬夜到凌晨两点看直播。在AlphaGo第一次对局李世乭之前，其实我们根本不知道AlphaGo是不是有些不清楚的致命缺陷。在第四局的时候我们看到了一些它的弱点。总结来说，它非常的让我们振奋。每个团队里的人都在比赛之前认为AlphaGo会赢的，但是没有人确定。幸运的是第一局并没有出现第四局的情况，如果AlphaGo输了第一局，他们会相当紧张的。问题2：人工智能取得了围棋的胜利为什么意义重大？答：围棋很多时候取决于直觉。真正优秀的棋手会在眼中看到哪里适合放置下一个棋子。他们也会做大量推理，也就是算棋，但是他们最出色的还是神乎其神的直觉，而这正是人类觉得计算机无法做到的。但是有了这些神经网络，计算机也可以做到这点。它们可以思考所有可能的落子方法，并依靠直觉决定其中一种优于其他所有。这正是feed point neural network所做的事：它给了这个系统类似于真正棋手的直觉。接着它可以尝试所有的替代方法。神经网络为你提供了好的直觉，这是其他系统所缺少的，这也是人们还没有理解计算机到底能做到什么的原因所在。问题3：在2014年，专家说过人工智能或许在未来有一天能够在围棋中获胜，但是主流思想是在那之前至少需要十年的时间。很显然，他们低估了人工智能。那么你在那时猜想过它会发生吗？答：我当时觉得如果有一个非常优秀的团队，管理有序，然后用一年的时候努力推进这项研究，并且利用神经网络，也许你可以做到，当然这只是一种可能性。但是Deep Mind团队真的做到了，因此我很惊讶他们的速度。问题4：那么下一步，人工智能又想去征服哪一个更加复杂的游戏呢？答：从我们对于棋盘类游戏所得来说，我不认为还有其他——我想这真的是一个里程碑。当然还有很多其他游戏，在这些游戏里你与其他和你对话的人物作出反应。人工智能仍然无法处理这类游戏，因为它们还不能很好地理解自然语言，但是它正在进步之中。现在所用的翻译手段一定会有所改变，因为谷歌承诺会研发更好的机器翻译技术，这是发展理解自然语言的一部分，并且会有着深远影响——它会影响幻想游戏等等，但是它也能让你更好地进行检索，因为它可以更好地理解文件的意思。其实它已经在影响很多东西了——在Gmail里有Smart Reply，后者可以辨别快速回复的邮件，并在它认为合适的时候给你替代选择。它们做的很好。你也许会认为它是一种大量数据存储系统，类似「如果邮件是这样子的，那么这是个不错的回复，如果邮件是那样子的，那么他的这个是个不错的回复」。实际上它合成了邮件里的回复。神经网络处理了邮件中的所有字句，并在神经元中腾置出内部状态，利用这些内部状态生成回复。它已经用大量数据训练过，在这个过程中熟悉各种回复的格式，但是它的确是在生成回复，并且越来越靠近人类做同样的事的方式。问题5：除了游戏，人工智能下一应用可能是什么?答：这取决于你问的那些人（团队）。在我看来，除非我们的系统中有了如同大脑那样的参数，否则无法达到人类的水平。在大脑中，神经元突触之间有链接，而且会发生变化。你所有的知识都储存在这些突触间。10-15岁时，你大脑中大约有千万亿量的突触，这个数字是非常庞大的。所以这不同于我们现有的神经网络。它们相比大脑太小了，我们最大的也只有大约十亿级的突触量。要比大脑小百万倍。问题6：你能为此做个预测吗？答：这个期限会超过5年，我拒绝谈及超过5年的的任何事情，因为我们无法看清5年后的事。你看过去的预测，比如世界上只有5台电脑的市场(据说是由IBM创始人托马斯·沃森所说）。你知道对未来做太久远的预测并不明智。问题7：对AlphaGo有一种比较盛行的看法就是害怕它会比人类更聪明，甚至会统治人类。害怕深度学习造成的结果会不会是一种非常荒谬的看法呢？答：我认为人们需要明白深度学习在背后可以做到很多事，而且做的更好。它已经用于Google 搜索和图片搜索。在Gmail智能回复上也使用了深度学习，就在语音和视觉领域，我相信不久机器翻译也会出现。而且它还将会用于其他像是气象科学、节约能源、基因组学等领域的重点问题上。所以这就像...只要你拥有好的机械技术，你就能像挖掘机在路上挖坑一样做事。当然，挖掘机可能会撞到你脑袋，但你并不会因此不设计挖掘机，这看起来会非常蠢。显然的，如果它们被错误使用，就会产生问题。任何新科技，如果被坏人使用，就会产生坏的影响。但这更像是一个政治问题而非技术问题。我认为，我们必需像看待挖掘机一样看待人工智能。它在很多事情上的表现都要比人类好。而且要比挖掘机的好处多得多，挖掘机只能在挖坑上帮助我们。当然，你能误用它。问题8：还有一种担忧就是人工智能代表着人类即将被淘汰，害怕人类会因此不可避免的失去工作。答：很难预测5年后会发生什么，但我相信5年内不会发生这种事，而且我也相当自信它不会成为我必需解决的问题。人们可以考虑这种事情。但考虑重点并非是因为技术有威胁就限制它的发展，而是如何改进我们政治系统，防止人们用它做坏事。问题9：在深度学习领域，计算能力有多重要？ 答：在深度学习中，我们使用的算法是二十世纪八九十年代开发的版本。当时人们很看好这些算法，但最终显示表现并不好。现在我们明白，当时之所以表现不好事因为计算能力有限，我们没有足够的数据集训练它们。如果我们想要达到人类大脑的水平，我们需要更多的计算，需要更好的硬件。比起20年前，我们更近了一步，但还有很长的路要走。合适的常识推理使得我们可以预测到这些事情。问题10：计算能力的持续增长会不会让深度学习的应用继续扩大？ 答：在过去的20年中，我们经历了计算能力的爆炸式增长、虽然当时人们说它不能持续，它却做到了。但这里也有我们未曾考虑到的事情。比如AlphaGo，我不确定它使用的计算能力的具体细节，但如果说它使用了数百千瓦的功率做计算我也不会感到惊讶。李世石可能就使用了30瓦，这是大脑消耗的，相当于灯泡。所以，做出更大的神经网络硬件会是关键。而且想拥有高质量的常识，我们需要更大的神经网络，这是我的观点。问题11：在上世纪80年代，人工智能领域的科学家曾经放弃了深度学习与神经网络研究，那么是什么改变了呢？ 答：主要原因是它开始有了效果。在那时，大型实用的人工智能问题没有解决，它也没有取代当时的技术。但是在2009年，我们在多伦多研发了针对语音识别的神经网络，比当时的技术要稍好一些，这一点很重要，因为当时的技术有着30年努力研究的基础，而我实验室里的几个研究生用了几个月就鼓捣出来了一个更好的技术。对于聪明人来说，很显然这项技术必定会取代那时的技术。

后来，谷歌首次将相关研究引进了自己的产品中，在2012年，谷歌推出安卓系统，并且在这个系统里语音识别的效果比之前都要好：将错误率降低到接近26%。之后，我实验室里的学生们利用由其他人所研发的技术并进一步提升了它，在那时其他技术最多只能降低错误率到26%，而我们的错误率可以到16%。在我们实现这个之后的一年，人们说「哇哦，这真的有作用」。他们的质疑态度持续了很多年，也发表了论文批评这个技术。但是几年后，这些人全部都抱住了人工智能的大腿。

几年过去，错误率从16%一直降到大约4%。深度学习已经非常非常好了，并且也让大公司和学术界意识到深度学习学习的巨大能量。问题12：这种知识回归的故事似乎只会发生在科学领域里。作家托马斯库恩谈及「范式转换」时，谈到过这个现象——这些科学革命并不必然产生更好的想法，仅仅是不同的想法。文化层面大体似乎已经失去了这一概念。深度学习回归就是这类只会发生在科学领域中的事情吗？&nbsp;答：我认为，这就是科学和宗教的区别所在。在科学领域中，你能看到看似疯狂的事情，但是，长远看来，你可能是对的。我们能获取真正好的证据，最终，研究社区会苏醒过来。你正在与之争论的科学家很有可能不会苏醒过来，但是，年青一代会改变，这就是深度学习领域正在发生的事情。并不是说老的传统人工智能研究人员们相信这个，坚信这个理念的是那些年轻的研究生们，他们都见证着事情发展的方向。

上世纪五十年代，我年轻时，也有过这样一些体验。我父亲是一位昆虫学家，相信大陆漂移说。那个时候，这无异于胡说八道。到了五十年代中期，大陆漂移说流行起来。有位叫做Alfred Wegener的人在三四十年前就想到了大陆漂移说，但是，他没有机会看到这个学说流行起来。这些学说以一些非常天真的想法为基础，比如非洲契合南美洲的方式，地质学家们仅仅投来鄙视的目光。他们认为那种观点纯属垃圾，异想天开。

我记得我父亲曾经卷入一个非常有趣的争论，有关一只无法行进很远也不能飞的龙虱。你能在澳洲的北海岸线看到这些动物，百万年来，他们无法从一个条溪流行进至另一条溪流。而且龙虱出现在了新几内亚的北海岸线，你在这里也看到了相同的龙虱，只有一些略微不同。这种事情能发生的唯一方式就是：新几内亚从澳洲大陆分离出来并转向相反的方向，新几内亚的北海岸线过去与澳洲海岸线相联。看看地质学家对这一观点的反应，是件很有趣的事情，他们认为，「龙虱不能移动大陆。」拒绝看证据。问题13：当面对那些驳回你的想法的论证时，是否想过放弃？答：人们非常非常反对这种想法。当时事情很棘手。但是，我的看法是，大脑一定是按照某种方式运行，它当然不会像普通计算机程序那样运作，特别是，那种认为任何事情都必须编入人工智能的想法很疯狂。你与世界互动，试图搞清楚世界如何运作。在我看来，将许多知识植入人工智能系统唯一的希望就是研发学习算法，允许机器学习这一知识。长期而言，那种方法是唯一有可能成功的办法。结果证明，我是对的。问题14：特别证明了你（的观点和想法是对的）？ 答：是的。我试着不去吹嘘，但是，它看起来不像我和其他一些人长期以来倡导的研究方法，如今真的比传统人工智能管用的多。"
"Geoffrey Hinton;;专访Geoffrey Hinton：人工智能会继续发展Geoffrey Hinton 可谓深度学习领域「教父」级的人物，正是他的坚持和创新，使得神经网络再次迎来复兴时代，成为推动人工智能发展的新动力。MACLEANS的Adrian Lee对其进行了专访。在这篇访谈中，Hinton不仅谈到了他对这次人机大战的看法，也解释了深度学习的未来，为什么人们不应该害怕人工智能，以及到目前为止，人工智能所取得的成功是否证明了他的观点和想法是正确的。问：你对Alpha Go 获胜有什么看法？答：激动人心。为了这场比赛，我常常熬夜到凌晨两点看直播。在AlphaGo第一次对局李世乭之前，其实我们根本不知道AlphaGo是不是有些不清楚的致命缺陷。在第四局的时候我们看到了一些它的弱点。总结来说，它非常的让我们振奋。每个团队里的人都在比赛之前认为AlphaGo会赢的，但是没有人确定。幸运的是第一局并没有出现第四局的情况，如果AlphaGo输了第一局，他们会相当紧张的。问题2：人工智能取得了围棋的胜利为什么意义重大？答：围棋很多时候取决于直觉。真正优秀的棋手会在眼中看到哪里适合放置下一个棋子。他们也会做大量推理，也就是算棋，但是他们最出色的还是神乎其神的直觉，而这正是人类觉得计算机无法做到的。但是有了这些神经网络，计算机也可以做到这点。它们可以思考所有可能的落子方法，并依靠直觉决定其中一种优于其他所有。这正是feed point neural network所做的事：它给了这个系统类似于真正棋手的直觉。接着它可以尝试所有的替代方法。神经网络为你提供了好的直觉，这是其他系统所缺少的，这也是人们还没有理解计算机到底能做到什么的原因所在。问题3：在2014年，专家说过人工智能或许在未来有一天能够在围棋中获胜，但是主流思想是在那之前至少需要十年的时间。很显然，他们低估了人工智能。那么你在那时猜想过它会发生吗？答：我当时觉得如果有一个非常优秀的团队，管理有序，然后用一年的时候努力推进这项研究，并且利用神经网络，也许你可以做到，当然这只是一种可能性。但是Deep Mind团队真的做到了，因此我很惊讶他们的速度。问题4：那么下一步，人工智能又想去征服哪一个更加复杂的游戏呢？答：从我们对于棋盘类游戏所得来说，我不认为还有其他——我想这真的是一个里程碑。当然还有很多其他游戏，在这些游戏里你与其他和你对话的人物作出反应。人工智能仍然无法处理这类游戏，因为它们还不能很好地理解自然语言，但是它正在进步之中。现在所用的翻译手段一定会有所改变，因为谷歌承诺会研发更好的机器翻译技术，这是发展理解自然语言的一部分，并且会有着深远影响——它会影响幻想游戏等等，但是它也能让你更好地进行检索，因为它可以更好地理解文件的意思。其实它已经在影响很多东西了——在Gmail里有Smart Reply，后者可以辨别快速回复的邮件，并在它认为合适的时候给你替代选择。它们做的很好。你也许会认为它是一种大量数据存储系统，类似「如果邮件是这样子的，那么这是个不错的回复，如果邮件是那样子的，那么他的这个是个不错的回复」。实际上它合成了邮件里的回复。神经网络处理了邮件中的所有字句，并在神经元中腾置出内部状态，利用这些内部状态生成回复。它已经用大量数据训练过，在这个过程中熟悉各种回复的格式，但是它的确是在生成回复，并且越来越靠近人类做同样的事的方式。问题5：除了游戏，人工智能下一应用可能是什么?答：这取决于你问的那些人（团队）。在我看来，除非我们的系统中有了如同大脑那样的参数，否则无法达到人类的水平。在大脑中，神经元突触之间有链接，而且会发生变化。你所有的知识都储存在这些突触间。10-15岁时，你大脑中大约有千万亿量的突触，这个数字是非常庞大的。所以这不同于我们现有的神经网络。它们相比大脑太小了，我们最大的也只有大约十亿级的突触量。要比大脑小百万倍。问题6：你能为此做个预测吗？答：这个期限会超过5年，我拒绝谈及超过5年的的任何事情，因为我们无法看清5年后的事。你看过去的预测，比如世界上只有5台电脑的市场(据说是由IBM创始人托马斯·沃森所说）。你知道对未来做太久远的预测并不明智。问题7：对AlphaGo有一种比较盛行的看法就是害怕它会比人类更聪明，甚至会统治人类。害怕深度学习造成的结果会不会是一种非常荒谬的看法呢？答：我认为人们需要明白深度学习在背后可以做到很多事，而且做的更好。它已经用于Google 搜索和图片搜索。在Gmail智能回复上也使用了深度学习，就在语音和视觉领域，我相信不久机器翻译也会出现。而且它还将会用于其他像是气象科学、节约能源、基因组学等领域的重点问题上。所以这就像...只要你拥有好的机械技术，你就能像挖掘机在路上挖坑一样做事。当然，挖掘机可能会撞到你脑袋，但你并不会因此不设计挖掘机，这看起来会非常蠢。显然的，如果它们被错误使用，就会产生问题。任何新科技，如果被坏人使用，就会产生坏的影响。但这更像是一个政治问题而非技术问题。我认为，我们必需像看待挖掘机一样看待人工智能。它在很多事情上的表现都要比人类好。而且要比挖掘机的好处多得多，挖掘机只能在挖坑上帮助我们。当然，你能误用它。问题8：还有一种担忧就是人工智能代表着人类即将被淘汰，害怕人类会因此不可避免的失去工作。答：很难预测5年后会发生什么，但我相信5年内不会发生这种事，而且我也相当自信它不会成为我必需解决的问题。人们可以考虑这种事情。但考虑重点并非是因为技术有威胁就限制它的发展，而是如何改进我们政治系统，防止人们用它做坏事。问题9：在深度学习领域，计算能力有多重要？ 答：在深度学习中，我们使用的算法是二十世纪八九十年代开发的版本。当时人们很看好这些算法，但最终显示表现并不好。现在我们明白，当时之所以表现不好事因为计算能力有限，我们没有足够的数据集训练它们。如果我们想要达到人类大脑的水平，我们需要更多的计算，需要更好的硬件。比起20年前，我们更近了一步，但还有很长的路要走。合适的常识推理使得我们可以预测到这些事情。问题10：计算能力的持续增长会不会让深度学习的应用继续扩大？ 答：在过去的20年中，我们经历了计算能力的爆炸式增长、虽然当时人们说它不能持续，它却做到了。但这里也有我们未曾考虑到的事情。比如AlphaGo，我不确定它使用的计算能力的具体细节，但如果说它使用了数百千瓦的功率做计算我也不会感到惊讶。李世石可能就使用了30瓦，这是大脑消耗的，相当于灯泡。所以，做出更大的神经网络硬件会是关键。而且想拥有高质量的常识，我们需要更大的神经网络，这是我的观点。问题11：在上世纪80年代，人工智能领域的科学家曾经放弃了深度学习与神经网络研究，那么是什么改变了呢？ 答：主要原因是它开始有了效果。在那时，大型实用的人工智能问题没有解决，它也没有取代当时的技术。但是在2009年，我们在多伦多研发了针对语音识别的神经网络，比当时的技术要稍好一些，这一点很重要，因为当时的技术有着30年努力研究的基础，而我实验室里的几个研究生用了几个月就鼓捣出来了一个更好的技术。对于聪明人来说，很显然这项技术必定会取代那时的技术。

后来，谷歌首次将相关研究引进了自己的产品中，在2012年，谷歌推出安卓系统，并且在这个系统里语音识别的效果比之前都要好：将错误率降低到接近26%。之后，我实验室里的学生们利用由其他人所研发的技术并进一步提升了它，在那时其他技术最多只能降低错误率到26%，而我们的错误率可以到16%。在我们实现这个之后的一年，人们说「哇哦，这真的有作用」。他们的质疑态度持续了很多年，也发表了论文批评这个技术。但是几年后，这些人全部都抱住了人工智能的大腿。

几年过去，错误率从16%一直降到大约4%。深度学习已经非常非常好了，并且也让大公司和学术界意识到深度学习学习的巨大能量。问题12：这种知识回归的故事似乎只会发生在科学领域里。作家托马斯库恩谈及「范式转换」时，谈到过这个现象——这些科学革命并不必然产生更好的想法，仅仅是不同的想法。文化层面大体似乎已经失去了这一概念。深度学习回归就是这类只会发生在科学领域中的事情吗？&nbsp;答：我认为，这就是科学和宗教的区别所在。在科学领域中，你能看到看似疯狂的事情，但是，长远看来，你可能是对的。我们能获取真正好的证据，最终，研究社区会苏醒过来。你正在与之争论的科学家很有可能不会苏醒过来，但是，年青一代会改变，这就是深度学习领域正在发生的事情。并不是说老的传统人工智能研究人员们相信这个，坚信这个理念的是那些年轻的研究生们，他们都见证着事情发展的方向。

上世纪五十年代，我年轻时，也有过这样一些体验。我父亲是一位昆虫学家，相信大陆漂移说。那个时候，这无异于胡说八道。到了五十年代中期，大陆漂移说流行起来。有位叫做Alfred Wegener的人在三四十年前就想到了大陆漂移说，但是，他没有机会看到这个学说流行起来。这些学说以一些非常天真的想法为基础，比如非洲契合南美洲的方式，地质学家们仅仅投来鄙视的目光。他们认为那种观点纯属垃圾，异想天开。

我记得我父亲曾经卷入一个非常有趣的争论，有关一只无法行进很远也不能飞的龙虱。你能在澳洲的北海岸线看到这些动物，百万年来，他们无法从一个条溪流行进至另一条溪流。而且龙虱出现在了新几内亚的北海岸线，你在这里也看到了相同的龙虱，只有一些略微不同。这种事情能发生的唯一方式就是：新几内亚从澳洲大陆分离出来并转向相反的方向，新几内亚的北海岸线过去与澳洲海岸线相联。看看地质学家对这一观点的反应，是件很有趣的事情，他们认为，「龙虱不能移动大陆。」拒绝看证据。问题13：当面对那些驳回你的想法的论证时，是否想过放弃？答：人们非常非常反对这种想法。当时事情很棘手。但是，我的看法是，大脑一定是按照某种方式运行，它当然不会像普通计算机程序那样运作，特别是，那种认为任何事情都必须编入人工智能的想法很疯狂。你与世界互动，试图搞清楚世界如何运作。在我看来，将许多知识植入人工智能系统唯一的希望就是研发学习算法，允许机器学习这一知识。长期而言，那种方法是唯一有可能成功的办法。结果证明，我是对的。问题14：特别证明了你（的观点和想法是对的）？ 答：是的。我试着不去吹嘘，但是，它看起来不像我和其他一些人长期以来倡导的研究方法，如今真的比传统人工智能管用的多。"
"科技史;;《纽约书评》：乔布斯的机器人生亚历克斯·吉布尼(Alex Gibney)的纪录片电影「史蒂夫·乔布斯（Steve Jobs）」堪称诚意之作；丹尼尔·柯特科（Daniel Kottke ，苹果早期员工）看到一半时提了一个问题：「要想成功，你得变得有多混蛋？」最近丹尼·博伊尔（Danny Boyle）拍摄乔布斯传时，已发出了同样的问句。丹尼·博伊尔的电影围绕着乔布斯一生三大阶段的主题---1984年发布Macintosh电脑、1988年发布NeXT电脑、1998年发布iMac笔记本，塑造了一个爱捣乱、行事乖张的人物形象。在博伊尔（和他的编剧艾伦·索金，Aaron Sorkin）心中，显然这个问题有了答案：「混世魔王」。在自己的电影中，吉布尼集合了一些乔布斯生前的朋友、爱人、员工的言论，他们同意上述评判，这令吉布尼颇感困惑。2011年乔布斯去世之时，他的冷酷、傲慢、喜怒无常、爱欺凌他人和其他种种孩子气行为已为大家熟知；彼时，苹果公司设在中国的生产工厂被曝光了恶劣的用工环境——多达几十起的员工自杀——而乔布斯冷漠以对；同时，苹果本身也被爆出谋划逃税一事。那么，乔布斯离世令全球哀恸，究竟是何缘由？吉布尼在电影开篇展现了乔布斯逝世当天的一幕：全世界成千上万的人们在苹果商店门外留下了数不清的鲜花和短笺---「致史蒂夫」；粉丝们眼泪汪汪地通过网络发表着感人至深的悼词；哀悼者聚集在临时搭设的龛笼周围，举起手中烛光闪烁的iPad，向乔布斯致敬。一个大约九、十岁，坐在电脑桌前左右旋转的小男孩道出答案：「我现在用的电脑是iMac，他创造的」，「他创造了iMac。他创造了Mac笔记本。他创造了Mac Pro系列。他创造了Mac Air系列。他创造了iPhone。他创造了iPad。他创造了iPod Touch。他创造了所有这一切。」然而，这个答案远远不够——乔布斯仅仅因为制造了风靡世界的电子产品，就获得身后殊荣吗？为什么乔治·伊士曼、托马斯·爱迪生、亚历山大·格拉汉姆·贝尔等大咖们仙逝当日，人们并未自发涌上街头、哭泣追思？这些英雄可是实实在在地发明了相机、电灯、电话，奠定了现代生活的基石！MIT社会学家Sherry Turkle认为其中的区别在于：人们感念史蒂夫·乔布斯，与其人、与其产品关系不大，打动人们的是这些产品和使用者之间形成的关联，这种关联迅速且有效地消弭了人与人之间的距离。「乔布斯把电子产品打造成了人类自身的延伸物」， Turkle告诉吉布尼，「不仅仅是对人类有用，而且成为人类自己的一部分。」2005年-2007年就任iPhone高级经理的Andy Grignon，在吉布尼的电影中观察到：苹果是一家公司。我们在某种程度上把情感（爱、奉献、崇高的目标感）代入到这家公司了，但公司的本质是为股东赚钱。仅此而已。乔布斯的最伟大的成就之一在于创造了人与人之间的新关联方式。乔布斯是一位完美主义者。所以艾伦·索金很自然便以苹果产品的发布为主线讲述乔布斯的生平。苹果公司的产品发布极富戏剧效果——像一场演出——每次新产品出炉面世，乔布斯都会想方设法参与到发布秀当中。首席创意官Lee Clow乔布斯紧密合作多年，觉得「史蒂夫简直是费尼尔司·泰勒·巴纳姆附身了」，「他爱制造惊喜，他总是说，『我要让你看到这世上最小的男人！（巴纳姆是美国巡回演出团老板和马戏团老板，因展现畸形人的表演而闻名。译者）』他总爱亲手把盖着新产品的那一块黑色绒布揭掉，他关心一切与展示技巧、市场、传播有关的事物。」人们都盼望见证奇迹的时刻。史蒂夫·乔布斯深谙此中奥妙，因此坚决要求必须到最后一刻才能掀开新产品神秘面纱。他这点执念比起「制造惊喜」的爱好有过之而无不及。2005年「经济学人」杂志发问「史蒂夫·乔布斯是不是商业史上最成功的偏执狂？」；同一年，苹果公司起诉一位哈佛新生，指控他运营的网站专门传播、买卖苹果公司小道消息及产品信息。吉布尼还讲述了Jason Chen的故事：Jason Chen是「硅谷日报」编辑，曾公开透露尚在研发阶段的苹果手机产品细节；2010年，一支跨部门执法队---加州警方迅速执法联合计算机小组（REACT）闯入他的住宅进行搜查，带走了他的电脑和其他物品。Gizmodo网站宣称，一名苹果雇员将这支手机遗落在一间酒吧，遭不明人士拾获，并以5000美元的价格向Gizmodo兜售，但早在REACT执法队伍闯入Jason Chen家宅之前4天，Jason Chen已将该支手机归还给了苹果公司。REACT是一个公共机构，然而苹果公司掌控着其委员会，令人不得不质疑，执法机构是否听命于苹果公司？无论是为了保护商业秘密，还是为了保持神秘感，或者两者兼而有之，乔布斯一直坚持把苹果产品做成封闭系统，不接受各种补丁。这是一起苹果诉讼案背后的深层原因——不希望用户「越狱」破解苹果操作系统，使用第三方软件——但是，这宗案件以苹果公司的失败告终。从最开始生产电脑的时候，乔布斯就要求把电脑软硬件一体化，不像微软公司的系统，可应用于任何厂商、任何型号的硬件之中；结果是苹果产品价格高于同类产品，且难以被人抄袭。在丹尼·博伊尔的电影中，斯蒂夫·沃兹尼亚克（苹果联合创始人）对乔布斯的做法持有异议，他认为一台个人电脑改动与否应由自己的主人决定，控制权在终端，「计算机并不是画画儿」；但乔布斯的想法恰恰相反，Macintosh电脑本质具有制造者们的鲜明特征。乔布斯销售的魔力远远超越了公司产品本身：它融入了他自己的故事。从一个百万富翁，到亿万富翁，再到出卖朋友和合伙人，再到被抓到回溯股票期权，再到卖掉苹果大部分的离岸现金以逃税，乔布斯称自己是局外人，一个有原则的反对主流（他认为是盲目的、愚蠢的、缺陷的）文化的叛逆者。你也行，他建议到，如果你和苹果为盟。正是这种花招使消费者相信购买商品也是做好事——这是改变世界的一种方式。记者Joe Nocera告诉Gibney，「围绕苹果的神话是针对一个做手机的公司。手机不是一个神奇的设备。它让你对我们自己感到惊奇，胜过对苹果的惊讶。」为了形象地理解它，你只需要在线浏览 Eric Pickersgill的摄影集「移除（Removed）」，摄影师将日常生活中，比如坐在餐桌旁，窝在沙发里，躺在床上的普通人手中的手机和其它电子设备移除。结果呈现出这样的画面：人们定格在聚精会神盯着被移除设备的瞬间，注意力如此坚定以至于完全不闻窗外事。正如Pickersgill所说：工作起始于我坐在咖啡馆的一个早上。这是我写下的自己的观察：在纽约特洛伊的Illium咖啡馆，坐在我旁边的家人十分生疏。没有太多言语。父亲和两个女儿拿出自己的手机。母亲没有手机或者是把它放起来了。她盯着窗外，在最亲近的家人陪伴下显得孤独、忧伤。爸爸不时地翻阅手机，回应他在网上发现的一些模糊的信息。他又一次谈到捕到的一条大鱼。使用技术去交流换来的却是没有交流，这使我很忧伤。这在之前从未发生过，我怀疑我们已经划开了这种新体验所带来的社交影响的表面。妈妈现在拿出了她的手机。有人假设如果乔布斯还活着，他会为这些图片心动，因为他们证实了这种洞察力——乔布斯在其他人当中所推崇的——他是一个有远见的人，他能让人们看到他们想要的，甚至于在人们知道自己想要之前。正如Gibney所说，「他不只是把自己定位成CEO，而是一位先知。一个能预言未来的人。」

而且他能做到——有时候。但是，值得记住的是，乔布斯在1985年被赶出苹果公司，他倾注公司资源投入的，两个计算机项目，苹果3和另一个名为Lisa计算机，失利惨重几乎让苹果关门。Boyle的讲述中反复出现的场景是乔布斯愁眉苦脸的前伙伴，苹果原型机的实际发明者Steve Wozniak，他求乔布斯公开承认打造了苹果2的团队，当乔布追求这些这些不幸灾难时，是这款苹果2计算机维持着公司的运转，乔布斯轻蔑地把他喷走了。&nbsp;离开苹果之后，乔布斯接下来投资了一个面向研究院和学术机构的计算机工作站，并相应地取名为NeXT，这更是灾难性的。由于价格过高，电量不足，这个计算机卖出很少。Boyle描述了乔布斯痴迷于装NeXT的黑塑料盒的精确尺寸，而不是计算机的实际缺陷，正如乔布斯对苹果1的米色层次的痴迷。这两个故事没有一个是杜撰的，而且很多年来它们都被用来说明，乔布斯为了更好和更差超乎寻常地吹毛求疵。（乔布斯还在NeXT商标上花了10万美金。）

Sorkin的电影借助沃兹尼亚克之口宣称，NeXT计算机的失败是注定的——设计它就是为了把乔布斯掷回苹果的轨道。小说容许这样的发明创造，但是正如商业记者Brent Schlender 和 Rick Tetzeli在他们半个人回忆氏纪录《成为乔布斯》中指出的，「NeXT的失败毫无疑问，失败是由乔布斯一手造成的也是毫无疑问的。」2010年，乔布斯面对自画像在斯坦福一个会议上的讲话和Steve Wozniak[/caption]

乔布斯还确实使用了NeXT的幸存资产——软件部门，就像门上的楔子，打开它后让他十年后重返苹果。Avie Tevanian（他是乔布斯忠实的追随者直到乔布斯在2006年把他抛弃）开发的NeXT软件，成为今天Mac电脑简便、稳定、多任务操作系统的基础。然而当时，苹果一落千丈，市值缩水10亿美元，濒临破产。这个支撑着Macintosh图形的、基于图标的操作系统不再强大、灵活，跟不上用户的需求。苹果需要一个新的操作系统，而乔布斯正好有一个。或者，更确切地讲，他有一个软件工程师——Tevanian——他能重构NeXT操作系统并用到苹果上，这一直是乔布斯的目标。不到一年的时间乔布斯以4.29亿美元的价格把这款软件卖给苹果，出任职位权责模糊的顾问一职，苹果CEO走了，董事会也走了，乔布斯重掌大权。

乔布斯的第二个大动作，始于1996年乔布斯作为非正式的顾问回归苹果时，或是1997年他终于赶走了当时苹果CEO，开始执掌大权，真正将他推上了万众瞩目的地位。确实，在几年以前，《Inc.》杂志称他为「十年以来的真正创业家」，即使他失败过，他仍然是传说中的男人。毕竟这可是斯蒂文·乔布斯，第一位把目光给了家用计算机的人，集结了爱好相同的伙伴们，例如斯蒂夫·沃兹尼亚克，并意识到这对于没有兴趣自己动手的人们的吸引力，点燃了整个产业界的创造激情（比尔·盖茨也预见到了同样的事情，并意识到他们需要功能性的软件，并为此从哈佛辍学开始自己写软件）。但是私人计算机，在二十年后非常普遍的一种设备，在乔布斯回归苹果时依旧是天方夜谭。他们缺少——用乔布斯的话来说——「魔力」。&nbsp;回到了他最开始的地方，乔布斯的第一个革新便是为当时人们桌子上常见的米色长方体提供代替品。这个新的设计在1998年揭幕，是一个半透明形状怪异的箱子，人们甚至可以看到它内部的结构（随后又有了许多新的颜色）。它有着一个凹进的手柄，可以移动，尽管它有足足38磅。Mac是一个苹果以i为前缀的产品，标志着它不是昙花一现的产品，而是在互联网迅速崛起的未来中，与广阔世界连接的通道。

它是一个巨大的成功，在第一年售出了接近两百万台。就像Schlender与Tetzeli所说的，iMac色彩斑斓的外壳并不仅仅意味着挑战主流工业审美，也强调并突出了乔布斯领导力，苹果的计算机反射出了个人的独特性。「『i』就是独特的。」他们写道，「这是我的计算机，甚至也许是『我』是谁的表达。」

乔布斯在「i」主题上才刚刚开始（有一段时间他甚至叫自己是苹果的「iCEO」）。苹果在1999年引进了「iMovie」，能够让用户们创造自己的电影。接着两年过去，在收购了一家制作数字点唱机软件的公司后，苹果发布了iTunes，最流行的音乐播放软件。iTunes非常酷，但是让它更酷的是苹果在同年发布的音乐播放器，iPod。根据Schlender与Tetzeli，在iPod之前有过移动数字音乐设备，但是，没有一个具有这样的容量，功能，特别是如此精湛的设计。

iPod用户界面的突破最终让这个产品变得具有魔力，独一无二。即使有很多其他重要的软件革新，就像同步用户iTunes收藏音乐的软件，但是，如果这个团队没有解决成千上万首音乐的播放应用问题，iPod将永无出头之日。&nbsp;到了2001年，接下来，苹果的策略，公司从个人计算机公司转型为个人计算，开始启动。乔布斯说服——或者很可能恐吓了——音乐产业的高管们——后者被人们可以免费将音乐下载到设备中的p2p网站吓坏了——允许苹果以每首歌1美元的价格在iTunes上出售歌曲。乔布斯肯定知道，这为一场商业音乐的戏剧性颠覆搭好了舞台。后果之一就是，苹果和它数百万个iTunes用户，成为品味，影响力和流行时尚的新动力。

苹果为微软操作系统提供iTunes的一个版本，从而让每个拥有个人电脑的用户可以使用这款软件，两年后，苹果加强进军音乐商业。为自己并不尊重的公司提供独特的苹果产品，而且还起诉过对方剽窃Mac操作系统关键元素，Schlender与Tetzeli认为，原因在于乔布斯的同事说服了他，他们说一旦Windows用户体验了苹果优雅精致的软件与硬件后，他们就看到了光芒并克服黑暗面。从苹果最近10兆美元的身价来看，他们貌似是对的。

然而，iPod如今也已经被iPhone,iPod Touch 以及iPad所取代。 与此同时，苹果公司继续生产个人电脑，以及其他能够体现乔布斯简单、纯粹审美的产品。并经Jony Ive之手大获成功，Ive是苹果的首席设计师。他的责任还包括确保苹果所有掌上设备的玻璃元件和金属原件的极简化，将形式集中到功能上。苹果手机之前，市场上的「智能机」也早已存在，并具备收发邮件及网络浏览的功能。然而，惊艳如iPhone：平滑流畅的触摸屏，各种「apps」带来的各种前所未见的功能大大地提高了手机对用户的粘性，手机不再只是用来拨打电话的，现在我们用手机听音乐，读书，玩象棋，录视频并且直接进行剪辑。

乔布斯预见到人们期望手机会变成一个强大的口袋电脑，这种超强的直觉就像他在三十年前时掐指一算，在不久的将来每个人的桌上都台属于自己的电脑。两次预言不仅带来的巨大的金钱效应，还激发了新的产业的诞生——目前，世界范围内的智能手机厂商众多，这催生了21世纪第一批小作坊产业： app制作。任何拥有电脑编程能力的人就可以给iPhone编写游戏或者应用，通过苹果公司审核的app就可以上线进行出售了。现如今，有四个以上苹果app程序的开发人，平均每年能赚21,000美元。如果有人正在记录「兼职经济」的历史——这种没有固定雇佣人，通过完成一些列小的任务来赚钱的形式，不妨从这里写起。&nbsp;Alex Gibney拍摄电影的初衷源于其自身对于乔布斯的疑问 ，为何他能如此受人追捧，在丹尼-鲍尔(Danny Boyle)导演的纪录片中，乔布斯对女儿说自己「人品差劲」（多年以来，乔布斯拒绝承认与女儿的血缘关系，尽管亲子鉴定给出了肯定的报告，他的孩子生活在困境，而他依然没有履行任何抚养义务。最后乔布斯父女关系得到缓和）。Gibney费力追寻着答案，虽然这一历程通常吸引人，但永远无法抵达它想要企及的地方，因为电影制片人已经提出了一个无法回答的问题。

疑问之二：为什么人们对这个男人的着迷可以一直持续？仅仅在这一个季节，就有两部关于乔帮主的电影和一本关于他的新书发布。他无疑是Schlender&amp;Tetzeli在书中所说的商业天才，然而，乔布斯身上最大的特质用他最爱的一句营销名言来形容就是：思不同（Think Indifferent）。如他一般，只关心产品，而不是背后无数的制造者。对他来说，无论是中国工厂的工人还是库比蒂诺的员工（库比蒂诺是苹果公司总部）亦或是像Wozniak，Kottke，Tevanian对苹果的成功起着关键作用的同僚，都是一样的存在。&nbsp;iPhone和其他衍生出的i系列智能设备，将苹果公司从一个高端且小众的电脑公司推上了全球数码行业之首的宝座，并使其成为世界上最富有的公司。 举例来说，2015年的第一季度，iPhone和iPad的销量带给苹果公司81%的收入，而电脑只占到9%。如今，面对手机和电脑市场趋于饱和，苹果公司需要带来一款人人都想要的产品从而爆发新的需求，尽管少了乔布斯的加持。

去年，万众瞩目的苹果手表上市，却没能激发主流消费者的购买热情。发布后第一个月其销售额便掉了90%，并在之后的一年中持续下跌。后来，苹果公司又发布了iPad Pro，屏幕更大，功能更强的pad。然而，销售依旧表现平平。还有传言说苹果即将制造汽车，并在2019年上市——苹果汽车可能是电动的，或许是自动驾驶的，或者从头设计打造，或许并与梅赛德斯奔驰合作。然而这些猜测可能为时尚早——当Tim Cook——苹果现任CEO，在Stephen的节目和Charlie Rose的六十分钟节目被问到有关汽车的问题时，他的回答支支吾吾。&nbsp;尽管如此，在乔布斯离开的几年中，尽管未能推出一个重磅产品，尽管它最近的股价下跌，公司继续增长。2015是苹果最赚钱的一年，到目前为止，营收为2340亿美元。根据金融分析师的分析，这要么是让苹果股票交易，要么是一只熊准备从一棵树上跌落下来。到目前为止，还没有人创建一个应用程序，可以预测未来。

苹果乔布斯去世的第一天之后发布的Siri，iPhone的虚拟助理，是一个好的风向标，预示着人工智能（AI）和机器学习将是下一代苹果产品的核心，正如它将更普遍地成为科技产业核心。

能够实时并在多领域实现一款设备，其人工智能和机器学习能力得以大大增强，正是乔布斯一直寻找的：在人们还没意识到他们想要什么之前，直接给出他们想要的。

今年早些时候，证实这种产品可能样子的公司不是苹果而是谷歌，在年度开发者大会上，谷歌发布了一个早期原型Now on Tap。这个原型的实质是将手机中不同的信息彼此连接起来。例如，一封来自朋友的电子邮件建议了某家餐厅，可能会带来有关该餐厅的评价，去往路线，以及检查日历，看看你那晚是否有空。如果这听起来还好，或许吧，但这些尚处早期——对市场营销的吸引力将是巨大的。&nbsp;谷歌在人工智能和机器学习方面遥遥领先苹果。这是有道理的，部分是因为谷歌的核心业务来自于搜索引擎，搜索引擎产生海量数据。但还有另一个原因，这要回溯到乔布斯身上，以及他给苹果注入的保密文化，公司盛行的文化。正如Tim Cook 在60分钟的采访中所告诉Charlie Rose的那样，「苹果最伟大的事情之一就是(我们)公司很可能比中央情报局还保密。」

这一制度精神似乎已经阻碍了苹果人工智能研究者与该领域其他研究人员的合作或信息共享，阻碍了人工智能的研发，也打消了顶尖研究人员去苹果公司工作的积极性。「真正强大的人不想进入一个四处秘密封闭的环境，」Yoshua Benigo，十月，一位蒙特利尔大学的计算机科学教授告诉彭博商业。「差异化的因素是，『你打算和谁一起工作？』『我将要留在科学界吗？』『我将有多少自由？』」

乔布斯有一个对自由的永久信念——他自己的。就如Gibney的纪录片，Boyle的电影，甚至Schlender和Tetzeli的另类友好评价清楚表明的，乔布斯想要摆脱适用其他人的规则。他想要制造自己的规则，允许他支配别人。乔布斯身边的人对此有一个称谓。他们称之为乔布斯的「现实扭曲力场（reality distortion field）」。因此，当苹果在人工智能的道路上独自前进之时，又多留给我们一个问题：傲慢是乔布斯最后的遗产吗？"
"苹果;;《纽约书评》：乔布斯的机器人生亚历克斯·吉布尼(Alex Gibney)的纪录片电影「史蒂夫·乔布斯（Steve Jobs）」堪称诚意之作；丹尼尔·柯特科（Daniel Kottke ，苹果早期员工）看到一半时提了一个问题：「要想成功，你得变得有多混蛋？」最近丹尼·博伊尔（Danny Boyle）拍摄乔布斯传时，已发出了同样的问句。丹尼·博伊尔的电影围绕着乔布斯一生三大阶段的主题---1984年发布Macintosh电脑、1988年发布NeXT电脑、1998年发布iMac笔记本，塑造了一个爱捣乱、行事乖张的人物形象。在博伊尔（和他的编剧艾伦·索金，Aaron Sorkin）心中，显然这个问题有了答案：「混世魔王」。在自己的电影中，吉布尼集合了一些乔布斯生前的朋友、爱人、员工的言论，他们同意上述评判，这令吉布尼颇感困惑。2011年乔布斯去世之时，他的冷酷、傲慢、喜怒无常、爱欺凌他人和其他种种孩子气行为已为大家熟知；彼时，苹果公司设在中国的生产工厂被曝光了恶劣的用工环境——多达几十起的员工自杀——而乔布斯冷漠以对；同时，苹果本身也被爆出谋划逃税一事。那么，乔布斯离世令全球哀恸，究竟是何缘由？吉布尼在电影开篇展现了乔布斯逝世当天的一幕：全世界成千上万的人们在苹果商店门外留下了数不清的鲜花和短笺---「致史蒂夫」；粉丝们眼泪汪汪地通过网络发表着感人至深的悼词；哀悼者聚集在临时搭设的龛笼周围，举起手中烛光闪烁的iPad，向乔布斯致敬。一个大约九、十岁，坐在电脑桌前左右旋转的小男孩道出答案：「我现在用的电脑是iMac，他创造的」，「他创造了iMac。他创造了Mac笔记本。他创造了Mac Pro系列。他创造了Mac Air系列。他创造了iPhone。他创造了iPad。他创造了iPod Touch。他创造了所有这一切。」然而，这个答案远远不够——乔布斯仅仅因为制造了风靡世界的电子产品，就获得身后殊荣吗？为什么乔治·伊士曼、托马斯·爱迪生、亚历山大·格拉汉姆·贝尔等大咖们仙逝当日，人们并未自发涌上街头、哭泣追思？这些英雄可是实实在在地发明了相机、电灯、电话，奠定了现代生活的基石！MIT社会学家Sherry Turkle认为其中的区别在于：人们感念史蒂夫·乔布斯，与其人、与其产品关系不大，打动人们的是这些产品和使用者之间形成的关联，这种关联迅速且有效地消弭了人与人之间的距离。「乔布斯把电子产品打造成了人类自身的延伸物」， Turkle告诉吉布尼，「不仅仅是对人类有用，而且成为人类自己的一部分。」2005年-2007年就任iPhone高级经理的Andy Grignon，在吉布尼的电影中观察到：苹果是一家公司。我们在某种程度上把情感（爱、奉献、崇高的目标感）代入到这家公司了，但公司的本质是为股东赚钱。仅此而已。乔布斯的最伟大的成就之一在于创造了人与人之间的新关联方式。乔布斯是一位完美主义者。所以艾伦·索金很自然便以苹果产品的发布为主线讲述乔布斯的生平。苹果公司的产品发布极富戏剧效果——像一场演出——每次新产品出炉面世，乔布斯都会想方设法参与到发布秀当中。首席创意官Lee Clow乔布斯紧密合作多年，觉得「史蒂夫简直是费尼尔司·泰勒·巴纳姆附身了」，「他爱制造惊喜，他总是说，『我要让你看到这世上最小的男人！（巴纳姆是美国巡回演出团老板和马戏团老板，因展现畸形人的表演而闻名。译者）』他总爱亲手把盖着新产品的那一块黑色绒布揭掉，他关心一切与展示技巧、市场、传播有关的事物。」人们都盼望见证奇迹的时刻。史蒂夫·乔布斯深谙此中奥妙，因此坚决要求必须到最后一刻才能掀开新产品神秘面纱。他这点执念比起「制造惊喜」的爱好有过之而无不及。2005年「经济学人」杂志发问「史蒂夫·乔布斯是不是商业史上最成功的偏执狂？」；同一年，苹果公司起诉一位哈佛新生，指控他运营的网站专门传播、买卖苹果公司小道消息及产品信息。吉布尼还讲述了Jason Chen的故事：Jason Chen是「硅谷日报」编辑，曾公开透露尚在研发阶段的苹果手机产品细节；2010年，一支跨部门执法队---加州警方迅速执法联合计算机小组（REACT）闯入他的住宅进行搜查，带走了他的电脑和其他物品。Gizmodo网站宣称，一名苹果雇员将这支手机遗落在一间酒吧，遭不明人士拾获，并以5000美元的价格向Gizmodo兜售，但早在REACT执法队伍闯入Jason Chen家宅之前4天，Jason Chen已将该支手机归还给了苹果公司。REACT是一个公共机构，然而苹果公司掌控着其委员会，令人不得不质疑，执法机构是否听命于苹果公司？无论是为了保护商业秘密，还是为了保持神秘感，或者两者兼而有之，乔布斯一直坚持把苹果产品做成封闭系统，不接受各种补丁。这是一起苹果诉讼案背后的深层原因——不希望用户「越狱」破解苹果操作系统，使用第三方软件——但是，这宗案件以苹果公司的失败告终。从最开始生产电脑的时候，乔布斯就要求把电脑软硬件一体化，不像微软公司的系统，可应用于任何厂商、任何型号的硬件之中；结果是苹果产品价格高于同类产品，且难以被人抄袭。在丹尼·博伊尔的电影中，斯蒂夫·沃兹尼亚克（苹果联合创始人）对乔布斯的做法持有异议，他认为一台个人电脑改动与否应由自己的主人决定，控制权在终端，「计算机并不是画画儿」；但乔布斯的想法恰恰相反，Macintosh电脑本质具有制造者们的鲜明特征。乔布斯销售的魔力远远超越了公司产品本身：它融入了他自己的故事。从一个百万富翁，到亿万富翁，再到出卖朋友和合伙人，再到被抓到回溯股票期权，再到卖掉苹果大部分的离岸现金以逃税，乔布斯称自己是局外人，一个有原则的反对主流（他认为是盲目的、愚蠢的、缺陷的）文化的叛逆者。你也行，他建议到，如果你和苹果为盟。正是这种花招使消费者相信购买商品也是做好事——这是改变世界的一种方式。记者Joe Nocera告诉Gibney，「围绕苹果的神话是针对一个做手机的公司。手机不是一个神奇的设备。它让你对我们自己感到惊奇，胜过对苹果的惊讶。」为了形象地理解它，你只需要在线浏览 Eric Pickersgill的摄影集「移除（Removed）」，摄影师将日常生活中，比如坐在餐桌旁，窝在沙发里，躺在床上的普通人手中的手机和其它电子设备移除。结果呈现出这样的画面：人们定格在聚精会神盯着被移除设备的瞬间，注意力如此坚定以至于完全不闻窗外事。正如Pickersgill所说：工作起始于我坐在咖啡馆的一个早上。这是我写下的自己的观察：在纽约特洛伊的Illium咖啡馆，坐在我旁边的家人十分生疏。没有太多言语。父亲和两个女儿拿出自己的手机。母亲没有手机或者是把它放起来了。她盯着窗外，在最亲近的家人陪伴下显得孤独、忧伤。爸爸不时地翻阅手机，回应他在网上发现的一些模糊的信息。他又一次谈到捕到的一条大鱼。使用技术去交流换来的却是没有交流，这使我很忧伤。这在之前从未发生过，我怀疑我们已经划开了这种新体验所带来的社交影响的表面。妈妈现在拿出了她的手机。有人假设如果乔布斯还活着，他会为这些图片心动，因为他们证实了这种洞察力——乔布斯在其他人当中所推崇的——他是一个有远见的人，他能让人们看到他们想要的，甚至于在人们知道自己想要之前。正如Gibney所说，「他不只是把自己定位成CEO，而是一位先知。一个能预言未来的人。」

而且他能做到——有时候。但是，值得记住的是，乔布斯在1985年被赶出苹果公司，他倾注公司资源投入的，两个计算机项目，苹果3和另一个名为Lisa计算机，失利惨重几乎让苹果关门。Boyle的讲述中反复出现的场景是乔布斯愁眉苦脸的前伙伴，苹果原型机的实际发明者Steve Wozniak，他求乔布斯公开承认打造了苹果2的团队，当乔布追求这些这些不幸灾难时，是这款苹果2计算机维持着公司的运转，乔布斯轻蔑地把他喷走了。&nbsp;离开苹果之后，乔布斯接下来投资了一个面向研究院和学术机构的计算机工作站，并相应地取名为NeXT，这更是灾难性的。由于价格过高，电量不足，这个计算机卖出很少。Boyle描述了乔布斯痴迷于装NeXT的黑塑料盒的精确尺寸，而不是计算机的实际缺陷，正如乔布斯对苹果1的米色层次的痴迷。这两个故事没有一个是杜撰的，而且很多年来它们都被用来说明，乔布斯为了更好和更差超乎寻常地吹毛求疵。（乔布斯还在NeXT商标上花了10万美金。）

Sorkin的电影借助沃兹尼亚克之口宣称，NeXT计算机的失败是注定的——设计它就是为了把乔布斯掷回苹果的轨道。小说容许这样的发明创造，但是正如商业记者Brent Schlender 和 Rick Tetzeli在他们半个人回忆氏纪录《成为乔布斯》中指出的，「NeXT的失败毫无疑问，失败是由乔布斯一手造成的也是毫无疑问的。」2010年，乔布斯面对自画像在斯坦福一个会议上的讲话和Steve Wozniak[/caption]

乔布斯还确实使用了NeXT的幸存资产——软件部门，就像门上的楔子，打开它后让他十年后重返苹果。Avie Tevanian（他是乔布斯忠实的追随者直到乔布斯在2006年把他抛弃）开发的NeXT软件，成为今天Mac电脑简便、稳定、多任务操作系统的基础。然而当时，苹果一落千丈，市值缩水10亿美元，濒临破产。这个支撑着Macintosh图形的、基于图标的操作系统不再强大、灵活，跟不上用户的需求。苹果需要一个新的操作系统，而乔布斯正好有一个。或者，更确切地讲，他有一个软件工程师——Tevanian——他能重构NeXT操作系统并用到苹果上，这一直是乔布斯的目标。不到一年的时间乔布斯以4.29亿美元的价格把这款软件卖给苹果，出任职位权责模糊的顾问一职，苹果CEO走了，董事会也走了，乔布斯重掌大权。

乔布斯的第二个大动作，始于1996年乔布斯作为非正式的顾问回归苹果时，或是1997年他终于赶走了当时苹果CEO，开始执掌大权，真正将他推上了万众瞩目的地位。确实，在几年以前，《Inc.》杂志称他为「十年以来的真正创业家」，即使他失败过，他仍然是传说中的男人。毕竟这可是斯蒂文·乔布斯，第一位把目光给了家用计算机的人，集结了爱好相同的伙伴们，例如斯蒂夫·沃兹尼亚克，并意识到这对于没有兴趣自己动手的人们的吸引力，点燃了整个产业界的创造激情（比尔·盖茨也预见到了同样的事情，并意识到他们需要功能性的软件，并为此从哈佛辍学开始自己写软件）。但是私人计算机，在二十年后非常普遍的一种设备，在乔布斯回归苹果时依旧是天方夜谭。他们缺少——用乔布斯的话来说——「魔力」。&nbsp;回到了他最开始的地方，乔布斯的第一个革新便是为当时人们桌子上常见的米色长方体提供代替品。这个新的设计在1998年揭幕，是一个半透明形状怪异的箱子，人们甚至可以看到它内部的结构（随后又有了许多新的颜色）。它有着一个凹进的手柄，可以移动，尽管它有足足38磅。Mac是一个苹果以i为前缀的产品，标志着它不是昙花一现的产品，而是在互联网迅速崛起的未来中，与广阔世界连接的通道。

它是一个巨大的成功，在第一年售出了接近两百万台。就像Schlender与Tetzeli所说的，iMac色彩斑斓的外壳并不仅仅意味着挑战主流工业审美，也强调并突出了乔布斯领导力，苹果的计算机反射出了个人的独特性。「『i』就是独特的。」他们写道，「这是我的计算机，甚至也许是『我』是谁的表达。」

乔布斯在「i」主题上才刚刚开始（有一段时间他甚至叫自己是苹果的「iCEO」）。苹果在1999年引进了「iMovie」，能够让用户们创造自己的电影。接着两年过去，在收购了一家制作数字点唱机软件的公司后，苹果发布了iTunes，最流行的音乐播放软件。iTunes非常酷，但是让它更酷的是苹果在同年发布的音乐播放器，iPod。根据Schlender与Tetzeli，在iPod之前有过移动数字音乐设备，但是，没有一个具有这样的容量，功能，特别是如此精湛的设计。

iPod用户界面的突破最终让这个产品变得具有魔力，独一无二。即使有很多其他重要的软件革新，就像同步用户iTunes收藏音乐的软件，但是，如果这个团队没有解决成千上万首音乐的播放应用问题，iPod将永无出头之日。&nbsp;到了2001年，接下来，苹果的策略，公司从个人计算机公司转型为个人计算，开始启动。乔布斯说服——或者很可能恐吓了——音乐产业的高管们——后者被人们可以免费将音乐下载到设备中的p2p网站吓坏了——允许苹果以每首歌1美元的价格在iTunes上出售歌曲。乔布斯肯定知道，这为一场商业音乐的戏剧性颠覆搭好了舞台。后果之一就是，苹果和它数百万个iTunes用户，成为品味，影响力和流行时尚的新动力。

苹果为微软操作系统提供iTunes的一个版本，从而让每个拥有个人电脑的用户可以使用这款软件，两年后，苹果加强进军音乐商业。为自己并不尊重的公司提供独特的苹果产品，而且还起诉过对方剽窃Mac操作系统关键元素，Schlender与Tetzeli认为，原因在于乔布斯的同事说服了他，他们说一旦Windows用户体验了苹果优雅精致的软件与硬件后，他们就看到了光芒并克服黑暗面。从苹果最近10兆美元的身价来看，他们貌似是对的。

然而，iPod如今也已经被iPhone,iPod Touch 以及iPad所取代。 与此同时，苹果公司继续生产个人电脑，以及其他能够体现乔布斯简单、纯粹审美的产品。并经Jony Ive之手大获成功，Ive是苹果的首席设计师。他的责任还包括确保苹果所有掌上设备的玻璃元件和金属原件的极简化，将形式集中到功能上。苹果手机之前，市场上的「智能机」也早已存在，并具备收发邮件及网络浏览的功能。然而，惊艳如iPhone：平滑流畅的触摸屏，各种「apps」带来的各种前所未见的功能大大地提高了手机对用户的粘性，手机不再只是用来拨打电话的，现在我们用手机听音乐，读书，玩象棋，录视频并且直接进行剪辑。

乔布斯预见到人们期望手机会变成一个强大的口袋电脑，这种超强的直觉就像他在三十年前时掐指一算，在不久的将来每个人的桌上都台属于自己的电脑。两次预言不仅带来的巨大的金钱效应，还激发了新的产业的诞生——目前，世界范围内的智能手机厂商众多，这催生了21世纪第一批小作坊产业： app制作。任何拥有电脑编程能力的人就可以给iPhone编写游戏或者应用，通过苹果公司审核的app就可以上线进行出售了。现如今，有四个以上苹果app程序的开发人，平均每年能赚21,000美元。如果有人正在记录「兼职经济」的历史——这种没有固定雇佣人，通过完成一些列小的任务来赚钱的形式，不妨从这里写起。&nbsp;Alex Gibney拍摄电影的初衷源于其自身对于乔布斯的疑问 ，为何他能如此受人追捧，在丹尼-鲍尔(Danny Boyle)导演的纪录片中，乔布斯对女儿说自己「人品差劲」（多年以来，乔布斯拒绝承认与女儿的血缘关系，尽管亲子鉴定给出了肯定的报告，他的孩子生活在困境，而他依然没有履行任何抚养义务。最后乔布斯父女关系得到缓和）。Gibney费力追寻着答案，虽然这一历程通常吸引人，但永远无法抵达它想要企及的地方，因为电影制片人已经提出了一个无法回答的问题。

疑问之二：为什么人们对这个男人的着迷可以一直持续？仅仅在这一个季节，就有两部关于乔帮主的电影和一本关于他的新书发布。他无疑是Schlender&amp;Tetzeli在书中所说的商业天才，然而，乔布斯身上最大的特质用他最爱的一句营销名言来形容就是：思不同（Think Indifferent）。如他一般，只关心产品，而不是背后无数的制造者。对他来说，无论是中国工厂的工人还是库比蒂诺的员工（库比蒂诺是苹果公司总部）亦或是像Wozniak，Kottke，Tevanian对苹果的成功起着关键作用的同僚，都是一样的存在。&nbsp;iPhone和其他衍生出的i系列智能设备，将苹果公司从一个高端且小众的电脑公司推上了全球数码行业之首的宝座，并使其成为世界上最富有的公司。 举例来说，2015年的第一季度，iPhone和iPad的销量带给苹果公司81%的收入，而电脑只占到9%。如今，面对手机和电脑市场趋于饱和，苹果公司需要带来一款人人都想要的产品从而爆发新的需求，尽管少了乔布斯的加持。

去年，万众瞩目的苹果手表上市，却没能激发主流消费者的购买热情。发布后第一个月其销售额便掉了90%，并在之后的一年中持续下跌。后来，苹果公司又发布了iPad Pro，屏幕更大，功能更强的pad。然而，销售依旧表现平平。还有传言说苹果即将制造汽车，并在2019年上市——苹果汽车可能是电动的，或许是自动驾驶的，或者从头设计打造，或许并与梅赛德斯奔驰合作。然而这些猜测可能为时尚早——当Tim Cook——苹果现任CEO，在Stephen的节目和Charlie Rose的六十分钟节目被问到有关汽车的问题时，他的回答支支吾吾。&nbsp;尽管如此，在乔布斯离开的几年中，尽管未能推出一个重磅产品，尽管它最近的股价下跌，公司继续增长。2015是苹果最赚钱的一年，到目前为止，营收为2340亿美元。根据金融分析师的分析，这要么是让苹果股票交易，要么是一只熊准备从一棵树上跌落下来。到目前为止，还没有人创建一个应用程序，可以预测未来。

苹果乔布斯去世的第一天之后发布的Siri，iPhone的虚拟助理，是一个好的风向标，预示着人工智能（AI）和机器学习将是下一代苹果产品的核心，正如它将更普遍地成为科技产业核心。

能够实时并在多领域实现一款设备，其人工智能和机器学习能力得以大大增强，正是乔布斯一直寻找的：在人们还没意识到他们想要什么之前，直接给出他们想要的。

今年早些时候，证实这种产品可能样子的公司不是苹果而是谷歌，在年度开发者大会上，谷歌发布了一个早期原型Now on Tap。这个原型的实质是将手机中不同的信息彼此连接起来。例如，一封来自朋友的电子邮件建议了某家餐厅，可能会带来有关该餐厅的评价，去往路线，以及检查日历，看看你那晚是否有空。如果这听起来还好，或许吧，但这些尚处早期——对市场营销的吸引力将是巨大的。&nbsp;谷歌在人工智能和机器学习方面遥遥领先苹果。这是有道理的，部分是因为谷歌的核心业务来自于搜索引擎，搜索引擎产生海量数据。但还有另一个原因，这要回溯到乔布斯身上，以及他给苹果注入的保密文化，公司盛行的文化。正如Tim Cook 在60分钟的采访中所告诉Charlie Rose的那样，「苹果最伟大的事情之一就是(我们)公司很可能比中央情报局还保密。」

这一制度精神似乎已经阻碍了苹果人工智能研究者与该领域其他研究人员的合作或信息共享，阻碍了人工智能的研发，也打消了顶尖研究人员去苹果公司工作的积极性。「真正强大的人不想进入一个四处秘密封闭的环境，」Yoshua Benigo，十月，一位蒙特利尔大学的计算机科学教授告诉彭博商业。「差异化的因素是，『你打算和谁一起工作？』『我将要留在科学界吗？』『我将有多少自由？』」

乔布斯有一个对自由的永久信念——他自己的。就如Gibney的纪录片，Boyle的电影，甚至Schlender和Tetzeli的另类友好评价清楚表明的，乔布斯想要摆脱适用其他人的规则。他想要制造自己的规则，允许他支配别人。乔布斯身边的人对此有一个称谓。他们称之为乔布斯的「现实扭曲力场（reality distortion field）」。因此，当苹果在人工智能的道路上独自前进之时，又多留给我们一个问题：傲慢是乔布斯最后的遗产吗？"
"乔布斯;;《纽约书评》：乔布斯的机器人生亚历克斯·吉布尼(Alex Gibney)的纪录片电影「史蒂夫·乔布斯（Steve Jobs）」堪称诚意之作；丹尼尔·柯特科（Daniel Kottke ，苹果早期员工）看到一半时提了一个问题：「要想成功，你得变得有多混蛋？」最近丹尼·博伊尔（Danny Boyle）拍摄乔布斯传时，已发出了同样的问句。丹尼·博伊尔的电影围绕着乔布斯一生三大阶段的主题---1984年发布Macintosh电脑、1988年发布NeXT电脑、1998年发布iMac笔记本，塑造了一个爱捣乱、行事乖张的人物形象。在博伊尔（和他的编剧艾伦·索金，Aaron Sorkin）心中，显然这个问题有了答案：「混世魔王」。在自己的电影中，吉布尼集合了一些乔布斯生前的朋友、爱人、员工的言论，他们同意上述评判，这令吉布尼颇感困惑。2011年乔布斯去世之时，他的冷酷、傲慢、喜怒无常、爱欺凌他人和其他种种孩子气行为已为大家熟知；彼时，苹果公司设在中国的生产工厂被曝光了恶劣的用工环境——多达几十起的员工自杀——而乔布斯冷漠以对；同时，苹果本身也被爆出谋划逃税一事。那么，乔布斯离世令全球哀恸，究竟是何缘由？吉布尼在电影开篇展现了乔布斯逝世当天的一幕：全世界成千上万的人们在苹果商店门外留下了数不清的鲜花和短笺---「致史蒂夫」；粉丝们眼泪汪汪地通过网络发表着感人至深的悼词；哀悼者聚集在临时搭设的龛笼周围，举起手中烛光闪烁的iPad，向乔布斯致敬。一个大约九、十岁，坐在电脑桌前左右旋转的小男孩道出答案：「我现在用的电脑是iMac，他创造的」，「他创造了iMac。他创造了Mac笔记本。他创造了Mac Pro系列。他创造了Mac Air系列。他创造了iPhone。他创造了iPad。他创造了iPod Touch。他创造了所有这一切。」然而，这个答案远远不够——乔布斯仅仅因为制造了风靡世界的电子产品，就获得身后殊荣吗？为什么乔治·伊士曼、托马斯·爱迪生、亚历山大·格拉汉姆·贝尔等大咖们仙逝当日，人们并未自发涌上街头、哭泣追思？这些英雄可是实实在在地发明了相机、电灯、电话，奠定了现代生活的基石！MIT社会学家Sherry Turkle认为其中的区别在于：人们感念史蒂夫·乔布斯，与其人、与其产品关系不大，打动人们的是这些产品和使用者之间形成的关联，这种关联迅速且有效地消弭了人与人之间的距离。「乔布斯把电子产品打造成了人类自身的延伸物」， Turkle告诉吉布尼，「不仅仅是对人类有用，而且成为人类自己的一部分。」2005年-2007年就任iPhone高级经理的Andy Grignon，在吉布尼的电影中观察到：苹果是一家公司。我们在某种程度上把情感（爱、奉献、崇高的目标感）代入到这家公司了，但公司的本质是为股东赚钱。仅此而已。乔布斯的最伟大的成就之一在于创造了人与人之间的新关联方式。乔布斯是一位完美主义者。所以艾伦·索金很自然便以苹果产品的发布为主线讲述乔布斯的生平。苹果公司的产品发布极富戏剧效果——像一场演出——每次新产品出炉面世，乔布斯都会想方设法参与到发布秀当中。首席创意官Lee Clow乔布斯紧密合作多年，觉得「史蒂夫简直是费尼尔司·泰勒·巴纳姆附身了」，「他爱制造惊喜，他总是说，『我要让你看到这世上最小的男人！（巴纳姆是美国巡回演出团老板和马戏团老板，因展现畸形人的表演而闻名。译者）』他总爱亲手把盖着新产品的那一块黑色绒布揭掉，他关心一切与展示技巧、市场、传播有关的事物。」人们都盼望见证奇迹的时刻。史蒂夫·乔布斯深谙此中奥妙，因此坚决要求必须到最后一刻才能掀开新产品神秘面纱。他这点执念比起「制造惊喜」的爱好有过之而无不及。2005年「经济学人」杂志发问「史蒂夫·乔布斯是不是商业史上最成功的偏执狂？」；同一年，苹果公司起诉一位哈佛新生，指控他运营的网站专门传播、买卖苹果公司小道消息及产品信息。吉布尼还讲述了Jason Chen的故事：Jason Chen是「硅谷日报」编辑，曾公开透露尚在研发阶段的苹果手机产品细节；2010年，一支跨部门执法队---加州警方迅速执法联合计算机小组（REACT）闯入他的住宅进行搜查，带走了他的电脑和其他物品。Gizmodo网站宣称，一名苹果雇员将这支手机遗落在一间酒吧，遭不明人士拾获，并以5000美元的价格向Gizmodo兜售，但早在REACT执法队伍闯入Jason Chen家宅之前4天，Jason Chen已将该支手机归还给了苹果公司。REACT是一个公共机构，然而苹果公司掌控着其委员会，令人不得不质疑，执法机构是否听命于苹果公司？无论是为了保护商业秘密，还是为了保持神秘感，或者两者兼而有之，乔布斯一直坚持把苹果产品做成封闭系统，不接受各种补丁。这是一起苹果诉讼案背后的深层原因——不希望用户「越狱」破解苹果操作系统，使用第三方软件——但是，这宗案件以苹果公司的失败告终。从最开始生产电脑的时候，乔布斯就要求把电脑软硬件一体化，不像微软公司的系统，可应用于任何厂商、任何型号的硬件之中；结果是苹果产品价格高于同类产品，且难以被人抄袭。在丹尼·博伊尔的电影中，斯蒂夫·沃兹尼亚克（苹果联合创始人）对乔布斯的做法持有异议，他认为一台个人电脑改动与否应由自己的主人决定，控制权在终端，「计算机并不是画画儿」；但乔布斯的想法恰恰相反，Macintosh电脑本质具有制造者们的鲜明特征。乔布斯销售的魔力远远超越了公司产品本身：它融入了他自己的故事。从一个百万富翁，到亿万富翁，再到出卖朋友和合伙人，再到被抓到回溯股票期权，再到卖掉苹果大部分的离岸现金以逃税，乔布斯称自己是局外人，一个有原则的反对主流（他认为是盲目的、愚蠢的、缺陷的）文化的叛逆者。你也行，他建议到，如果你和苹果为盟。正是这种花招使消费者相信购买商品也是做好事——这是改变世界的一种方式。记者Joe Nocera告诉Gibney，「围绕苹果的神话是针对一个做手机的公司。手机不是一个神奇的设备。它让你对我们自己感到惊奇，胜过对苹果的惊讶。」为了形象地理解它，你只需要在线浏览 Eric Pickersgill的摄影集「移除（Removed）」，摄影师将日常生活中，比如坐在餐桌旁，窝在沙发里，躺在床上的普通人手中的手机和其它电子设备移除。结果呈现出这样的画面：人们定格在聚精会神盯着被移除设备的瞬间，注意力如此坚定以至于完全不闻窗外事。正如Pickersgill所说：工作起始于我坐在咖啡馆的一个早上。这是我写下的自己的观察：在纽约特洛伊的Illium咖啡馆，坐在我旁边的家人十分生疏。没有太多言语。父亲和两个女儿拿出自己的手机。母亲没有手机或者是把它放起来了。她盯着窗外，在最亲近的家人陪伴下显得孤独、忧伤。爸爸不时地翻阅手机，回应他在网上发现的一些模糊的信息。他又一次谈到捕到的一条大鱼。使用技术去交流换来的却是没有交流，这使我很忧伤。这在之前从未发生过，我怀疑我们已经划开了这种新体验所带来的社交影响的表面。妈妈现在拿出了她的手机。有人假设如果乔布斯还活着，他会为这些图片心动，因为他们证实了这种洞察力——乔布斯在其他人当中所推崇的——他是一个有远见的人，他能让人们看到他们想要的，甚至于在人们知道自己想要之前。正如Gibney所说，「他不只是把自己定位成CEO，而是一位先知。一个能预言未来的人。」

而且他能做到——有时候。但是，值得记住的是，乔布斯在1985年被赶出苹果公司，他倾注公司资源投入的，两个计算机项目，苹果3和另一个名为Lisa计算机，失利惨重几乎让苹果关门。Boyle的讲述中反复出现的场景是乔布斯愁眉苦脸的前伙伴，苹果原型机的实际发明者Steve Wozniak，他求乔布斯公开承认打造了苹果2的团队，当乔布追求这些这些不幸灾难时，是这款苹果2计算机维持着公司的运转，乔布斯轻蔑地把他喷走了。&nbsp;离开苹果之后，乔布斯接下来投资了一个面向研究院和学术机构的计算机工作站，并相应地取名为NeXT，这更是灾难性的。由于价格过高，电量不足，这个计算机卖出很少。Boyle描述了乔布斯痴迷于装NeXT的黑塑料盒的精确尺寸，而不是计算机的实际缺陷，正如乔布斯对苹果1的米色层次的痴迷。这两个故事没有一个是杜撰的，而且很多年来它们都被用来说明，乔布斯为了更好和更差超乎寻常地吹毛求疵。（乔布斯还在NeXT商标上花了10万美金。）

Sorkin的电影借助沃兹尼亚克之口宣称，NeXT计算机的失败是注定的——设计它就是为了把乔布斯掷回苹果的轨道。小说容许这样的发明创造，但是正如商业记者Brent Schlender 和 Rick Tetzeli在他们半个人回忆氏纪录《成为乔布斯》中指出的，「NeXT的失败毫无疑问，失败是由乔布斯一手造成的也是毫无疑问的。」2010年，乔布斯面对自画像在斯坦福一个会议上的讲话和Steve Wozniak[/caption]

乔布斯还确实使用了NeXT的幸存资产——软件部门，就像门上的楔子，打开它后让他十年后重返苹果。Avie Tevanian（他是乔布斯忠实的追随者直到乔布斯在2006年把他抛弃）开发的NeXT软件，成为今天Mac电脑简便、稳定、多任务操作系统的基础。然而当时，苹果一落千丈，市值缩水10亿美元，濒临破产。这个支撑着Macintosh图形的、基于图标的操作系统不再强大、灵活，跟不上用户的需求。苹果需要一个新的操作系统，而乔布斯正好有一个。或者，更确切地讲，他有一个软件工程师——Tevanian——他能重构NeXT操作系统并用到苹果上，这一直是乔布斯的目标。不到一年的时间乔布斯以4.29亿美元的价格把这款软件卖给苹果，出任职位权责模糊的顾问一职，苹果CEO走了，董事会也走了，乔布斯重掌大权。

乔布斯的第二个大动作，始于1996年乔布斯作为非正式的顾问回归苹果时，或是1997年他终于赶走了当时苹果CEO，开始执掌大权，真正将他推上了万众瞩目的地位。确实，在几年以前，《Inc.》杂志称他为「十年以来的真正创业家」，即使他失败过，他仍然是传说中的男人。毕竟这可是斯蒂文·乔布斯，第一位把目光给了家用计算机的人，集结了爱好相同的伙伴们，例如斯蒂夫·沃兹尼亚克，并意识到这对于没有兴趣自己动手的人们的吸引力，点燃了整个产业界的创造激情（比尔·盖茨也预见到了同样的事情，并意识到他们需要功能性的软件，并为此从哈佛辍学开始自己写软件）。但是私人计算机，在二十年后非常普遍的一种设备，在乔布斯回归苹果时依旧是天方夜谭。他们缺少——用乔布斯的话来说——「魔力」。&nbsp;回到了他最开始的地方，乔布斯的第一个革新便是为当时人们桌子上常见的米色长方体提供代替品。这个新的设计在1998年揭幕，是一个半透明形状怪异的箱子，人们甚至可以看到它内部的结构（随后又有了许多新的颜色）。它有着一个凹进的手柄，可以移动，尽管它有足足38磅。Mac是一个苹果以i为前缀的产品，标志着它不是昙花一现的产品，而是在互联网迅速崛起的未来中，与广阔世界连接的通道。

它是一个巨大的成功，在第一年售出了接近两百万台。就像Schlender与Tetzeli所说的，iMac色彩斑斓的外壳并不仅仅意味着挑战主流工业审美，也强调并突出了乔布斯领导力，苹果的计算机反射出了个人的独特性。「『i』就是独特的。」他们写道，「这是我的计算机，甚至也许是『我』是谁的表达。」

乔布斯在「i」主题上才刚刚开始（有一段时间他甚至叫自己是苹果的「iCEO」）。苹果在1999年引进了「iMovie」，能够让用户们创造自己的电影。接着两年过去，在收购了一家制作数字点唱机软件的公司后，苹果发布了iTunes，最流行的音乐播放软件。iTunes非常酷，但是让它更酷的是苹果在同年发布的音乐播放器，iPod。根据Schlender与Tetzeli，在iPod之前有过移动数字音乐设备，但是，没有一个具有这样的容量，功能，特别是如此精湛的设计。

iPod用户界面的突破最终让这个产品变得具有魔力，独一无二。即使有很多其他重要的软件革新，就像同步用户iTunes收藏音乐的软件，但是，如果这个团队没有解决成千上万首音乐的播放应用问题，iPod将永无出头之日。&nbsp;到了2001年，接下来，苹果的策略，公司从个人计算机公司转型为个人计算，开始启动。乔布斯说服——或者很可能恐吓了——音乐产业的高管们——后者被人们可以免费将音乐下载到设备中的p2p网站吓坏了——允许苹果以每首歌1美元的价格在iTunes上出售歌曲。乔布斯肯定知道，这为一场商业音乐的戏剧性颠覆搭好了舞台。后果之一就是，苹果和它数百万个iTunes用户，成为品味，影响力和流行时尚的新动力。

苹果为微软操作系统提供iTunes的一个版本，从而让每个拥有个人电脑的用户可以使用这款软件，两年后，苹果加强进军音乐商业。为自己并不尊重的公司提供独特的苹果产品，而且还起诉过对方剽窃Mac操作系统关键元素，Schlender与Tetzeli认为，原因在于乔布斯的同事说服了他，他们说一旦Windows用户体验了苹果优雅精致的软件与硬件后，他们就看到了光芒并克服黑暗面。从苹果最近10兆美元的身价来看，他们貌似是对的。

然而，iPod如今也已经被iPhone,iPod Touch 以及iPad所取代。 与此同时，苹果公司继续生产个人电脑，以及其他能够体现乔布斯简单、纯粹审美的产品。并经Jony Ive之手大获成功，Ive是苹果的首席设计师。他的责任还包括确保苹果所有掌上设备的玻璃元件和金属原件的极简化，将形式集中到功能上。苹果手机之前，市场上的「智能机」也早已存在，并具备收发邮件及网络浏览的功能。然而，惊艳如iPhone：平滑流畅的触摸屏，各种「apps」带来的各种前所未见的功能大大地提高了手机对用户的粘性，手机不再只是用来拨打电话的，现在我们用手机听音乐，读书，玩象棋，录视频并且直接进行剪辑。

乔布斯预见到人们期望手机会变成一个强大的口袋电脑，这种超强的直觉就像他在三十年前时掐指一算，在不久的将来每个人的桌上都台属于自己的电脑。两次预言不仅带来的巨大的金钱效应，还激发了新的产业的诞生——目前，世界范围内的智能手机厂商众多，这催生了21世纪第一批小作坊产业： app制作。任何拥有电脑编程能力的人就可以给iPhone编写游戏或者应用，通过苹果公司审核的app就可以上线进行出售了。现如今，有四个以上苹果app程序的开发人，平均每年能赚21,000美元。如果有人正在记录「兼职经济」的历史——这种没有固定雇佣人，通过完成一些列小的任务来赚钱的形式，不妨从这里写起。&nbsp;Alex Gibney拍摄电影的初衷源于其自身对于乔布斯的疑问 ，为何他能如此受人追捧，在丹尼-鲍尔(Danny Boyle)导演的纪录片中，乔布斯对女儿说自己「人品差劲」（多年以来，乔布斯拒绝承认与女儿的血缘关系，尽管亲子鉴定给出了肯定的报告，他的孩子生活在困境，而他依然没有履行任何抚养义务。最后乔布斯父女关系得到缓和）。Gibney费力追寻着答案，虽然这一历程通常吸引人，但永远无法抵达它想要企及的地方，因为电影制片人已经提出了一个无法回答的问题。

疑问之二：为什么人们对这个男人的着迷可以一直持续？仅仅在这一个季节，就有两部关于乔帮主的电影和一本关于他的新书发布。他无疑是Schlender&amp;Tetzeli在书中所说的商业天才，然而，乔布斯身上最大的特质用他最爱的一句营销名言来形容就是：思不同（Think Indifferent）。如他一般，只关心产品，而不是背后无数的制造者。对他来说，无论是中国工厂的工人还是库比蒂诺的员工（库比蒂诺是苹果公司总部）亦或是像Wozniak，Kottke，Tevanian对苹果的成功起着关键作用的同僚，都是一样的存在。&nbsp;iPhone和其他衍生出的i系列智能设备，将苹果公司从一个高端且小众的电脑公司推上了全球数码行业之首的宝座，并使其成为世界上最富有的公司。 举例来说，2015年的第一季度，iPhone和iPad的销量带给苹果公司81%的收入，而电脑只占到9%。如今，面对手机和电脑市场趋于饱和，苹果公司需要带来一款人人都想要的产品从而爆发新的需求，尽管少了乔布斯的加持。

去年，万众瞩目的苹果手表上市，却没能激发主流消费者的购买热情。发布后第一个月其销售额便掉了90%，并在之后的一年中持续下跌。后来，苹果公司又发布了iPad Pro，屏幕更大，功能更强的pad。然而，销售依旧表现平平。还有传言说苹果即将制造汽车，并在2019年上市——苹果汽车可能是电动的，或许是自动驾驶的，或者从头设计打造，或许并与梅赛德斯奔驰合作。然而这些猜测可能为时尚早——当Tim Cook——苹果现任CEO，在Stephen的节目和Charlie Rose的六十分钟节目被问到有关汽车的问题时，他的回答支支吾吾。&nbsp;尽管如此，在乔布斯离开的几年中，尽管未能推出一个重磅产品，尽管它最近的股价下跌，公司继续增长。2015是苹果最赚钱的一年，到目前为止，营收为2340亿美元。根据金融分析师的分析，这要么是让苹果股票交易，要么是一只熊准备从一棵树上跌落下来。到目前为止，还没有人创建一个应用程序，可以预测未来。

苹果乔布斯去世的第一天之后发布的Siri，iPhone的虚拟助理，是一个好的风向标，预示着人工智能（AI）和机器学习将是下一代苹果产品的核心，正如它将更普遍地成为科技产业核心。

能够实时并在多领域实现一款设备，其人工智能和机器学习能力得以大大增强，正是乔布斯一直寻找的：在人们还没意识到他们想要什么之前，直接给出他们想要的。

今年早些时候，证实这种产品可能样子的公司不是苹果而是谷歌，在年度开发者大会上，谷歌发布了一个早期原型Now on Tap。这个原型的实质是将手机中不同的信息彼此连接起来。例如，一封来自朋友的电子邮件建议了某家餐厅，可能会带来有关该餐厅的评价，去往路线，以及检查日历，看看你那晚是否有空。如果这听起来还好，或许吧，但这些尚处早期——对市场营销的吸引力将是巨大的。&nbsp;谷歌在人工智能和机器学习方面遥遥领先苹果。这是有道理的，部分是因为谷歌的核心业务来自于搜索引擎，搜索引擎产生海量数据。但还有另一个原因，这要回溯到乔布斯身上，以及他给苹果注入的保密文化，公司盛行的文化。正如Tim Cook 在60分钟的采访中所告诉Charlie Rose的那样，「苹果最伟大的事情之一就是(我们)公司很可能比中央情报局还保密。」

这一制度精神似乎已经阻碍了苹果人工智能研究者与该领域其他研究人员的合作或信息共享，阻碍了人工智能的研发，也打消了顶尖研究人员去苹果公司工作的积极性。「真正强大的人不想进入一个四处秘密封闭的环境，」Yoshua Benigo，十月，一位蒙特利尔大学的计算机科学教授告诉彭博商业。「差异化的因素是，『你打算和谁一起工作？』『我将要留在科学界吗？』『我将有多少自由？』」

乔布斯有一个对自由的永久信念——他自己的。就如Gibney的纪录片，Boyle的电影，甚至Schlender和Tetzeli的另类友好评价清楚表明的，乔布斯想要摆脱适用其他人的规则。他想要制造自己的规则，允许他支配别人。乔布斯身边的人对此有一个称谓。他们称之为乔布斯的「现实扭曲力场（reality distortion field）」。因此，当苹果在人工智能的道路上独自前进之时，又多留给我们一个问题：傲慢是乔布斯最后的遗产吗？"
"机器人;;照顾老人这件事，欧洲决定交给机器人来做到 2020 年，Robosoft 计划每年生产10,000 万台 Kompaï 机器人，这款机器人是为在家里协助老年人设计的。在意大利比萨郊区，退休的 Maurizio Feraboli 将购物清单输进了一台平板电脑，然后派出轮式机器人去自己公寓附近的一家商店取食物。他的邻居 Wanda Mascitelli 指导着机器人从她的厨房抓起垃圾然后将其扔进位于街口的垃圾箱中。一个机器人还提醒 Mascitelli 注意可能的煤气泄漏，然后给她带来了一杯水和一瓶维生素。这些场景来自一段一个欧洲研究项目 Robot-Era（机器人时代）的推广视频，该项目近日结束，这是世界上规模最大的为老人提供机器人助手的真实生活实验。来自意大利和瑞典大约 160 位老年人在这个为期 4 年的项目中对机器人进行了测试，该项目得到了欧盟委员会 650 万欧元（720 万美元）和包括意大利制造商 Robotech 以及苹果的供应商意法半导体提供的共 220 万欧元的资金支持。现在，Robot-Era 经理 Filippo Cavallo 以及位于比萨郊区圣安娜高等研究学院 BioRobotics 研究所的教授同事们已经成立了一家名为 Co-Robotics 的公司以对该技术进行商业化。「视频中的机器人已经准备好了」进行更多测试， Cavallo 说，他计划尽快在明年开始销售它们。作为增强该地区机器人产业的计划的一部分，欧盟委员会每年都将上千万欧元投入到帮助老年人的技术中。这些项目可能没有东芝的看起来像日本女人的机器人 ChihiraAico 那样轰动，当然也赶不上本田的人形机器助手 Asimo那样知名，但结果是「同一水平或甚至更先进的」，Uwe Haass 说，他是 EuRobotics 一位前秘书长，该机构是在布鲁塞尔与欧盟委员会合作的一个非盈利性的游说组织。在欧盟委员会以及西门子、意大利电信等合作伙伴提供的 430 万欧元的支持下，2015 年 2 月一个名叫 Acanto 的项目诞生，该项目的目的是为了开发可以鼓励老年人进行锻炼和社交的助行器。西班牙、意大利和英国的大约 100 位老年人将在2018年实验结束之前测试这些设备。负责该项目的特伦托大学计算机工程教授 Luigi Palopoli 表示，该项目的目标是得到一款为医院提供的助行器版本和一款更便宜的售价低于 2000 欧元的家庭版本。他说，「一种是机器人但看起来不像机器人的助行器」更有机会被接纳进日常生活。「围绕着机器人在积极健康老龄化领域的使用上，委员会有非常明确的目标。」——评估寻求欧盟委员会资助的项目的外部评估员 Andy Bleaden欧盟委员会已经给了一个正在为患有痴呆症的人开发机器人伴侣的组织 Mario 400 万欧元。「你可以问机器人同样的事情 10 遍，而且它永远不会生气，」爱尔兰国立大学（高威）护理和助产学院教授 Kathy Murphy 说。她正帮助管理这个和法国开发商 Robosoft 及英国斯托克波特的小镇等合作伙伴合作的研究项目。今年夏天，Mario 将开始在爱尔兰、英国和意大利开始与老年人开展项目试点。Murphy 说，到 2018 年项目结束时的目标是商业化一种「医疗保健提供者都希望购买的高性价比机器人」，以帮助老人减轻寂寞和孤独感，并减少医疗保健人员。「围绕着机器人在积极健康老龄化领域的使用上，委员会有非常明确的目标。」斯托克波特的资金和项目经理兼评估寻求欧盟委员会资助的项目的外部评估员 Andy Bleaden 说。除了解决一种社会需求，他说，「欧盟把钱放在桌子上的原因是想让我们可以比竞争对手更快地投入市场。」那就是 Vincent Dupourqué 的目标，他是法国 Robosoft公司的创始人，该公司制造了 Mario 项目正在测试中的 Kompaï 机器人。Dupourqué 是一位生物医学工程师，自 1970 年代末以来就一直在从事机器人方面的工作，他计划明年将 Kompaï 机器人投入商业化生产，并到 2020 年达到 年产 10,000 台，单台售价为 5000 欧元。Dupourqué 说，因为护理人员的短缺和养老院与保险公司对机器人的滚雪球式的兴趣，「现在正是加速的时候。」据法兰克福国际机器人联合会（IFR）的一份秋季报告指出，2014 年全世界厂商共销售了 4416 台老年人和残障人士辅助机器人。IFR 将老年人护理描述为「明天的主要市场」，而且从 2015 年到 2018 年项目销售将总共达到 32,500 台。证明机器人可以让老年人的生活质量更好并能降低护理成本对开拓这个市场来说是很关键的，Intériale 公司创意总监 Anne Gradvohl 说，该公司是一家位于巴黎的保险公司，去年与几个老年客户测试了 Kompaï 机器人。参与者「意识到机器人并不会让关系非人性化，」她说，「他们意识到机器人并不要是取代护理人员」，而是他们的补充，也「能让他们的家人安心以防意外的发生。」Gradvohl 还表述，其它保险公司也在投资关注老年人的机器人公司，而她也正计划第二轮使用 Kompaï 机器人的家中应用测试。这将为有需要的更多客户提供持续 6 到 12 个月的日常协助。「我们不考虑将机器人作为每一个问题的答案，」她说，「但它可以以合理的价格帮助人们更长时间安全地待在家里。」

底线：据一项估计，从 2015 年到 2018 年，为帮助老年人和残障人士而设计的机器人的销量将达到32,500 台。

&nbsp;"
"机器人;;为何机器人无法理解讽刺？人工智能还未能领会人类交流的一些精妙之处。人工智能和演算法的能力惊人：计算机能横扫《危险边缘》（美国最流行的一档智力问答竞赛节目——译注）的答题版，能计算出高精度的圆周率，还能熟练地发推特而不会患上腕管综合症。

然而，当人工智能离开数学领域，进入更微妙的人类交流领域时，它们往往表现糟糕。机器人对幽默的理解非常欠缺和无力，自己常常闹笑话。&nbsp;最近，当Siri搜索歌曲不给力时，我就挖苦它以表达自己的不满。

“Siri，你真是聪明过人。”我面无表情地说道。

“啊，哪有。”Siri认真地回答。她的无知只是聊天机器人和语音操作系统的一个例子而已，它们作为人类新奇的消遣工具和不可或缺的数字助理，却非常缺乏幽默感。

我们能指望人工智能掌握讽刺吗？一些虚构的例子让人浮想联翩：在斯派克·琼斯的电影《她》中，斯嘉丽·约翰逊配音的萨曼莎（电脑操作系统——译注）比她的人类伴侣更嬉皮笑脸；在《星球大战》的宇宙中，机器人R2-D2只要用哔哔声和口哨声就能传达它的冷嘲热讽。&nbsp;诺亚·古德曼是斯坦福大学的一位助理教授，专门研究心理学、计算机科学和语言学，他认为，人类首先要确定自己对讽刺的理解。“在给计算机编程，让它做一件很酷的事之前，你得了解这件很酷的事是什么，”古德曼说，“而我们才刚刚开始了解到底什么是交流的精妙之处。”

伊丽莎白·坎普也认为讽刺令人迷惑、十分复杂，她是罗格斯大学的一位副教授，研究语言和思维哲学。她说：“像社会动力学和权力动力学，所有这些领域给讽刺贴上的标签都是它‘与人类息息相关’。”

古德曼和坎普解释道，让讽刺发挥作用的是围绕它的语境。过去的经历和情感的潜在意义构成了复杂的框架，但是这对机器来说却是块绊脚石。古德曼说，把这种层次的知识输入给机器人需要的不仅仅是几行时髦的代码。同样的原因也导致我们不常遇到能运用或理解夸张的机器人。&nbsp;古德曼说，目前那些结合了人工智能和幽默感的系统有所成效，但仍处于初级阶段。他解释道：“它们的工作原理通常是基于识别或产生极为有限的模版。”这也是为什么一个机器人上一秒可能讲了个“你妈妈”的笑话（“Yo’ Mama”是美国青少年比较常用的一种吐槽形式——译注），下一秒就完全没有幽默感了。奥伦·提苏尔是哈佛和美国东北大学的博士后研究生，专门研究自然语言处理和网络科学，他几年前建立了一种搜索讽刺用语的算法。他说，这个程序能检测出亚马逊网站评论和推特中的讽刺用语，却不懂调侃。然而，它能学着识别文本中的某些话语模式。

米茜·卡明斯是麻省理工大学的一位副教授，研究人机交互，她认为如今的技术不可能制造出尖酸刻薄的机器人。她说：“机器人在理解清晰、明确的指令时仍然有困难，更别说理解讽刺用语中的微妙差别。”尖酸刻薄的机器人是“圣杯”，她解释道。她还补充：“你可以让世界上所有的机器学习语言，但是讽刺往往在于语气而非语言，或者关乎表情。讽刺有许多非语言的元素。”&nbsp;卡明斯还注意到——可能很讽刺——程序员或许不是破译讽刺并将其转化成代码的最佳人选：他们需要喜剧演员的帮助。她说：“我们需要进一步想一想，怎样让更多不同类型的研究人员参与其中，使得这个过程的合作性更强。”&nbsp;喜剧演员约翰·拉兹完全接受这个想法，他是《赛金花晚间秀》的电视编剧，还饰演过《我为喜剧狂》中的呆子J.D.拉兹。他告诉我：“我知道这个世界吵着要‘拉兹机器人-4000’，而我哪能阻止他们。”此外，拉兹还注意到，先进的人工智能已经出现在了黄金时段播出的电视中。他说：“我认为比尔·奥莱利（他被公认为是保守评论家并自称为“传统主义者”——译注）做得很棒。”（如果让一台电脑说出拉兹的妙语，它很可能会从字面上解释这个玩笑。）《我为喜剧狂》中的另一位喜剧演员基斯·鲍威尔则认为机器人不需要学习讽刺：它们几乎已经占领了这个世界，而且很好的阻止了人类互动。“我排队等待咖啡，而每个人都在看自己的手机，”鲍威尔说，“这样看来，机器人不用领悟交流中的讽刺，因为根本就没有交流可言。”

如果出言不逊的机器人还遥不可及，科学家能至少估算一下它们到来的日子吗？“人工智能里的讽刺、反话，任何类型的微妙情感——我们距此还很远，”卡明斯说，“在学术界，我认为至少需要20年的时间。”&nbsp;古德曼更加不确信。他说：“我从来不习惯为任何事情设定一个日期。”但是他提到智能机器不会无约而至——随着比如今更智能的机器人出现，它们会接踵而至。

然而，有些人不想要尖酸刻薄的机器人。想象一下：一辆粗暴无礼、年轻气盛的智能车拒绝启动，只因为油箱里的汽油不够高级。

“我最不愿意机器人做的事就是挖苦人。”巴斯蒂安·特隆说。他是一位斯坦福大学出生并在谷歌工作过的机器人学专家。“我希望它们实用又可靠——就像我家的洗碗机。” &nbsp;&nbsp;"
"算法;;算法让「CRISPR」火得名副其实生物科技学家正在踊跃抓住使用革命性基因编辑利器CRISPR的良机。这个分子工具能通过编程准确调整任何有机体的DNA，但是，科学家仍需要加快编程速度的软件算法。目前，有数十个团队正在开发这样的软件，而且每个团队都面临着赶上快速发展的科学的重任和一个日益拥挤的领域。CRISPR –「规律成簇间隔短回文重复」缩写，是一个在微生物中发现的基因现象，被科学家用来在指定位置上摧毁或者添加DNA。CRISPR软件不是第一个基因编辑工具，但它是迄今为止操作最简单，最便宜的，并且自从四年前升级以来，已经得到世界范围内的使用。研究人员可以用它移除动物模型的基因，研究该基因的功能；生产药用微生物，创立基因疗法来治疗疾病；并且在未来—伦理争论结束后—用来消除人类胚胎中的遗传性疾病。

在不到四年的时间里，CRISPR「已经改变了世界各地的生物实验室。」该技术的贡献者之一，来自位于查尔斯镇，马萨诸塞州总医学院心血管研究中心的化学生物学家Jing-Ruey Joanna Yeh说：「因为这个系统是如此的简单、高效，任何实验室都可以使用。」传统的基因改造技术把DNA梭进细胞里面，但没法预知基因组会粘在哪里。使用CRISPR就像用光标在文档中的两个字母中间点击「删除」或者「粘贴」。工具的使用费不超过$50美元。市面上有其它和CRISPR一样精确的基因组编辑系统，但它们都需要定制，并且需要更多的专业知识和资源来组装。

「尽管较之以前的工具，CRISPR很赞，但它并不总是管用。」加州大学伯克利分校创新基因组的科学主任Jacob Corn说：「我们感到很费解，」但那也是软件流行起来的原因。开发新算法可以帮助研究人员设计出更容易取得成功的CRISPR。&nbsp;CRISPR系统配有两个主要特征：1）一个可编程的基因代码短链（向导RNA）；2）一个充当分子剪刀的蛋白质（通常是被称作Cas9的酶）。一旦复合物被导入细胞，向导RNA会把Cas9带到生物体DNA序列（或基因组）内的准确位置，像魔术贴一样粘在上面，并让Cas9剪断该DNA。接下来，细胞自身机制会修护切口，在这一过程中，毁坏或者添加一些DNA，破坏基因。研究人员也可以有意将新的基因代码导入这个位置。

向导RNA通过寻找带有分子互补代码的DNA片段，来发现自己在生物体基因组内的目标。这些分子被称为碱基，并用字母A（腺嘌呤），T（胸腺嘧啶），G（鸟嘌呤），和C（胞嘧啶）表示。 智能剪刀：CRISPR系统包括能够砍掉DNA的酶和向导RNA，它将酶放在基因组的正确点位上。向导RNA被设计用来将酶导向DNA中的特别位点。[/caption]

DNA把基因编码成化学序列（符号A，T，G，C），让它们与互补的序列交配（A与T，G与C），形成分子螺旋线的阶梯。

向导RNA把CRISPR复合体带到DNA里的互补位点，亦即酶寻找被称为「protospacer相邻基序」（缩写为PAM）地标的地方。如果复合体同时找到匹配的DNA和PAM，它将剪断DNA链，打乱基因的序列或者在相同的地方创造新的DNA。&nbsp;编辑基因组的科学家通常是寻找一个控制特定功能的片段——一个基因。它们大概有几百到几千碱基那么长。不过，向导RNA只有20组碱基的长度，所以，科学家们必须选择位于基因中，以20组为单位的互补碱基段作为目标。这里有两个需要考虑的限制：一）目标必须靠近分子剪刀可以识别的地标；二）目标不能与基因组里其它任何地方由20组碱基组成的片段相同。

由Cas9酶查找的地标叫做「protospacer相邻基序」（缩写为PAM）。「PAM」在基因组里很容易找到：就像在一本书里找「the」字。任何一个在「PAM」旁边，以20组为单位的互补碱基都可以作为目标点位。

不过，想要确保这20组互补碱基的独特性很难。对于只有四个变量的基因代码来说，大多数生物的基因组有几百到数十亿组的碱基对，模式经常重复。向导RNA会被诱饵片段（decoy segments），叫做脱靶位点（off-target sites），分散注意力，而且可能最终让错误的基因发生突变。与目标片段存在几个碱基差异的片段能妨碍到工具工作。「你能用眼扫描整个基因组，找出（脱靶位点），但要花很长时间。」负责开发CRISPR软件Protospacer工作台，来自巴黎巴斯德研究所的数据学家Cameron Ross McPherson说。

仅需来自用户的少数输入，基因编辑软件的算法就能进行快速搜索。由哈佛大学开发的CHOPCHOP要求用户输入生物体的名称，基因的名称，和其它可选的高级参数。在短短的几秒钟内，该算法可以找出目标基因内，所有在「PAM」附近的以20组为单位的互补碱基，并根据它们在基因组和其它参数中的独特性排名，生成一张向导RNA清单。例如，对斑马鱼爪子 （spaw）基因的检索产生了55个可能的向导RNA，其中大部分拥的RNA是与其它基因组有至少两处不同的独特序列.

在过去的两年内，有数十个这样的软件工具问世，大多数都是免费的。也有些公司，比如来自旧金山的Benchling，提供比免费公开版本更好用的用户界面。但没有一个脱颖而出的软件系统，开发CRISPR的软件E-CRISP，来自位于海德堡，德国癌症研究中心的Michael Boutros说。Boutros表示还有大量工作需要完成。拥有一个有55个理论上可能有用的向导RNA的清单是一个有益的起点，但是，留给研究人员的任务是必须以试错的方式判断出那个最管用。人们需要能确定预测某个特别向导RNA将会有用的算法。

为此，生物统计学家开始整理试验数据，寻找成功向导RNA的普遍特征，用来指导基于机器学习的预测系统。但是,大部分数据都分散在小型的个人研究里。「把所有数据都放在一起将形成非常强大的资源，这是电脑工程师的机遇。」加州伯克利的Jacob Corn说。不过，现阶段也存在一些大型数据集。来自马萨诸塞州剑桥Broad研究所的一组研究人员近期在人类和老鼠细胞上测试了近2,000组向导RNA，并且发表了一组改进算法的规定。

与此同时，科学家正在试图改造Cas9和其它用来切割的蛋白质，试图为CRISPR用户提供更多的操作选择。这其中的一些蛋白质可以提高向导RNA的准确度。如果他们成功了，对预测精准度软件的需求可能会消失，或者更新。「如果可以完全消除脱靶的可能性，那很好。」Corn说：「但是我们做到了吗？还没有。」"
"生成对抗网络;;生成对抗网络初学入门：一文读懂GAN的基本原理（附资源）生成对抗网络是现在人工智能领域的当红技术之一。近日，Sigmoidal.io 的博客发表了一篇入门级介绍文章，对 GAN 的原理进行了解释说明。另外，在该文章的最后还附带了一些能帮助初学者自己上手开发实验的资源（包含演讲、教程、代码和论文），其中部分资源机器之心也曾有过报道或解读，读者可访问对应链接查阅。你怎么教一台从未见过人脸的机器学会绘出人脸？计算机可以存储拍字节级的照片，但它却不知道怎样一堆像素组合才具有与人类外表相关的含义。多年以来，已经出现了很多各种各样旨在解决这一问题的生成模型。它们使用了各种不同的假设来建模数据的基本分布，有的假设太强，以至于根本不实用。对于我们目前的大多数任务来说，这些方法的结果仅仅是次优的。使用隐马尔可夫模型生成的文本显得很笨拙，而且可以预料；变分自编码器生成的图像很模糊，而且尽管这种方法的名字里面有「变」，但生成的图像却缺乏变化。所有这些缺陷都需要一种全新的方法来解决，而这样的方法最近已经诞生了。在这篇文章中，我们将对生成对抗网络（GAN）背后的一般思想进行全面的介绍，并向你展示一些主要的架构以帮你很好地开始学习，另外我们还将提供一些有用的技巧，可以帮你显著改善你的结果。GAN 的发明生成模型的基本思想是输入一个训练样本集合，然后形成这些样本的概率分布的表征。常用的生成模型方法是直接推断其概率密度函数。在我第一次学习生成模型时，我就禁不住想：既然我们已经有如此多的真实训练样本了，为什么还要麻烦地做这种事呢？答案很有说服力，这里给出了几个需要优秀生成模型的可能的应用：1. 模拟实验的可能结果，降低成本，加速研究2. 使用预测出的未来状态来规划行动——比如「知道」道路下一时刻状况的 GAN3. 生成缺失的数据和标签——我们常常缺乏格式正确的规整数据，而这会导致过拟合4. 高质量语音生成5. 自动提升照片的质量（图像超分辨率）2014 年，Ian Goodfellow 及其蒙特利尔大学的同事引入了生成对抗网络（GAN）。这是一种学习数据的基本分布的全新方法，让生成出的人工对象可以和真实对象之间达到惊人的相似度。GAN 背后的思想非常直观：生成器和鉴别器两个网络彼此博弈。生成器的目标是生成一个对象（比如人的照片），并使其看起来和真的一样。而鉴别器的目标就是找到生成出的结果和真实图像之间的差异。这张图给出了生成对抗网络的一个大致概览。目前最重要的是要理解 GAN 差不多就是把两个网络放到一起工作的方法——生成器和鉴别器都有它们自己的架构。要更好地理解这种思想的根源，我们需要回忆一些基本的代数知识并且问我们自己一个问题：如果一个网络分类图像的能力比大多数人还好，那么我们该怎么欺骗它？对抗样本在我们详细描述 GAN 之前，我们先看看一个有些近似的主题。给定一个训练后的分类器，我们能生成一个能骗过该网络的样本吗？如果我们可以，那看起来又会如何？事实证明，我们可以。不仅如此，对于几乎任何给定的图像分类器，都可以通过图像变形的方式，在新图像看起来和原图像基本毫无差别的情况下，让网络得到有很高置信度的错误分类结果！这个过程被称为对抗攻击（adversarial attack），而这种生成方式的简单性能够给 GAN 提供很多解释。对抗样本（adversarial example）是指经过精心计算得到的旨在误导分类器的样本。下图是这一过程的一个示例。左边的熊猫所属的分类就和右边的不一样——右边的图被分类为了长臂猿。图片来自：Goodfellow, 2017图像分类器本质上是高维空间中的一个复杂的决策边界。当然，在涉及到图像分类时，我们没法画出这样的边界线。但我们可以肯定地假设，当训练完成后，得到的网络无法泛化到所有的图像上——只能用于那些在训练集中的图像。这样的泛化很可能不能很好地近似真实情况。换句话说，它与我们的数据过拟合了——而我们可以利用这一点。让我们首先向图像加入一些随机噪声，并且确保噪声非常接近于 0。我们可以通过控制噪声的 L2 范数来实现这一点。你不用担心 L2 范数这个数学概念，对于大多数实际应用而言，你可以将其看作是一个向量的长度。这里的诀窍是你的图像中的像素越多，其平均 L2 范数就越大。所以，如果你的噪声的范数足够低，你就可以认为它在视觉上是不可感知的；但是在向量空间中，加入噪声的图像可以与原始图像相距非常远。为什么会这样呢？如果 H×W 的图像是一个向量，那么我们加入其中的 H×W 噪声也是一个向量。原始图像有各种各样相当密集的颜色——这会增加 L2 范数。另一方面，噪声则从视觉上看起来是一张混乱的而且相当苍白的图像——一个小范数的向量。最后我们将它们加到一起，得到的受损图像看起来和原图像很接近，但却会被错误地分类！现在，如果原始类别「狗」的决策边界没有那么远（在 L2 范数角度来看），那么增加的这点噪声会将新的图像带到决策边界之外。你不需要成为世界级的拓扑学家，也能理解特定类别的流形或决策边界。因为每张图像只是高维空间中的一个向量，在它们之上训练的分类器就是将「所有猴子」定义为「这个用隐含参数描述的高维 blob（二进制大对象）中的所有向量」。我们将这个 blob 称为该类别的决策边界。好了，也就是说我们可以通过添加随机噪声来轻松欺骗网络。那生成新图像还必须做什么？生成器和鉴别器现在我们已经简单了解了对抗样本，我们离 GAN 只有一步之遥了！那么，如果我们前面部分描述的分类器网络是为二分类（真和加）设计的呢？根据 Goodfellow 等人那篇原始论文的说法，我们称之为鉴别器（Discriminator）。现在让我们增加一个网络，让其可以生成会让鉴别器错误分类为「真」的图像。这个过程和我们在对抗样本部分使用的过程完全一样。这个网络称为生成器（Generator）。对抗训练这个过程为其赋予了一些迷人的特性。在训练的每一步，鉴别器都要区分训练集和一些假样本的图像，这样它区分真假的能力就越来越强。在统计学习理论中，这本质上就意味着学习到了数据的底层分布。那当鉴别器非常擅长识别真假时，欺骗它能有什么好处呢？没错！能用来学习以假乱真的赝品！图片来自：Goodfellow, 2016有一个古老但睿智的数学结果最小最大定理（Minimax theorem）开启了我们所知的博弈论的先河，其表明：对于零和博弈中的两个玩家而言，最小最大解决方案与纳什均衡是一样的。哇！这都说的啥！简单来说，当两个玩家（D 和 G）彼此竞争时（零和博弈），双方都假设对方采取最优的步骤而自己也以最优的策略应对（最小最大策略），那么结果就已经预先确定了，玩家无法改变它（纳什均衡）。图片来自：Goodfellow, 2017所以，对于我们的网络而言，这意味着如果我们训练它们足够长时间，那么生成器将会学会如何从真实「分布」中采样，这意味着它开始可以生成接近真实的图像，同时鉴别器将无法将其与真实图像区分开。上手学习的最佳架构理论归理论，当涉及到实践时，尤其是在机器学习领域，很多东西就是没法起效。幸运的是，我们收集了一些有用的小点子，可以帮助得到更好的结果。在这篇文章中，我们将首先回顾一些经典的架构，并提供一些相关链接。深度卷积生成对抗网络（DCGAN）在 GAN 的第一篇论文出来之后的大概一年时间里，训练 GAN 与其说是科学，倒不如说是艺术——模型很不稳定，需要大量调整才能工作。2015 年时，Radford 等人发表了题为《使用深度卷积生成对抗网络的无监督表征学习（Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks）》的论文，描述了之后被称为 DCGAN 的著名模型。图片来自：Radford et al., 2015关于 DCGAN，最值得一提的是这个架构在大多数情况下都是稳定的。这是第一篇使用向量运算描述生成器学习到的表征的固有性质的论文：这与 Word2Vec 中的词向量使用的技巧一样，但却是对图像操作的！图片来自：Radford et al., 2015DCGAN 是最简单的稳定可靠的模型，我们推荐从它开始上手。后面我们给出了一些训练和实现的有用技巧，并提供了代码示例的链接。条件 GAN（Conditional GAN）这是研究者提出的一种 GAN 的元架构的扩展，以便提升生成图像的质量，你也可以把它称为一个小技巧，百分之百没问题。其思想是，如果你的一些数据点有标签，你可以使用它们来构建显著的表征。这和你使用了哪种架构无关——这个扩展每次都是一样的。你需要做的全部事情就是为其生成器添加另一个输入。图片来自：Mirza, 2014&nbsp;所以，现在又如何呢？现在假如你的模型可以生成各种各样的动物，但你其实喜欢猫。现在你不再为生成器传递生成的噪声然后期待有最好的结果，而是为第二个输入增加一些标签，比如「猫」类别的 ID 或词向量。在这种情况下，就说生成器是以预期输入的类别为条件的。诀窍和技巧在真正实践时，你在上面读到的描述可不够用。只是介绍该算法的概况的教程也不行——通常他们的方法仅在用于演示的小数据集上才有效。在这篇文章中，我们的目标是为你提供一整套能让你自己上手研究 GAN 的工具，让你能立马开始自己开发炫酷的东西。所以，你已经实现了你自己的 GAN 或从 GitHub 上克隆了一个（说实话，这是我力挺的开发方式）。在哪种随机梯度下降（SGD）的效果最好上，目前还不存在普遍共识，所以最好就选择你自己最喜欢的（我使用 Adam），并且在你实施长时间的训练之前要对学习率进行仔细的调节——这可以节省你大量时间。一般的工作流程很简单直接：1. 采样训练样本的一个 minibatch，然后计算它们的鉴别器分数；2. 得到一个生成样本 minibatch，然后计算它们的鉴别器分数；3. 使用这两个步骤累积的梯度执行一次更新。应该分开处理训练和生成的 minibatch，并且分别为不同的 batch 计算 batch norm，这是很关键，可以确保鉴别器有快速的初始训练。有时候，当生成器执行一步时，让鉴别器执行一步以上的效果更好。如果你的生成器在损失函数方面开始「获胜」了，不妨试试这么做。如果你在生成器中使用了 BatchNorm 层，这可能会导致 batch 之间出现很强的相关性，如下图所示：图片来自：Goodfellow, 2016基本而言，每一个 batch 都会得到同样的结果，其中只是稍微有些不同。你怎么防止这种情况发生？一种方法是预计算平均像素和标准差，然后每次都使用，但这常常会导致过拟合。作为替代，还有一种被称为虚拟批归一化（Virtual Batch Normalization）的妙招：在你开始训练之前预定义一个 batch（让我们称其为 R），对于每一个新 batch X，都使用 R 和 X 的级联来计算归一化参数。另一个有趣的技巧是从一个球体上采样输入噪声，而不是从一个立方体上。我们可以通过控制噪声向量的范数来近似地实现这一目标，但是从高维立方体上真正均匀地采样会更好一点。下一个诀窍是避免使用稀疏梯度，尤其是在生成器中。只需将特定的层换成它们对应的「平滑」的类似层就可以了，比如：1.ReLU 换成 LeakyReLU2. 最大池化换成平均池化、卷积+stride3.Unpooling 换成去卷积结论在这篇文章中，我们解释了生成对抗网络，并且给出了一些训练和实现的实用技巧。在下面的资源一节中，你可以找到一些 GAN 实现，能帮你上手你自己的实验。资源演讲1.Ian Goodfellow 在 NIPS 2016 的演讲《生成对抗网络》：参阅机器之心报道《独家 | GAN 之父 NIPS 2016 演讲现场直击：全方位解读生成对抗网络的原理及未来》2.Ian Goodfellow 演讲《对抗样本和对抗训练》：https://www.youtube.com/watch?v=CIfsB_EYsVI3.Soumith Chintala 在 NIPS 2016 的演讲《如何训练 GAN》：https://www.youtube.com/watch?v=X1mUN6dD8uE教程1. 来自 O'Reilly 的全面教程《生成对抗网络初学者》：https://www.oreilly.com/learning/generative-adversarial-networks-for-beginners2. 极简教程，有很多可以发挥的空间：https://github.com/uclaacmai/Generative-Adversarial-Network-Tutorial代码库1.TensorFlow 实现 DCGAN：https://github.com/carpedm20/DCGAN-tensorflow2.PyTorch 实现 DCGAN：https://github.com/pytorch/examples/tree/master/dcgan3. 使用条件 GAN 生成动画人物：https://github.com/m516825/Conditional-GAN论文1. 生成对抗网络（Generative Adversarial Networks）：https://arxiv.org/abs/1406.2661)2. 使用深度卷积生成对抗网络的无监督表征学习）Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks）：https://arxiv.org/abs/1511.064343. 条件生成对抗网络（Conditional Generative Adversarial Nets）：https://arxiv.org/abs/1411.1784​"
"入门;;生成对抗网络初学入门：一文读懂GAN的基本原理（附资源）生成对抗网络是现在人工智能领域的当红技术之一。近日，Sigmoidal.io 的博客发表了一篇入门级介绍文章，对 GAN 的原理进行了解释说明。另外，在该文章的最后还附带了一些能帮助初学者自己上手开发实验的资源（包含演讲、教程、代码和论文），其中部分资源机器之心也曾有过报道或解读，读者可访问对应链接查阅。你怎么教一台从未见过人脸的机器学会绘出人脸？计算机可以存储拍字节级的照片，但它却不知道怎样一堆像素组合才具有与人类外表相关的含义。多年以来，已经出现了很多各种各样旨在解决这一问题的生成模型。它们使用了各种不同的假设来建模数据的基本分布，有的假设太强，以至于根本不实用。对于我们目前的大多数任务来说，这些方法的结果仅仅是次优的。使用隐马尔可夫模型生成的文本显得很笨拙，而且可以预料；变分自编码器生成的图像很模糊，而且尽管这种方法的名字里面有「变」，但生成的图像却缺乏变化。所有这些缺陷都需要一种全新的方法来解决，而这样的方法最近已经诞生了。在这篇文章中，我们将对生成对抗网络（GAN）背后的一般思想进行全面的介绍，并向你展示一些主要的架构以帮你很好地开始学习，另外我们还将提供一些有用的技巧，可以帮你显著改善你的结果。GAN 的发明生成模型的基本思想是输入一个训练样本集合，然后形成这些样本的概率分布的表征。常用的生成模型方法是直接推断其概率密度函数。在我第一次学习生成模型时，我就禁不住想：既然我们已经有如此多的真实训练样本了，为什么还要麻烦地做这种事呢？答案很有说服力，这里给出了几个需要优秀生成模型的可能的应用：1. 模拟实验的可能结果，降低成本，加速研究2. 使用预测出的未来状态来规划行动——比如「知道」道路下一时刻状况的 GAN3. 生成缺失的数据和标签——我们常常缺乏格式正确的规整数据，而这会导致过拟合4. 高质量语音生成5. 自动提升照片的质量（图像超分辨率）2014 年，Ian Goodfellow 及其蒙特利尔大学的同事引入了生成对抗网络（GAN）。这是一种学习数据的基本分布的全新方法，让生成出的人工对象可以和真实对象之间达到惊人的相似度。GAN 背后的思想非常直观：生成器和鉴别器两个网络彼此博弈。生成器的目标是生成一个对象（比如人的照片），并使其看起来和真的一样。而鉴别器的目标就是找到生成出的结果和真实图像之间的差异。这张图给出了生成对抗网络的一个大致概览。目前最重要的是要理解 GAN 差不多就是把两个网络放到一起工作的方法——生成器和鉴别器都有它们自己的架构。要更好地理解这种思想的根源，我们需要回忆一些基本的代数知识并且问我们自己一个问题：如果一个网络分类图像的能力比大多数人还好，那么我们该怎么欺骗它？对抗样本在我们详细描述 GAN 之前，我们先看看一个有些近似的主题。给定一个训练后的分类器，我们能生成一个能骗过该网络的样本吗？如果我们可以，那看起来又会如何？事实证明，我们可以。不仅如此，对于几乎任何给定的图像分类器，都可以通过图像变形的方式，在新图像看起来和原图像基本毫无差别的情况下，让网络得到有很高置信度的错误分类结果！这个过程被称为对抗攻击（adversarial attack），而这种生成方式的简单性能够给 GAN 提供很多解释。对抗样本（adversarial example）是指经过精心计算得到的旨在误导分类器的样本。下图是这一过程的一个示例。左边的熊猫所属的分类就和右边的不一样——右边的图被分类为了长臂猿。图片来自：Goodfellow, 2017图像分类器本质上是高维空间中的一个复杂的决策边界。当然，在涉及到图像分类时，我们没法画出这样的边界线。但我们可以肯定地假设，当训练完成后，得到的网络无法泛化到所有的图像上——只能用于那些在训练集中的图像。这样的泛化很可能不能很好地近似真实情况。换句话说，它与我们的数据过拟合了——而我们可以利用这一点。让我们首先向图像加入一些随机噪声，并且确保噪声非常接近于 0。我们可以通过控制噪声的 L2 范数来实现这一点。你不用担心 L2 范数这个数学概念，对于大多数实际应用而言，你可以将其看作是一个向量的长度。这里的诀窍是你的图像中的像素越多，其平均 L2 范数就越大。所以，如果你的噪声的范数足够低，你就可以认为它在视觉上是不可感知的；但是在向量空间中，加入噪声的图像可以与原始图像相距非常远。为什么会这样呢？如果 H×W 的图像是一个向量，那么我们加入其中的 H×W 噪声也是一个向量。原始图像有各种各样相当密集的颜色——这会增加 L2 范数。另一方面，噪声则从视觉上看起来是一张混乱的而且相当苍白的图像——一个小范数的向量。最后我们将它们加到一起，得到的受损图像看起来和原图像很接近，但却会被错误地分类！现在，如果原始类别「狗」的决策边界没有那么远（在 L2 范数角度来看），那么增加的这点噪声会将新的图像带到决策边界之外。你不需要成为世界级的拓扑学家，也能理解特定类别的流形或决策边界。因为每张图像只是高维空间中的一个向量，在它们之上训练的分类器就是将「所有猴子」定义为「这个用隐含参数描述的高维 blob（二进制大对象）中的所有向量」。我们将这个 blob 称为该类别的决策边界。好了，也就是说我们可以通过添加随机噪声来轻松欺骗网络。那生成新图像还必须做什么？生成器和鉴别器现在我们已经简单了解了对抗样本，我们离 GAN 只有一步之遥了！那么，如果我们前面部分描述的分类器网络是为二分类（真和加）设计的呢？根据 Goodfellow 等人那篇原始论文的说法，我们称之为鉴别器（Discriminator）。现在让我们增加一个网络，让其可以生成会让鉴别器错误分类为「真」的图像。这个过程和我们在对抗样本部分使用的过程完全一样。这个网络称为生成器（Generator）。对抗训练这个过程为其赋予了一些迷人的特性。在训练的每一步，鉴别器都要区分训练集和一些假样本的图像，这样它区分真假的能力就越来越强。在统计学习理论中，这本质上就意味着学习到了数据的底层分布。那当鉴别器非常擅长识别真假时，欺骗它能有什么好处呢？没错！能用来学习以假乱真的赝品！图片来自：Goodfellow, 2016有一个古老但睿智的数学结果最小最大定理（Minimax theorem）开启了我们所知的博弈论的先河，其表明：对于零和博弈中的两个玩家而言，最小最大解决方案与纳什均衡是一样的。哇！这都说的啥！简单来说，当两个玩家（D 和 G）彼此竞争时（零和博弈），双方都假设对方采取最优的步骤而自己也以最优的策略应对（最小最大策略），那么结果就已经预先确定了，玩家无法改变它（纳什均衡）。图片来自：Goodfellow, 2017所以，对于我们的网络而言，这意味着如果我们训练它们足够长时间，那么生成器将会学会如何从真实「分布」中采样，这意味着它开始可以生成接近真实的图像，同时鉴别器将无法将其与真实图像区分开。上手学习的最佳架构理论归理论，当涉及到实践时，尤其是在机器学习领域，很多东西就是没法起效。幸运的是，我们收集了一些有用的小点子，可以帮助得到更好的结果。在这篇文章中，我们将首先回顾一些经典的架构，并提供一些相关链接。深度卷积生成对抗网络（DCGAN）在 GAN 的第一篇论文出来之后的大概一年时间里，训练 GAN 与其说是科学，倒不如说是艺术——模型很不稳定，需要大量调整才能工作。2015 年时，Radford 等人发表了题为《使用深度卷积生成对抗网络的无监督表征学习（Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks）》的论文，描述了之后被称为 DCGAN 的著名模型。图片来自：Radford et al., 2015关于 DCGAN，最值得一提的是这个架构在大多数情况下都是稳定的。这是第一篇使用向量运算描述生成器学习到的表征的固有性质的论文：这与 Word2Vec 中的词向量使用的技巧一样，但却是对图像操作的！图片来自：Radford et al., 2015DCGAN 是最简单的稳定可靠的模型，我们推荐从它开始上手。后面我们给出了一些训练和实现的有用技巧，并提供了代码示例的链接。条件 GAN（Conditional GAN）这是研究者提出的一种 GAN 的元架构的扩展，以便提升生成图像的质量，你也可以把它称为一个小技巧，百分之百没问题。其思想是，如果你的一些数据点有标签，你可以使用它们来构建显著的表征。这和你使用了哪种架构无关——这个扩展每次都是一样的。你需要做的全部事情就是为其生成器添加另一个输入。图片来自：Mirza, 2014&nbsp;所以，现在又如何呢？现在假如你的模型可以生成各种各样的动物，但你其实喜欢猫。现在你不再为生成器传递生成的噪声然后期待有最好的结果，而是为第二个输入增加一些标签，比如「猫」类别的 ID 或词向量。在这种情况下，就说生成器是以预期输入的类别为条件的。诀窍和技巧在真正实践时，你在上面读到的描述可不够用。只是介绍该算法的概况的教程也不行——通常他们的方法仅在用于演示的小数据集上才有效。在这篇文章中，我们的目标是为你提供一整套能让你自己上手研究 GAN 的工具，让你能立马开始自己开发炫酷的东西。所以，你已经实现了你自己的 GAN 或从 GitHub 上克隆了一个（说实话，这是我力挺的开发方式）。在哪种随机梯度下降（SGD）的效果最好上，目前还不存在普遍共识，所以最好就选择你自己最喜欢的（我使用 Adam），并且在你实施长时间的训练之前要对学习率进行仔细的调节——这可以节省你大量时间。一般的工作流程很简单直接：1. 采样训练样本的一个 minibatch，然后计算它们的鉴别器分数；2. 得到一个生成样本 minibatch，然后计算它们的鉴别器分数；3. 使用这两个步骤累积的梯度执行一次更新。应该分开处理训练和生成的 minibatch，并且分别为不同的 batch 计算 batch norm，这是很关键，可以确保鉴别器有快速的初始训练。有时候，当生成器执行一步时，让鉴别器执行一步以上的效果更好。如果你的生成器在损失函数方面开始「获胜」了，不妨试试这么做。如果你在生成器中使用了 BatchNorm 层，这可能会导致 batch 之间出现很强的相关性，如下图所示：图片来自：Goodfellow, 2016基本而言，每一个 batch 都会得到同样的结果，其中只是稍微有些不同。你怎么防止这种情况发生？一种方法是预计算平均像素和标准差，然后每次都使用，但这常常会导致过拟合。作为替代，还有一种被称为虚拟批归一化（Virtual Batch Normalization）的妙招：在你开始训练之前预定义一个 batch（让我们称其为 R），对于每一个新 batch X，都使用 R 和 X 的级联来计算归一化参数。另一个有趣的技巧是从一个球体上采样输入噪声，而不是从一个立方体上。我们可以通过控制噪声向量的范数来近似地实现这一目标，但是从高维立方体上真正均匀地采样会更好一点。下一个诀窍是避免使用稀疏梯度，尤其是在生成器中。只需将特定的层换成它们对应的「平滑」的类似层就可以了，比如：1.ReLU 换成 LeakyReLU2. 最大池化换成平均池化、卷积+stride3.Unpooling 换成去卷积结论在这篇文章中，我们解释了生成对抗网络，并且给出了一些训练和实现的实用技巧。在下面的资源一节中，你可以找到一些 GAN 实现，能帮你上手你自己的实验。资源演讲1.Ian Goodfellow 在 NIPS 2016 的演讲《生成对抗网络》：参阅机器之心报道《独家 | GAN 之父 NIPS 2016 演讲现场直击：全方位解读生成对抗网络的原理及未来》2.Ian Goodfellow 演讲《对抗样本和对抗训练》：https://www.youtube.com/watch?v=CIfsB_EYsVI3.Soumith Chintala 在 NIPS 2016 的演讲《如何训练 GAN》：https://www.youtube.com/watch?v=X1mUN6dD8uE教程1. 来自 O'Reilly 的全面教程《生成对抗网络初学者》：https://www.oreilly.com/learning/generative-adversarial-networks-for-beginners2. 极简教程，有很多可以发挥的空间：https://github.com/uclaacmai/Generative-Adversarial-Network-Tutorial代码库1.TensorFlow 实现 DCGAN：https://github.com/carpedm20/DCGAN-tensorflow2.PyTorch 实现 DCGAN：https://github.com/pytorch/examples/tree/master/dcgan3. 使用条件 GAN 生成动画人物：https://github.com/m516825/Conditional-GAN论文1. 生成对抗网络（Generative Adversarial Networks）：https://arxiv.org/abs/1406.2661)2. 使用深度卷积生成对抗网络的无监督表征学习）Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks）：https://arxiv.org/abs/1511.064343. 条件生成对抗网络（Conditional Generative Adversarial Nets）：https://arxiv.org/abs/1411.1784​"
"对抗样本;;生成对抗网络初学入门：一文读懂GAN的基本原理（附资源）生成对抗网络是现在人工智能领域的当红技术之一。近日，Sigmoidal.io 的博客发表了一篇入门级介绍文章，对 GAN 的原理进行了解释说明。另外，在该文章的最后还附带了一些能帮助初学者自己上手开发实验的资源（包含演讲、教程、代码和论文），其中部分资源机器之心也曾有过报道或解读，读者可访问对应链接查阅。你怎么教一台从未见过人脸的机器学会绘出人脸？计算机可以存储拍字节级的照片，但它却不知道怎样一堆像素组合才具有与人类外表相关的含义。多年以来，已经出现了很多各种各样旨在解决这一问题的生成模型。它们使用了各种不同的假设来建模数据的基本分布，有的假设太强，以至于根本不实用。对于我们目前的大多数任务来说，这些方法的结果仅仅是次优的。使用隐马尔可夫模型生成的文本显得很笨拙，而且可以预料；变分自编码器生成的图像很模糊，而且尽管这种方法的名字里面有「变」，但生成的图像却缺乏变化。所有这些缺陷都需要一种全新的方法来解决，而这样的方法最近已经诞生了。在这篇文章中，我们将对生成对抗网络（GAN）背后的一般思想进行全面的介绍，并向你展示一些主要的架构以帮你很好地开始学习，另外我们还将提供一些有用的技巧，可以帮你显著改善你的结果。GAN 的发明生成模型的基本思想是输入一个训练样本集合，然后形成这些样本的概率分布的表征。常用的生成模型方法是直接推断其概率密度函数。在我第一次学习生成模型时，我就禁不住想：既然我们已经有如此多的真实训练样本了，为什么还要麻烦地做这种事呢？答案很有说服力，这里给出了几个需要优秀生成模型的可能的应用：1. 模拟实验的可能结果，降低成本，加速研究2. 使用预测出的未来状态来规划行动——比如「知道」道路下一时刻状况的 GAN3. 生成缺失的数据和标签——我们常常缺乏格式正确的规整数据，而这会导致过拟合4. 高质量语音生成5. 自动提升照片的质量（图像超分辨率）2014 年，Ian Goodfellow 及其蒙特利尔大学的同事引入了生成对抗网络（GAN）。这是一种学习数据的基本分布的全新方法，让生成出的人工对象可以和真实对象之间达到惊人的相似度。GAN 背后的思想非常直观：生成器和鉴别器两个网络彼此博弈。生成器的目标是生成一个对象（比如人的照片），并使其看起来和真的一样。而鉴别器的目标就是找到生成出的结果和真实图像之间的差异。这张图给出了生成对抗网络的一个大致概览。目前最重要的是要理解 GAN 差不多就是把两个网络放到一起工作的方法——生成器和鉴别器都有它们自己的架构。要更好地理解这种思想的根源，我们需要回忆一些基本的代数知识并且问我们自己一个问题：如果一个网络分类图像的能力比大多数人还好，那么我们该怎么欺骗它？对抗样本在我们详细描述 GAN 之前，我们先看看一个有些近似的主题。给定一个训练后的分类器，我们能生成一个能骗过该网络的样本吗？如果我们可以，那看起来又会如何？事实证明，我们可以。不仅如此，对于几乎任何给定的图像分类器，都可以通过图像变形的方式，在新图像看起来和原图像基本毫无差别的情况下，让网络得到有很高置信度的错误分类结果！这个过程被称为对抗攻击（adversarial attack），而这种生成方式的简单性能够给 GAN 提供很多解释。对抗样本（adversarial example）是指经过精心计算得到的旨在误导分类器的样本。下图是这一过程的一个示例。左边的熊猫所属的分类就和右边的不一样——右边的图被分类为了长臂猿。图片来自：Goodfellow, 2017图像分类器本质上是高维空间中的一个复杂的决策边界。当然，在涉及到图像分类时，我们没法画出这样的边界线。但我们可以肯定地假设，当训练完成后，得到的网络无法泛化到所有的图像上——只能用于那些在训练集中的图像。这样的泛化很可能不能很好地近似真实情况。换句话说，它与我们的数据过拟合了——而我们可以利用这一点。让我们首先向图像加入一些随机噪声，并且确保噪声非常接近于 0。我们可以通过控制噪声的 L2 范数来实现这一点。你不用担心 L2 范数这个数学概念，对于大多数实际应用而言，你可以将其看作是一个向量的长度。这里的诀窍是你的图像中的像素越多，其平均 L2 范数就越大。所以，如果你的噪声的范数足够低，你就可以认为它在视觉上是不可感知的；但是在向量空间中，加入噪声的图像可以与原始图像相距非常远。为什么会这样呢？如果 H×W 的图像是一个向量，那么我们加入其中的 H×W 噪声也是一个向量。原始图像有各种各样相当密集的颜色——这会增加 L2 范数。另一方面，噪声则从视觉上看起来是一张混乱的而且相当苍白的图像——一个小范数的向量。最后我们将它们加到一起，得到的受损图像看起来和原图像很接近，但却会被错误地分类！现在，如果原始类别「狗」的决策边界没有那么远（在 L2 范数角度来看），那么增加的这点噪声会将新的图像带到决策边界之外。你不需要成为世界级的拓扑学家，也能理解特定类别的流形或决策边界。因为每张图像只是高维空间中的一个向量，在它们之上训练的分类器就是将「所有猴子」定义为「这个用隐含参数描述的高维 blob（二进制大对象）中的所有向量」。我们将这个 blob 称为该类别的决策边界。好了，也就是说我们可以通过添加随机噪声来轻松欺骗网络。那生成新图像还必须做什么？生成器和鉴别器现在我们已经简单了解了对抗样本，我们离 GAN 只有一步之遥了！那么，如果我们前面部分描述的分类器网络是为二分类（真和加）设计的呢？根据 Goodfellow 等人那篇原始论文的说法，我们称之为鉴别器（Discriminator）。现在让我们增加一个网络，让其可以生成会让鉴别器错误分类为「真」的图像。这个过程和我们在对抗样本部分使用的过程完全一样。这个网络称为生成器（Generator）。对抗训练这个过程为其赋予了一些迷人的特性。在训练的每一步，鉴别器都要区分训练集和一些假样本的图像，这样它区分真假的能力就越来越强。在统计学习理论中，这本质上就意味着学习到了数据的底层分布。那当鉴别器非常擅长识别真假时，欺骗它能有什么好处呢？没错！能用来学习以假乱真的赝品！图片来自：Goodfellow, 2016有一个古老但睿智的数学结果最小最大定理（Minimax theorem）开启了我们所知的博弈论的先河，其表明：对于零和博弈中的两个玩家而言，最小最大解决方案与纳什均衡是一样的。哇！这都说的啥！简单来说，当两个玩家（D 和 G）彼此竞争时（零和博弈），双方都假设对方采取最优的步骤而自己也以最优的策略应对（最小最大策略），那么结果就已经预先确定了，玩家无法改变它（纳什均衡）。图片来自：Goodfellow, 2017所以，对于我们的网络而言，这意味着如果我们训练它们足够长时间，那么生成器将会学会如何从真实「分布」中采样，这意味着它开始可以生成接近真实的图像，同时鉴别器将无法将其与真实图像区分开。上手学习的最佳架构理论归理论，当涉及到实践时，尤其是在机器学习领域，很多东西就是没法起效。幸运的是，我们收集了一些有用的小点子，可以帮助得到更好的结果。在这篇文章中，我们将首先回顾一些经典的架构，并提供一些相关链接。深度卷积生成对抗网络（DCGAN）在 GAN 的第一篇论文出来之后的大概一年时间里，训练 GAN 与其说是科学，倒不如说是艺术——模型很不稳定，需要大量调整才能工作。2015 年时，Radford 等人发表了题为《使用深度卷积生成对抗网络的无监督表征学习（Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks）》的论文，描述了之后被称为 DCGAN 的著名模型。图片来自：Radford et al., 2015关于 DCGAN，最值得一提的是这个架构在大多数情况下都是稳定的。这是第一篇使用向量运算描述生成器学习到的表征的固有性质的论文：这与 Word2Vec 中的词向量使用的技巧一样，但却是对图像操作的！图片来自：Radford et al., 2015DCGAN 是最简单的稳定可靠的模型，我们推荐从它开始上手。后面我们给出了一些训练和实现的有用技巧，并提供了代码示例的链接。条件 GAN（Conditional GAN）这是研究者提出的一种 GAN 的元架构的扩展，以便提升生成图像的质量，你也可以把它称为一个小技巧，百分之百没问题。其思想是，如果你的一些数据点有标签，你可以使用它们来构建显著的表征。这和你使用了哪种架构无关——这个扩展每次都是一样的。你需要做的全部事情就是为其生成器添加另一个输入。图片来自：Mirza, 2014&nbsp;所以，现在又如何呢？现在假如你的模型可以生成各种各样的动物，但你其实喜欢猫。现在你不再为生成器传递生成的噪声然后期待有最好的结果，而是为第二个输入增加一些标签，比如「猫」类别的 ID 或词向量。在这种情况下，就说生成器是以预期输入的类别为条件的。诀窍和技巧在真正实践时，你在上面读到的描述可不够用。只是介绍该算法的概况的教程也不行——通常他们的方法仅在用于演示的小数据集上才有效。在这篇文章中，我们的目标是为你提供一整套能让你自己上手研究 GAN 的工具，让你能立马开始自己开发炫酷的东西。所以，你已经实现了你自己的 GAN 或从 GitHub 上克隆了一个（说实话，这是我力挺的开发方式）。在哪种随机梯度下降（SGD）的效果最好上，目前还不存在普遍共识，所以最好就选择你自己最喜欢的（我使用 Adam），并且在你实施长时间的训练之前要对学习率进行仔细的调节——这可以节省你大量时间。一般的工作流程很简单直接：1. 采样训练样本的一个 minibatch，然后计算它们的鉴别器分数；2. 得到一个生成样本 minibatch，然后计算它们的鉴别器分数；3. 使用这两个步骤累积的梯度执行一次更新。应该分开处理训练和生成的 minibatch，并且分别为不同的 batch 计算 batch norm，这是很关键，可以确保鉴别器有快速的初始训练。有时候，当生成器执行一步时，让鉴别器执行一步以上的效果更好。如果你的生成器在损失函数方面开始「获胜」了，不妨试试这么做。如果你在生成器中使用了 BatchNorm 层，这可能会导致 batch 之间出现很强的相关性，如下图所示：图片来自：Goodfellow, 2016基本而言，每一个 batch 都会得到同样的结果，其中只是稍微有些不同。你怎么防止这种情况发生？一种方法是预计算平均像素和标准差，然后每次都使用，但这常常会导致过拟合。作为替代，还有一种被称为虚拟批归一化（Virtual Batch Normalization）的妙招：在你开始训练之前预定义一个 batch（让我们称其为 R），对于每一个新 batch X，都使用 R 和 X 的级联来计算归一化参数。另一个有趣的技巧是从一个球体上采样输入噪声，而不是从一个立方体上。我们可以通过控制噪声向量的范数来近似地实现这一目标，但是从高维立方体上真正均匀地采样会更好一点。下一个诀窍是避免使用稀疏梯度，尤其是在生成器中。只需将特定的层换成它们对应的「平滑」的类似层就可以了，比如：1.ReLU 换成 LeakyReLU2. 最大池化换成平均池化、卷积+stride3.Unpooling 换成去卷积结论在这篇文章中，我们解释了生成对抗网络，并且给出了一些训练和实现的实用技巧。在下面的资源一节中，你可以找到一些 GAN 实现，能帮你上手你自己的实验。资源演讲1.Ian Goodfellow 在 NIPS 2016 的演讲《生成对抗网络》：参阅机器之心报道《独家 | GAN 之父 NIPS 2016 演讲现场直击：全方位解读生成对抗网络的原理及未来》2.Ian Goodfellow 演讲《对抗样本和对抗训练》：https://www.youtube.com/watch?v=CIfsB_EYsVI3.Soumith Chintala 在 NIPS 2016 的演讲《如何训练 GAN》：https://www.youtube.com/watch?v=X1mUN6dD8uE教程1. 来自 O'Reilly 的全面教程《生成对抗网络初学者》：https://www.oreilly.com/learning/generative-adversarial-networks-for-beginners2. 极简教程，有很多可以发挥的空间：https://github.com/uclaacmai/Generative-Adversarial-Network-Tutorial代码库1.TensorFlow 实现 DCGAN：https://github.com/carpedm20/DCGAN-tensorflow2.PyTorch 实现 DCGAN：https://github.com/pytorch/examples/tree/master/dcgan3. 使用条件 GAN 生成动画人物：https://github.com/m516825/Conditional-GAN论文1. 生成对抗网络（Generative Adversarial Networks）：https://arxiv.org/abs/1406.2661)2. 使用深度卷积生成对抗网络的无监督表征学习）Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks）：https://arxiv.org/abs/1511.064343. 条件生成对抗网络（Conditional Generative Adversarial Nets）：https://arxiv.org/abs/1411.1784​"
"计算机视觉;;生成对抗网络初学入门：一文读懂GAN的基本原理（附资源）生成对抗网络是现在人工智能领域的当红技术之一。近日，Sigmoidal.io 的博客发表了一篇入门级介绍文章，对 GAN 的原理进行了解释说明。另外，在该文章的最后还附带了一些能帮助初学者自己上手开发实验的资源（包含演讲、教程、代码和论文），其中部分资源机器之心也曾有过报道或解读，读者可访问对应链接查阅。你怎么教一台从未见过人脸的机器学会绘出人脸？计算机可以存储拍字节级的照片，但它却不知道怎样一堆像素组合才具有与人类外表相关的含义。多年以来，已经出现了很多各种各样旨在解决这一问题的生成模型。它们使用了各种不同的假设来建模数据的基本分布，有的假设太强，以至于根本不实用。对于我们目前的大多数任务来说，这些方法的结果仅仅是次优的。使用隐马尔可夫模型生成的文本显得很笨拙，而且可以预料；变分自编码器生成的图像很模糊，而且尽管这种方法的名字里面有「变」，但生成的图像却缺乏变化。所有这些缺陷都需要一种全新的方法来解决，而这样的方法最近已经诞生了。在这篇文章中，我们将对生成对抗网络（GAN）背后的一般思想进行全面的介绍，并向你展示一些主要的架构以帮你很好地开始学习，另外我们还将提供一些有用的技巧，可以帮你显著改善你的结果。GAN 的发明生成模型的基本思想是输入一个训练样本集合，然后形成这些样本的概率分布的表征。常用的生成模型方法是直接推断其概率密度函数。在我第一次学习生成模型时，我就禁不住想：既然我们已经有如此多的真实训练样本了，为什么还要麻烦地做这种事呢？答案很有说服力，这里给出了几个需要优秀生成模型的可能的应用：1. 模拟实验的可能结果，降低成本，加速研究2. 使用预测出的未来状态来规划行动——比如「知道」道路下一时刻状况的 GAN3. 生成缺失的数据和标签——我们常常缺乏格式正确的规整数据，而这会导致过拟合4. 高质量语音生成5. 自动提升照片的质量（图像超分辨率）2014 年，Ian Goodfellow 及其蒙特利尔大学的同事引入了生成对抗网络（GAN）。这是一种学习数据的基本分布的全新方法，让生成出的人工对象可以和真实对象之间达到惊人的相似度。GAN 背后的思想非常直观：生成器和鉴别器两个网络彼此博弈。生成器的目标是生成一个对象（比如人的照片），并使其看起来和真的一样。而鉴别器的目标就是找到生成出的结果和真实图像之间的差异。这张图给出了生成对抗网络的一个大致概览。目前最重要的是要理解 GAN 差不多就是把两个网络放到一起工作的方法——生成器和鉴别器都有它们自己的架构。要更好地理解这种思想的根源，我们需要回忆一些基本的代数知识并且问我们自己一个问题：如果一个网络分类图像的能力比大多数人还好，那么我们该怎么欺骗它？对抗样本在我们详细描述 GAN 之前，我们先看看一个有些近似的主题。给定一个训练后的分类器，我们能生成一个能骗过该网络的样本吗？如果我们可以，那看起来又会如何？事实证明，我们可以。不仅如此，对于几乎任何给定的图像分类器，都可以通过图像变形的方式，在新图像看起来和原图像基本毫无差别的情况下，让网络得到有很高置信度的错误分类结果！这个过程被称为对抗攻击（adversarial attack），而这种生成方式的简单性能够给 GAN 提供很多解释。对抗样本（adversarial example）是指经过精心计算得到的旨在误导分类器的样本。下图是这一过程的一个示例。左边的熊猫所属的分类就和右边的不一样——右边的图被分类为了长臂猿。图片来自：Goodfellow, 2017图像分类器本质上是高维空间中的一个复杂的决策边界。当然，在涉及到图像分类时，我们没法画出这样的边界线。但我们可以肯定地假设，当训练完成后，得到的网络无法泛化到所有的图像上——只能用于那些在训练集中的图像。这样的泛化很可能不能很好地近似真实情况。换句话说，它与我们的数据过拟合了——而我们可以利用这一点。让我们首先向图像加入一些随机噪声，并且确保噪声非常接近于 0。我们可以通过控制噪声的 L2 范数来实现这一点。你不用担心 L2 范数这个数学概念，对于大多数实际应用而言，你可以将其看作是一个向量的长度。这里的诀窍是你的图像中的像素越多，其平均 L2 范数就越大。所以，如果你的噪声的范数足够低，你就可以认为它在视觉上是不可感知的；但是在向量空间中，加入噪声的图像可以与原始图像相距非常远。为什么会这样呢？如果 H×W 的图像是一个向量，那么我们加入其中的 H×W 噪声也是一个向量。原始图像有各种各样相当密集的颜色——这会增加 L2 范数。另一方面，噪声则从视觉上看起来是一张混乱的而且相当苍白的图像——一个小范数的向量。最后我们将它们加到一起，得到的受损图像看起来和原图像很接近，但却会被错误地分类！现在，如果原始类别「狗」的决策边界没有那么远（在 L2 范数角度来看），那么增加的这点噪声会将新的图像带到决策边界之外。你不需要成为世界级的拓扑学家，也能理解特定类别的流形或决策边界。因为每张图像只是高维空间中的一个向量，在它们之上训练的分类器就是将「所有猴子」定义为「这个用隐含参数描述的高维 blob（二进制大对象）中的所有向量」。我们将这个 blob 称为该类别的决策边界。好了，也就是说我们可以通过添加随机噪声来轻松欺骗网络。那生成新图像还必须做什么？生成器和鉴别器现在我们已经简单了解了对抗样本，我们离 GAN 只有一步之遥了！那么，如果我们前面部分描述的分类器网络是为二分类（真和加）设计的呢？根据 Goodfellow 等人那篇原始论文的说法，我们称之为鉴别器（Discriminator）。现在让我们增加一个网络，让其可以生成会让鉴别器错误分类为「真」的图像。这个过程和我们在对抗样本部分使用的过程完全一样。这个网络称为生成器（Generator）。对抗训练这个过程为其赋予了一些迷人的特性。在训练的每一步，鉴别器都要区分训练集和一些假样本的图像，这样它区分真假的能力就越来越强。在统计学习理论中，这本质上就意味着学习到了数据的底层分布。那当鉴别器非常擅长识别真假时，欺骗它能有什么好处呢？没错！能用来学习以假乱真的赝品！图片来自：Goodfellow, 2016有一个古老但睿智的数学结果最小最大定理（Minimax theorem）开启了我们所知的博弈论的先河，其表明：对于零和博弈中的两个玩家而言，最小最大解决方案与纳什均衡是一样的。哇！这都说的啥！简单来说，当两个玩家（D 和 G）彼此竞争时（零和博弈），双方都假设对方采取最优的步骤而自己也以最优的策略应对（最小最大策略），那么结果就已经预先确定了，玩家无法改变它（纳什均衡）。图片来自：Goodfellow, 2017所以，对于我们的网络而言，这意味着如果我们训练它们足够长时间，那么生成器将会学会如何从真实「分布」中采样，这意味着它开始可以生成接近真实的图像，同时鉴别器将无法将其与真实图像区分开。上手学习的最佳架构理论归理论，当涉及到实践时，尤其是在机器学习领域，很多东西就是没法起效。幸运的是，我们收集了一些有用的小点子，可以帮助得到更好的结果。在这篇文章中，我们将首先回顾一些经典的架构，并提供一些相关链接。深度卷积生成对抗网络（DCGAN）在 GAN 的第一篇论文出来之后的大概一年时间里，训练 GAN 与其说是科学，倒不如说是艺术——模型很不稳定，需要大量调整才能工作。2015 年时，Radford 等人发表了题为《使用深度卷积生成对抗网络的无监督表征学习（Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks）》的论文，描述了之后被称为 DCGAN 的著名模型。图片来自：Radford et al., 2015关于 DCGAN，最值得一提的是这个架构在大多数情况下都是稳定的。这是第一篇使用向量运算描述生成器学习到的表征的固有性质的论文：这与 Word2Vec 中的词向量使用的技巧一样，但却是对图像操作的！图片来自：Radford et al., 2015DCGAN 是最简单的稳定可靠的模型，我们推荐从它开始上手。后面我们给出了一些训练和实现的有用技巧，并提供了代码示例的链接。条件 GAN（Conditional GAN）这是研究者提出的一种 GAN 的元架构的扩展，以便提升生成图像的质量，你也可以把它称为一个小技巧，百分之百没问题。其思想是，如果你的一些数据点有标签，你可以使用它们来构建显著的表征。这和你使用了哪种架构无关——这个扩展每次都是一样的。你需要做的全部事情就是为其生成器添加另一个输入。图片来自：Mirza, 2014&nbsp;所以，现在又如何呢？现在假如你的模型可以生成各种各样的动物，但你其实喜欢猫。现在你不再为生成器传递生成的噪声然后期待有最好的结果，而是为第二个输入增加一些标签，比如「猫」类别的 ID 或词向量。在这种情况下，就说生成器是以预期输入的类别为条件的。诀窍和技巧在真正实践时，你在上面读到的描述可不够用。只是介绍该算法的概况的教程也不行——通常他们的方法仅在用于演示的小数据集上才有效。在这篇文章中，我们的目标是为你提供一整套能让你自己上手研究 GAN 的工具，让你能立马开始自己开发炫酷的东西。所以，你已经实现了你自己的 GAN 或从 GitHub 上克隆了一个（说实话，这是我力挺的开发方式）。在哪种随机梯度下降（SGD）的效果最好上，目前还不存在普遍共识，所以最好就选择你自己最喜欢的（我使用 Adam），并且在你实施长时间的训练之前要对学习率进行仔细的调节——这可以节省你大量时间。一般的工作流程很简单直接：1. 采样训练样本的一个 minibatch，然后计算它们的鉴别器分数；2. 得到一个生成样本 minibatch，然后计算它们的鉴别器分数；3. 使用这两个步骤累积的梯度执行一次更新。应该分开处理训练和生成的 minibatch，并且分别为不同的 batch 计算 batch norm，这是很关键，可以确保鉴别器有快速的初始训练。有时候，当生成器执行一步时，让鉴别器执行一步以上的效果更好。如果你的生成器在损失函数方面开始「获胜」了，不妨试试这么做。如果你在生成器中使用了 BatchNorm 层，这可能会导致 batch 之间出现很强的相关性，如下图所示：图片来自：Goodfellow, 2016基本而言，每一个 batch 都会得到同样的结果，其中只是稍微有些不同。你怎么防止这种情况发生？一种方法是预计算平均像素和标准差，然后每次都使用，但这常常会导致过拟合。作为替代，还有一种被称为虚拟批归一化（Virtual Batch Normalization）的妙招：在你开始训练之前预定义一个 batch（让我们称其为 R），对于每一个新 batch X，都使用 R 和 X 的级联来计算归一化参数。另一个有趣的技巧是从一个球体上采样输入噪声，而不是从一个立方体上。我们可以通过控制噪声向量的范数来近似地实现这一目标，但是从高维立方体上真正均匀地采样会更好一点。下一个诀窍是避免使用稀疏梯度，尤其是在生成器中。只需将特定的层换成它们对应的「平滑」的类似层就可以了，比如：1.ReLU 换成 LeakyReLU2. 最大池化换成平均池化、卷积+stride3.Unpooling 换成去卷积结论在这篇文章中，我们解释了生成对抗网络，并且给出了一些训练和实现的实用技巧。在下面的资源一节中，你可以找到一些 GAN 实现，能帮你上手你自己的实验。资源演讲1.Ian Goodfellow 在 NIPS 2016 的演讲《生成对抗网络》：参阅机器之心报道《独家 | GAN 之父 NIPS 2016 演讲现场直击：全方位解读生成对抗网络的原理及未来》2.Ian Goodfellow 演讲《对抗样本和对抗训练》：https://www.youtube.com/watch?v=CIfsB_EYsVI3.Soumith Chintala 在 NIPS 2016 的演讲《如何训练 GAN》：https://www.youtube.com/watch?v=X1mUN6dD8uE教程1. 来自 O'Reilly 的全面教程《生成对抗网络初学者》：https://www.oreilly.com/learning/generative-adversarial-networks-for-beginners2. 极简教程，有很多可以发挥的空间：https://github.com/uclaacmai/Generative-Adversarial-Network-Tutorial代码库1.TensorFlow 实现 DCGAN：https://github.com/carpedm20/DCGAN-tensorflow2.PyTorch 实现 DCGAN：https://github.com/pytorch/examples/tree/master/dcgan3. 使用条件 GAN 生成动画人物：https://github.com/m516825/Conditional-GAN论文1. 生成对抗网络（Generative Adversarial Networks）：https://arxiv.org/abs/1406.2661)2. 使用深度卷积生成对抗网络的无监督表征学习）Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks）：https://arxiv.org/abs/1511.064343. 条件生成对抗网络（Conditional Generative Adversarial Nets）：https://arxiv.org/abs/1411.1784​"
人工智能应用;;人工智能在铁路行业的应用本文作者Bhoopathi Rapolu是Cyient EMEA 的分析主管。在这个角色中，他负责客户参与、解决方案的开发和商业开发。他拥有超过15年的商业智能和技术管理经验，并在过去几年中一直在宣扬实时技术与IT技术的融合。他利用搭载远程信息处理和先进的分析（主要用于航空航天，交通运输，机械设备，公用事业和电信），概念化并研发了智能资产管理解决方案。他还建造并运行大型BI系统，并为高级的功能和运营分析平台提供企业级解决方案。在铁路工业，任何有助于使列车保持移动，避免操作延迟，增进用户体验的事，都是值得追求的。很多OEM厂商正在把大量资源财富投入到企业中最有价值和潜在回报的事物之一：大数据。在铁路系统，特别是涉及到车辆维修，大数据等同于基于状态的维护(CBM)和预测性维护(PM)。由于制造业和资产维护行业的规模迅速扩大，他们现在正适应于把高级算法更广泛地应用于消费者产生的大数据。虽然CBM和PM都普遍采用铁路行业惯例，CBM的范围远比PM宽。CBM通常涉及直接应用的实时诊断监控，明白显示资产和子系统，使得在了解了情况之后我们有足够的时间反应。这也使得大多数的诊断检测方案，例如检测车轮，车轴，高层次的网络问题等，清晰明了。但是CBM不能指出哪些系统不能给出足够时间采取行动，或者直接影响客户体验。例如，如果你用诊断检测系统来确定一个门的故障，几乎无法在不延迟和影响客户舒适度的情况下来修正。理想状况下，OEM厂商想在故障发生之前意识到任何潜在的故障并采取行动，使得这些故障不会在生产/运营过程中发生。PM的解决方式有助于管理这些资产，使得OEM厂商不会出现这样的「失败」场面。同样地，像桥梁这些任务关键型、与安全紧密关联的系统，一些信号资产根本就不允许失败， 需要PM解决方案的补充。而对于其他资产，因为有足够的时间来采取行动，CBM足够用了，可以不需要PM。但是，大数据的应用绝不仅限于CBM和PM。随着产业的资产和各种维护管理系统产生越来越多的数据，应用于其他行业的大数据应用（例如电子商务，社交媒体，在线搜索等）与铁路行业也越来越相关。这些应用之一就是人工智能(AI)，而AI已经以各种方式在铁路工业中进行了应用：一、情景智能通常，情景智能（Situational Intelligence）意味着如果需要，通过完全掌握操作知识以及更好的控制来使事情井然有序的进行。列车运营公司(TOCs)通过收集列车运行的实时数据，从空间，时间和节点三个维度进行分析。首先，空间方面提供了列车以及每列列车上的各个系统和子系统的实时位置。有了这些信息，你就可以通过地理空间定位了解每个物件在哪里，它们如何运行。增加时间维度可以让让我们根据时间尺度来深入了解资产的性能，从实时、1分钟、1小时、1天、一周甚至更长的时间方面来看其如何运行。情景智能最后的元素是节点，即整个系统中不同子系统的内部关系和层次结构。以节点尺度来分析数据让我们能看到各个系统间相互依赖的关系，从而找出故障的根源和系统行为。图1：人工智能引擎的空间-时间-节点模型分析三个维度的实时工作的大数据就像「集体思维」，会同时发现列车运行中的机遇和威胁。结合最近计算效率的发展，能在几分钟内对异常模式进行大范围排查并生成结果。因此，我们可以进行全面监测并且遗漏重要线索的几率也越来越小。如今，可采用一些高级统计分析模型来产生结果的排序列表，以便调查资源可以专注于最重要、最紧急的事情。一旦确认了最频繁和最普遍的问题，那么定期常规分析就能自动运行，形成更有效的资源配置。诸如公共事业（水电费）等特定行业如今已经用了这些系统进行网络监控和资产维护。二、运行智能运行智能会同时用数据的力量及其能力，在正确的时间提取正确的信息以改善铁路车辆检修的效率。比如亚马逊官网上的产品推荐引、Facebook上的好友推荐或者谷歌搜索上的相关广告：欢迎来到人工智能的世界。随着传感器和维护数据的增长量已经开始达到互联网用户产生的数据的数量，铁路产业已经可以采用人工智能。对于铁路产业面临如何鉴别问题根源、找到最合适的解决办法等挑战，其实与那些已经广泛应用人工智能的消费领域所面临的挑战非常相似。如今先进的算法能为 TOCs发掘大量操作数据，并以推荐的方式提出大量计划外的维护问题。就运行智能而言，相关的人工智能技术（包括知识库系统，案例推理，遗传算法，神经网络和模糊逻辑等）可以解决铁路产业中诸如车辆监控和资产维护等问题。它们能消除冗长的故障根源识别，能更快地进行维修、降低维修成本、增加车辆可用性和消费者满意度。列车运行和维护数据能用于建立类似于IBM沃森的超级计算机那样的维护知识库系统，这样的人工智能系统能执行简单任务，诸如以最优方式调度工程工作，对给定工作提供所需的工具和库存列表，提出在车辆可用性方面可能会造成影响的问题，以防维护工程师忽略某些问题。图2：知识库系统人工智能引擎的关键在于它能捕捉或编码工程项目、安全要求以及指导方针中有价值的领域和专家知识，来自动优化如何追踪已经分配到各种工程工作中的财产、工程训练和人力资源。例如，香港港铁公司（MTR Corporation of Hong Kong）使用人工智能简化且自动化其所有工程建筑的季度计划和每周安排。解决方案在坚持所有维护规则、法规和指南的同时帮助他们最大化其资源利用率。因此，MTR除了显著节省成本和时间外，MTR的整体维修效率的显著改善超过了50%。更进一步讲，当供应商将人工智能引擎集成到工作流程中，其所带来的益处将成倍增加。有了人工智能引擎，反馈（比如请求可行性、资源可用性、安全性和潜在的冲突以及其他请求）可以在几秒内给出。这让数以百计的计划者无需等待数天甚至一周，当即就可以根据需要做出计划改善或者改变。三、资产智能就资产智能而言，火车上各种子系统所产生的持续数据流可以帮助OEM建立起实时反映物理系统情况的模拟数字系统。通过运行火车的数字模拟系统来建立火车的运行行为模式，不仅能预测系统的故障，还能长期监测和评估诸如可靠性和可用性等资产指标的性能，并在产品设计方面提出改善意见。对产品设计进行不断的改进可令OEM厂商获得显著的竞争优势。为关键资产建立数字模拟系统目前被应用于航空航天和重工领域，以有效地实时监测及远程控制。总的来说，应用人工智能的潜在动机是识别「故障特征」，一旦发现立即纠正。诸如由人工智能产生的复发事件模型（ the recurrent event models）在预测故障方面非常有用，诸如关联和序列(Association and Sequence)分析可用于识别极为类似的故障以及接连发生的故障，而决策树（decision trees ）和神经网络可以拥有构建预测模型。建立事件和故障的根本原因对建立知识库系统至关重要，在上述数值数据分析之外，一些其他技术也被用于支持预测性维护的实践。譬如，文本挖掘技术正越来越多地应用于这个领域。如今，高级故障模型也可以被用于获得组件、子系统和系统的剩余使用寿命（Residual Useful Life，RUL）。此外，在可修复的系统中用参数和非参数的方法分析周期性故障事件：Wayne Nelson平均累计函数(Residual Useful Life，MCF)是很流行的非参数方法，而应用最广泛的两个参数方法是齐次泊松过程(Homogeneous Poisson Process，HPP)和非齐次泊松过程(Non-Homogeneous Poisson Process，NHPP)。CROW - AMSAA模型是实现NHPP的一个实例，能让分析人员对故障的系统建模。综上所述，很显然人工智能应用并不是速成之法，也并非一个能迅速实现并用以预测和状态维护的现成解决方案。正确分析大数据来创造情境智能、运行智能和资产智能可能会颠覆整个铁路行业维护车辆的OEM方法。如果应用得当，这三个领域不仅能证明铁路工业适合采用人工智能解决方案，而且对于目前互联网行业的人工智能应用也有所启迪。
nan;;【一周·精选】周末寒流入侵，窝在温暖的家里看看这些文章吧深度学习如何入门？科学家们都在用什么样的深度学习工具？神经网络和深度学习有何关系？人工智能未来何在？拉里·佩奇有哪些过人之处？……深度学习教程：从感知器到深度网络本文作者Ivan Vasilev是一名具有创业精神的高级开发人员。他的经验范围跨越多个领域和技术，但他的主要焦点在Java、JavaScript及机器学习上。本文介绍了包括感知器、前馈神经网络、有限玻尔兹曼机器、深度信仰网络等在内的深度学习基础知识。神经网络和深度学习简史（1）这是《神经网络和深度学习简史》第一部分。这一部分，我们会介绍1958年感知机神经网络的诞生，70年代人工智能寒冬以及1986年BP算法让神经网络再度流行起来。宣布开源的TensorFlowTensorFlow没有改变世界。但是，它显然是最棒的，也是现有最便利的深度学习库。本文作者Zachary Chase Lipton是来自加利福尼亚大学计算机科学工程学院的博士生，接受生物医学信息部的资助。他对机器学习的理论基础和实际应用都非常感兴趣。除了大学的研究工作，他还是微软研发实验室的实习生，亚马逊的机器学习科学家，同时还是KDnuggets杂志的特约编辑，以及曼宁出版公司的签约作者。数据科学家们的手中利器本文作者Matthew May是一位正在进行并行式机器学习算法研究的计算机硕士研究生，同时Matthew也是一位数据挖掘研习者，数据发烧友，热忱的机器学习科学家。开源工具在数据科学工作流中起到了愈发重要的作用。Github十大深度学习项目，其中包含了大量的代码库，框架以及学习资料。看看Github上的人们都在使用哪些工具，都在从哪些资源那里进行学习。人工智能未来在何方？没有什么事件能比2011年1月14日沃森在《Jeopardy!》节目中打败两位传奇冠军更能昭示人工智能的到来了。最终，机器人比我们还聪明。至此，沃森已经发展成IBM的增长引擎。如今，IBM的沃森被运用到超过三十五个国家十七个产业领域，不过，正如Rhodib在本次采访中提到的，这仅仅是一个开始。先进机器人改变我们的未来&nbsp;1月18日，由中国人工智能学会、湛庐文化等主办的「智能时代大未来」高峰论坛在上海召开，这是新年以来首场中外人工智能领域专家、学者的深度交流。中国科学院院士何积丰，首先指出先进机器人是一种颠覆式技术，将会改变我们的未来。&nbsp;硅谷老炮约翰·马尔科夫专访深得乔布斯信任的科技记者约翰·马尔科夫职业生涯最遗憾的事情是什么？他在重磅新书《与机器人共舞》中表达了怎样的观点？机器人会让我们失业吗？除了人工智能，具有灵敏科技嗅觉的他最看好哪一个新兴科技领域？他在大洋彼岸对中国的科技进步又有怎样的观察？带着这些问题，机器之心对「硅谷老炮」约翰·马尔科夫进行了深度专访。Facebook野心：连接全世界马克·扎克伯格呼吁让全世界的人都能接入互联网，他认为，互联网应该像卫生保健和净水一样，被当成一项基本人权。他把这个看作是当今时代最关键的社会尝试。扎克伯格相信，点对点通信承担着对全球能力进行重新分配的责任，使每个人都能接触和共享信息。人们能够接入政府服务，决定农作物价格，获取健康护理服务。一个印度的小孩可能借助在线学习掌握所有的数学知识。我们应该将情绪外包给机器人吗？可爱的机器玩具熊和海豹看起来似乎无害，但依赖机器寻求慰藉则存在真正的风险。拉里·佩奇的痴心妄想是如何成为谷歌的业务的？拉里·佩奇对事情有着广泛的兴趣，他总能敏锐的捕捉到事情最重要的一点，他的痴心妄想一步步成为了谷歌的业务，大隐隐于市的他是如何做到这一点的？
"日报;;【日报】发明「@」符号的人走了、比利时大学生制作蝎子机器人…这个发明电子邮件「@」符号的人走了据 Engadget 报道，电子邮件（Email）的发明者 Ray Tomlinson 于美国时间3月5日去世。他的公司和亲人并未透露更多信息，但死因可能是心脏病。Ray 在1971年发明了机遇 ARPANET（Internet前身）的电子邮件系统，当时他采用的邮件地址即为「用户名@主机」，这种方式也一直被人们沿用至今。在提到自己为何会选择在邮件地址里使用 @ 这个符号的时候，Ray曾 幽默的表示，这个符号是计算机键盘上唯一的介词。也正是因为 @ 符号有一定的指向性含义，在 Twitter 早期用户开始用这个符号来标记一个人，这也让 @ 符号得到了更广泛的使用。如果没有 @ 这个符号，Twitter、Facebook 和新浪微博等产品会变得和现在很不一样。比利时大学生制作蝎子机器人 可感应并攻击物体据英国《每日邮报》3月4日报道，来自比利时根特大学的大学生利用3D打印技术、激光切割技术和计算机数控技术制作了一个名为六足蝎子(Scorpion Hexapod)的机器人，这只蝎子体型巨大，可以感应前方“敌情”，并在攻击者手上留下标记。参与设计制作的大学生罗博•特雷恩(Robbe Terryn)表示，这只六足蝎子机器人是他们机电一体化设计和嵌入式原型制作课程的一部分。和真的蝎子一样，学生所设计的这个白色的六足蝎子机器人也有两个螯、一个尾巴和身体，不同之处在于这只蝎子机器人只有6个脚。它不仅可以全方位走动还可以感应周围环境，在攻击者手上留下记号。物理学家利用人工智能设计量子力学实验维也纳大学研究人员安东·齐林格(Anton Zeilinger)及其团队设计了一种名为Melvin的人工智能算法，希望利用人工智能技术来推进量子力学的研究。他们的研究成果已发表在《物理评论快报》上。量子力学是最令人迷惑的科学领域之一，即使最优秀的物理学家也认为，量子力学非常复杂。正如英国诺丁汉大学的迈克尔·梅瑞菲尔德(Michael Merrifeld)所说：“如果量子力学没有把你弄糊涂，那么这是因为你还没有真正理解它。”齐林格的团队认为，如果人类思维很难解决量子力学问题，那么没有人工干预的“大脑”或许将可以更容易设计出这种实验。

这一概念的提出者是博士生马里奥·科伦(Mario Krenn)。他曾尝试设计一种实验，利用激光和镜子去实现特定量子态。在这一过程中，他发现自己只是在做猜想，而计算机算法也可以进行这样的猜想，并且速度更快。

他表示：“因此我定义了目标，开发了算法，让算法整夜运行。第二天上午，算法生成了结果文件。这是令人兴奋的一天。”美国竞争加剧 无人机制造商开始拓展中国等亚洲市场《华尔街日报》网络版发表文章称，随着全球最大无人机市场美国的竞争加剧，无人机制造商开始将目光转向亚洲市场。中国无人机市场目前还处于发展初期，但是 随着分销渠道和应用的扩大，中国无人机年销量将快速增加。大疆、亿航等公司已开始着手拓展亚洲市场，招募员工，开设旗舰店，无人机飞行课程，并提供租赁服 务。不过他们也面临英特尔、Parrot等公司的挑战，无人机行业格局可能会在未来几年迅速发生改变。中国重型火箭即将立项 用于登月与火星采样中国重型火箭预计将在今年或明年立项，设计制造流程将全部数字化。这是6日政协小组会间隙，航天科技集团运载火箭技术研究院原党委书记梁小虹委员告诉科技日报记者的。之前公布的消息称，已开始研发的中国重型火箭长征九号，起飞质量为3000吨，直径超过9米。而即将发射的中国目前最大火箭“长征五号”，直径为5米，起飞质量为1000吨。日本研发搜救犬智能背心 可直播搜救现场据英国《每日邮报》3月4日报道，日本研发人员为搜救犬设计了新款“背心”。在搜救犬搜救过程中能将现场视频发回平板电脑，且背心与搜救犬嗅觉相通，能通过GPS快速定位待救人员位置。背心重达1.3千克，内置GPS定位系统与微型摄像头。操作人员可通过现场视频确定搜救犬的位置、搜救犬的搜救过程以及被害人的位置。

东京大学教授Ohno是智能背的发起者。他之前也研发过机器人搜救犬，但机器犬不能在规定时间内精确找出受害人所处位置。搜救工作中时间不等人。相反，传统搜救犬却能通过敏锐的嗅觉在短时间内找出受害者。Ohno教授根据这一现象将机器狗与搜救犬结合，研发出搜救犬智能背心。

上月，研发人员对搜救犬Gonta进行试练。背心虽能发回现场视频与受害人位置，但当搜救犬独自进入倒塌建筑时，视频信号便会中断。Ohno教授将就这一点改进。有了这种皮肤，机器人能更好地表达“情绪”康奈尔大学的研究人员研究出了一种特殊的“皮肤”，这是一种可发光的材料，柔软性极强，可以拉伸至六倍以上并且保持发光。这种“皮肤”由两层透明的导电水凝胶构成，两层水凝胶之间是一排电容器，它们在通电时会发光。这种灵感来源于章鱼，它们能根据环境很快速地改变自己的皮肤颜色从而达到伪装。研究报告第一作者、康奈尔大学机械与航空航天工程学助理教授Rob Shepherd认为这种“皮肤”将有两种应用方向，一种是应用在机器人上，打造出能变色和显示信息的软体机器人；一种是能变形的显示器。

有了这种“皮肤”，机器人不仅拥有柔软的肢体，而且还能有自己的“情绪”表达，通过不同的颜色，机器人能展示自己的感受，从而与人类更好地沟通。变形显示器的应用则更具想象力一些，比如研究员Chris Larson认为，在未来你可以在开会时通过手腕上橡皮筋一样的装置查看邮件。

这个项目得到了陆军研究办公室的资助，看来不久的将来我们能到伪装机器人。除了引力波，一束奇异的光射线信号也到达地球一个月前，引力波探测消息引爆全球，并引发持续研究讨论。在这组来自13亿年前的引力波被探测到的同时，科学家还发现一束奇异的光射线信号也到达地球。

2015年9月14日，几乎是在LIGO探测到两个黑洞碰撞的引力波的同时，在距离地球500公里的外太空也有另一个更晦涩的信号被发现。近轨卫星搭载的费米伽马射线空间望远镜记录了一次伽马射线爆发。但是这个伽马射线信号太微弱了，以至于NASA望远镜背后的科学家们一开始并没有注意到它。&nbsp;“引力波探测器LIGO发现的是一组非常清晰的信号，几乎清晰到难以置信，而我们发现的数据要模糊得多，也仅仅是因为太靠近引力波发现的时间点才让这个数据变得有趣。” 费米望远镜的一位研究组成员Valerie Connaughton这样说。

2016年2月11日，费米望远镜的研究人员在预印论文网站arxiv.org上发表文章，描述了这次伽马射线爆发以及猜测它可能来自于LIGO探测到的同一黑洞碰撞事件。这一相关联系仅仅建立在假想层面，并且需要推翻一些根深蒂固的天文物理常识。天文学家长久以来认为黑洞周围是真空，因为它会吞噬周围的所有物质。而如果周围缺乏物质就意味着两个黑洞的融合不可能产生光及射线。&nbsp;“如果没有带电粒子就没有磁场，没有磁场就没有电磁波，”普林斯顿大学天文学家Adam Burrows解释道，“这是个很清楚的系统。”&nbsp;但是费米伽马射线空间望远镜探测到的伽马射线爆发意味着这一对黑洞的周围可能并不是完全真空。在费米望远镜团队发表文章的几天之后，许多天文学家纷纷就黑洞周围的物质存在提出理论支持，从而解释伽马射线伴随黑洞碰撞爆发。这些理论结合了天文学家的想象力和某些未解的历史天文事件，以解释这一次不寻常的射线现象。量子计算将能分解任意极大整数，RSA加密或成摆设就算是一台超级计算机有可能在数年的时间内计算出任意质因数，这也是得不偿失的。为了科学地解决这个问题，麻省理工学院（MIT）的科学家找到了明确的方法。今天，《科学》杂志最新发表的一篇论文显示，量子计算机有史以来第一次以可扩展的方式，实现了Shor算法。
据外媒Engadget报道，MIT和 Innsbruck大学的计算机科学家组装了一台5量子比特的量子计算机，它将能够用Shor算法完成对数字15的质因数分解。他们研发了一台量子计算机原型，然后使用一系列离子，借助激光脉冲来在4个量子比特上执行Shor算法，令其分解数字，第5个量子比特则用于储存和输出结果。目前的结果是，这台计算机不仅能够比现有量子系统更高效地计算出方案，而且区间缩放相对容易。哈勃望远镜发现最遥远星系:距离至少134亿光年北京时间3月7日消息，哈勃空间望远镜自从1990年发射入轨以来已经过去了26年之久，相信这个岁数比正在看这篇文章的很多读者的年龄还要大。但尽管“年事已高”，这台轨道实验室却仍在继续取得最新的发现。比如就在最近，科学家们便利用哈勃空间望远镜的强大观测能力发现了据信是迄今最为遥远的天体。

[caption id=&quot;attachment_11612&quot; align=&quot;aligncenter&quot; width=&quot;630&quot;]最近，科学家们便利用哈勃空间望远镜的强大观测能力发现了据信是迄今最为遥远的天体，这个婴儿星系距离地球至少134亿光年，当时的宇宙年龄仅有今天的3%左右[/caption]

欧洲空间局(ESA)的科学家们宣称他们首次观测到来自天体GN-z11的光芒，这是一个原始的婴儿星系，这些光是在宇宙大爆炸之后仅4亿年时发出的。这个婴儿星系距离地球至少134亿光年，而此次观测也让天文学家们有机会一窥大爆炸之后宇宙中诞生的最早一批星系。

同时，这项发现也是向哈勃这台“长寿”的高性能轨道望远镜的致敬之作。哈勃空间望远镜，1990年由现在已经推移的美国“发现”号航天飞机搭载入轨。尽管每隔一段时间美国宇航局就会对其进行硬件升级，但按照现代技术标准来看，哈勃实际上已经可算是一个老古董了。意念控制头环：用脑电波来操控智能家居人类对脑电波控制的研究已经有数十年历史，近年来也已经取得了一些实际成果，例如在假肢控制的医学康复领域，或是用于简单的游戏操纵。这些脑波控制都离不开一个头罩或是头环，用于捕捉脑电波信号并进行解读。哈佛大学在读博士生韩璧丞的创业项目产品Focus 1，也是一款类似的产品。但在他看来，自己的智能头环是全球第一款医疗级别的可穿戴脑效率提升专家，可以用于提高注意力，控制智能家居以及假肢控制。举个简单例子，早上醒来带上头环想一下，兼容连接的咖啡机就开始自动煮咖啡，吐司机也自动烤好面包。

这个创业团队BrainCo设在美国波士顿，组建于2014年9月，是由几位哈佛或是麻省理工的中国留学生共同创办的。他们的原型产品在今年1月的CES进行了展示，吸引了《今日美国》、美联社、雅虎等数家美国主流媒体的报道。目前他们的脑波控制头环Focus 1正在生产制造环节，韩璧丞他们计划年内上市销售。三星联手迪肯大学测试AI老年家庭护理平台据科技网站ZDNet报道，近日，三星宣布将联手澳大利亚迪肯大学共同在大吉朗市开展老年家庭护理平台的测试，如果进展顺利，该平台未来将成为解决老龄化社会问题的一剂良药。

这场为期6周的测试被称为神圣计划，测试人群定位在73至81岁的老年人。在测试中，家庭护理平台上的相关软件和硬件设备将记录老年人的生活方式和习惯。具体来说，测试将引入SP Tech Solutions的智能家居平台，三星将为其提供支持。安装在家中的Holly Hub小型电脑将负责传感器数据的收集汇总，而家中的传感器则可探测动作，震动，气温和湿度。此外，每个房间中还装有扬声器，老人们可通过它与智能AI Holy交流。

三星高管表示，该平台可以帮助超过70岁的老人独立生活，减少家人和社会的负担。此前就有此类系统出现，但它们只是扶手或墙上的报警按钮，使用效果非常一般。英国将开测无人驾驶卡车车队Google已经测试无人驾驶小汽车多年，而这项技术的下一阶段，则是无人驾驶货车。由于摆脱了传统货车驾驶员所必须的睡眠休息时间，无人驾驶卡车将能够让长途运输变得比以往更快。据悉，英国将于今年晚些时候开测无人驾驶卡车车队，不过它不仅仅是为了提升物流的速度，还有望减轻道路的拥塞状况。该国交通部希望能够在重型运输车辆（HGV）的使用上处于领先地位，且试验将在公共道路上展开。

在不久的将来，人们将能够在M6高速路上见到高达10辆的无人驾驶货车车队。此外，尽管测试是在公共道路上进行，但有关方面会尽可能地将影响和潜在问题降到最低。"
"日报;;日报 | 人工智能预测莱昂纳多拿下本届奥斯卡人工智能预测小李子拿下本届奥斯卡、谷歌举办「人工神经网络」艺术展、沃尔沃用无人机和机器人实现倒垃圾自动化、光遗传学技术助力恢复盲人视力首次人体实验、虚拟现实眼镜治疗毒瘾……机器之心日报，精选一天前沿科技优质内容。人工智能预测莱昂纳多将拿下本届奥斯卡小李子终于如愿捧得奥斯卡小金人，20年陪跑的辛酸史终于在今天画上了句点。虽然奥斯卡奖一向都如扔骰子般随机，但并不意味着完全不可预测。人工智能公司Unanimous A.I.就对今年的6个大奖的归属进行了一番预测。人工智能系统预测：今年的最佳影片得主是《荒野猎人》；莱昂纳多·迪卡普里奥(Leonardo DiCaprio)终将如愿以偿，获得最佳男主角；最佳导演奖则会由该片导演伊尼亚里图获得；最佳女主角将归属于《房间》主演布丽·拉尔森(Brie Larson)；而凯特·温斯莱特(Kate Winslet)则会成为最佳女配角；史泰龙(Sylvester Stallone)有望获得最佳男配角。&nbsp;以上是人工智能的预测，下面我们来看看本届奥斯卡的获奖名单：莱昂纳多凭《荒野猎人》成功夺得奥斯卡影帝，布丽·拉尔森凭借《房间》夺得影后大奖，《荒野猎人》导演亚利桑德罗·冈萨雷斯·伊纳里图获得最佳导演奖，最佳女配角归属《丹麦女孩》艾丽西亚·维坎德，最佳男配角归属《间谍之桥》的马克·里朗斯；《聚焦》获得最佳影片大奖，《疯狂的麦克斯4》一举拿下最佳音效剪辑等六项技术大奖。

这一切的背后功臣当归属平台的UNU算法，据悉它可在30秒之内让用户利用自己的人类直觉、情感和感受力得出结论，虽然这听起来有些像众包，但这种群体性人工智能方法并不依赖投票和调查来得出结论，而是让整个群体“一起思考，并利用他们共同的知识和直觉得出结论。为了预测奥斯卡奖的结果，UNU使用了50名参与者的专家思维，他们都对不同的奖项和提名人有着不同程度的了解，而且这份预测结果与微软必应的预测以及专家花费好几个与小时分析数据的结果一样准确。值得一提的是，从“超级碗”的赌球结果来看，UNU的表现超过了99%的人。由此可见，连人工智能都力挺的影帝，小李子当之无愧。谷歌举办「人工神经网络」艺术展还记得那个画出了很多诡异图像的谷歌Deep Dream吗？没错，近日谷歌(微博)搜索将联合Gray Area Foundation for the Arts艺术基金会举办一个艺术展，展出由「人工神经网络」工具创造的作品。去年6月，谷歌的工程师向社会公布展示了他们独特的「人工神经网络」工具和相关算法，声称可以讲普通照片转化为有着迷幻漩涡和瑕疵的新物体。如今他们将会这段时间创造出来的29件作品举办一个艺术展。这个新的物体是由普通用户和DeepDream联合应用程序制造出来的，这次这些作品除了展出之外还将进行拍卖，拍卖所得的全部筹款皆会捐给非营利组织。 沃尔沃：用无人机和机器人来实现倒垃圾自动化日前，沃尔沃宣布该公司旗下的ROAR(机器人自主拒绝处理系统)项目已进入原型测试阶段。该系统的设计初衷是要实现将路边垃圾箱内的垃圾自动倾倒进垃圾车内的漏斗中，无需人力辅助。该项目最早计划利用机器人来完成这一工作，这将需要一份标明垃圾桶大致位置的地图来为其提供路径导航(以及GPS、激光雷达和加速度计等辅助工具)。而在新的计划中沃尔沃加入了无人机，作为垃圾车的「天眼」来告知垃圾桶当时的确切位置。该项目的设计和原型构建是由沃尔沃与查尔姆斯理工大学、梅拉达伦大学和宾州州立大学的学生在短短四个月的时间里完成的。扎克伯格：下一个计算平台是VR上周，扎克伯格在柏林接受德国报纸《星期日世界报》的访问时表示，他坚信虚拟现实会成为一项重要的技术，现在正是投资虚拟现实技术的时候。他预测建立VR生态系统可能花5年、10年甚至15年或20年的时间。「我猜想，建立这个生态系统至少需要10年的时间。人类从开发最早的智能手机到智能手机进入大众市场用了10年的时间，黑莓在2003年推出，到2013年的时候它的总销量才达到10亿部。因此我想虚拟现实的发展速度不会比它们更快。」在虚拟现实方面，Facebook最感兴趣的是软件，但是在任何新平台的早期开发阶段，需要同时去做硬件和软件方面的事务。只有发展到一定程度之后，专业化才有意义。因此他们需要拥有一家在硬件方面做得很好的公司，还需要一家在软件方面做得很好的公司。「一切都是瞬息万变的，你想让更新迭代联系在一起。这就是为什么我们的长期目标是软件，但是同时也会去关注硬件的原因。」而他还透露，未来10年或更长时期，Facebook将专注于视频、人工智能和VR与AR领域。澳大利亚利用无人机进行海域巡逻与搜救行动澳大利亚的首位宇航员与一位博爱的人打造了一款无人机，用来在新南威尔士州的海滩附近巡逻，监控大白鲨以及其他食人的鱼类。他们所打造的无人机名为「Little Rippers」，每架价值25万美金，这款军用级别电池续航的无人机配备了可拍摄实时画面的摄像头，飞行距离达到100公里，在空中悬停时长可达150分钟。这款无人机非常适合在海滩边执行监控鲨鱼的任务。在接下来几天这些无人机将被部署于新南威尔士州的北海岸，这片海域经常有鲨鱼出没。光遗传学技术助力恢复盲人视力将进行首次人体实验根据麻省理工学院的技术审查报告显示，美国德克萨斯州的医生正在计划使用开创性的神经科学技术来恢复失明者的视力。位于安阿伯市的 RetroSense Therapeutics 公司试图通过一项被称为「光遗传学」的技术来修改神经元，以实现用光线「打开」或者「关闭」它们的目的。据了解，这项技术已经在小老鼠和猴子的身上得到了验证，但是这将是它第一次被应用到人类的身上。根据计划，医生将会把包含有光敏基因的病毒注入到患者眼睛中的神经节细胞里，这种细胞会把信号从视网膜传输到大脑中去。由于患者的视网膜受损，医生们希望能够绕过这些细胞，让神经节细胞直接对光线做出响应。另外，接受这项实验的视网膜色素变性患者并不是完全失明的，但是他们也只能看到在自己面前挥动的手。此前，有科学家曾经利用「光遗传学」技术成功将小老鼠大脑中的恐惧记忆去除掉。这项实验是否成功还有待观察，但是，它的应用前景是非常令人振奋的。目前，科学家们已经开始探索利用“光遗传学”技术来治疗其他的疾病，比如帕金森氏病等等。&nbsp;美科学家欲借虚拟现实眼镜治疗毒瘾美国休斯敦大学博德尼克团队最近进行了一项新的研究，他们将给毒瘾患者戴上虚拟现实眼罩，使用了8个红外摄像头系统投影出与真人相同尺寸的3D化身，以及可以与之互动的虚拟环境，创造一个虚拟的海洛因环境，这里会有各种吸食和注射海洛因的场景。他们希望通过这种方法更好地训练在现实生活中深受毒瘾之苦的人。研究人员表示，他们花了将近一年时间才让整个环境栩栩如生。休斯敦大学社会工作学院的这项研究其中精心设计了很多细节，目的都是为了激发参与者的毒瘾。博德尼克之前还曾利用虚拟现实对烟瘾等其他问题展开过研究，结果表明，参与者在虚拟现实环境中学习了一些技巧后，便会加强他们在现实生活中抗拒诱惑的信心。雅虎也有人工智能的秘密武器2月24日，雅虎公布了 CaffeOnSpark 人工智能引擎的源代码，从学术研究者到大公司员工都可以使用或修改。和许多新的开源人工智能项目一样，CaffeOnSpark 以深度学习为基础。深度学习是人工智能的一项分支，对帮助机器识别人类讲话、图像和视频内容用处尤其大。比如雅虎利用它测定不同图片的内容，来优化 Flickr 的搜素结果。雅虎不是依赖上传图片的人所输入的描述和关键词，而是教会计算机识别图片的某些特点，比如特定的颜色、甚至动物和物体。谷歌的TensorFlow、微软的CNTK、Facebook的人工智能硬件设计、百度的深度学习训练软件代码……这些开源各有侧重，雅虎想在现有的系统上运行深度学习进程，不必把数据从一个地方移到另一个地方。百度吴恩达：担心超级人工智能？还早了几百年近日，凤凰科技专访了人工智能专家、百度首席科学家吴恩达（Dr. Andrew Ng），谈了谈他在百度的工作和对中国互联网发展的一些看法。吴恩达，加入百度前曾是谷歌深度学习实验室的创始人之一。按照学界的说法，他是被称为机器学习四大天王的人物，目前还是斯坦福大学计算机科学系和电子工程系副教授，人工智能实验室主任。电脑有时很聪明，但是在吴恩达看来，机器智能是完全不同于人类智能的两种东西，他们的想法截然不同。有很多东西，电脑都不会复制人类，「人工智能做自动驾驶，语音识别，做搜索，做那些反垃圾邮件，让我们的数据中心变得更依赖，更可靠。但是机器的有监管学习与人相比还是有局限性的。人是有情感的生物，比如爱、恨、不耐烦，为什么我们会要电脑做这些东西？」吴恩达这样阐述了对人工智能的看法。&nbsp;电话推销太烦？让机器人来应付他们Roger Anderson是个在电话系统工作的咨询顾问，负责为企业设置电话线路、搭建叫你「这样请按 1；那样请按 2」的电话网络。他喜欢电话。度假的时候，他会去参观西雅图通信博物馆（Museum of Communications）那种地方，然后在旧电话线旁边自拍。可是到了晚上，他就开始与「邪恶」的电话推销员做斗争，调试一个能与电话推销员没完没了对话的机器人，消耗掉他们的时间，这样推销员就不会来浪费你的时间了。Anderson 一接到电话推销员的电话，就会把电话切给他的机器人，然后把自己的话筒静音，让机器人来对话。虽然这个简单的机器人离人工智能那些特性差得还很远，但它能够理解人们说话的模式和语调，所以它可以监听电话推销员说的话，然后尽其所能让电话另一端的人保持通话。一切的目的就是让电话推销员的通话时间尽可能长。这种对话进行得越久，机器人就变得越怪。Anderson 觉得自己好像真的用机器人帮到了大家。他日日夜夜地努力完善这个机器人。而且，近日他发起了 Kickstarter 众筹，希望能把机器人做到完美。他还在想办法支付所有打进来的电话费用。然而，他的终极目标不仅如此。「我的梦想是扰乱自动拨号程序，」他说。这些机器人拨号程序每天能拨通 1 万个电话号码，而且能探测到那边是应答机还是真人在接电话。换句话说，Anderson 想用自己的机器人与其他机器人对决。 瞬移需要的大脑导航基础瞬移的技术还没有实现，瞬移的神经科学研究却已经展开了。Neuron上的一篇文章显示，瞬移过程中，我们的大脑也可以进行导航，从传送点走出来也知道自己在什么地方。加州大学戴维斯分校的研究人员，让三名脑内已植入电极的癫痫患者在电脑屏幕前的虚拟街道中活动。这些街道中，有几个「传送点」，一旦进入，就会在另一个已知地点的传送点中出来。在这种虚拟的传送中，人看不到任何东西，所有与环境线索有关的外界信息都被消除了。研究人员始终在监测被试者的海马低频振荡，发现这种低频振荡在传送过程中仍然存在，且持续时间并没有因为传送而改变。因此，这种振荡不需要依赖外部的感官，而是被记忆和学习过程始终驱动的。所以，即使被传送的过程中失去了所有环境线索，传送后人可能仍然清楚自己在那里，而不会一片茫然。当然，前提是他以前来过这里。这种“精神导航”，显示了人的大脑可能可以从环境中脱离出来，但精神仍然在不断地导航。这也可能意味着，虽然瞬移的设备还没有建好，但人类为瞬移准备的大脑导航系统已经可以工作了。 谷歌PlaNet照片识别系统准确判断照片地理位置谷歌两名工程师开发了一款名为PlaNet的照片识别系统，运用深度学习技术在没有特定地标情况下通过分析照片上的像素判断照片的地理位置。开发团队建立了一个超过1.26亿张包含GPS信息图片的庞大数据库，并将它们投入到机器学习算法之中让PlaNet学习不同地方的图片有哪些特征，从而逐渐具备识别图片有可能所在地点的能力。 保证摩托车驾驶完全的智能转向系统一直以来，摩托车都被人认为是一种比汽车危险得多的交通工具，虽然它的移动速度很快，但是它却像自行车一样不设有安全防范措施。而提升摩托车安全等级的一个非常重要的因素就是它的能见度，让周围的机动车辆看到它的存在就能大大减少摩托车的事故发生率。总部位于斯洛文尼亚的 ABCS Sistem 公司就开发了一种智能转向系统，其目的就是为了降低摩托车出现交通事故的风险。据了解，这款智能转向系统使用的是运动传感器技术，以确定摩托车正在改变车道或者离开高速公路，该系统能够以每秒300个数据的速度进行运动数据收集，其中包括了加速度、倾斜和震动等方面。然后，该系统的算法将确定摩托车驾驶者正在进行什么操作。目前，摩托车上的一些信号指示灯数据已经被集成到了这个系统中。东莞：机器手臂取代汗水车间在被称为「世界工厂」的东莞今年仍将大力实施「机器人智造」计划，着力建设中国机器人产业先行市，打造有全球影响力的先进制造基地。以制造业和加工贸易著称的东莞企业累计申报「机器换人」专项资金项目共1262个，总投资达103.84亿元。调查显示，「机器换人」项目完成后，相关企业的劳动生产率平均提高65.25%，产品合格率平均从89.04%提高至94.44%，估算可减少用工71253人，单位产品成本平均下降9.98%。今年的东莞市政府工作报告则提出，2016年东莞将引进若干家有国际国内影响力的机器人龙头企业，加快形成覆盖本体、关键零部件、系统集成商、服务提供商的机器人产业集群，力争机器人产业产值增长30%。机器之心编辑出品。"
摩尔定律;;从人机大赛中看趋势，摩尔定律失效后计算机世界如何发展？摩尔定律之后，可预见计算机硬件发展的时代已经结束。尔后，谁将接踵而至？1971年，世界上跑得最快的汽车是法拉利代托纳，时速高达280km/h（174m/h）；最高的建筑是美国纽约的双子塔，高达415m（1362英尺）。在这一年的十一月份，英特尔发布了世界上首个商业微处理器芯片——4004，包含2300个微晶体管，单个大小如同红细胞。从此，芯片的发展速度如同英特尔联合创始人戈登·摩尔预测的那样线性发展。根据他的经验法则，也就是我们熟知的摩尔定律：大概每两年，随着晶体管越来越小，在硅晶上的排布越加密集，计算机的处理能力将会翻一翻，性能更好，成本更低。现今，一个英特尔的 Skylake 处理器上约有17.5亿个晶体管——大概50万个这样的晶体管的大小才相当于4004上的一个——全部运作起来传送速度是当时的40万倍。这样的指数增长速度是很难和物质世界联系起来的。如果从1971年开始，汽车和摩天大楼也以此速度发展，如今最高的车速将会是光速的十分之一；最高的大楼距月球只有一半的距离。摩尔定理的影响我们能切身感受到。如今全球有30亿人随身携带着智能手机，而每个手机的处理能力都比20世纪80年代房屋大小的超级计算机强。无数的行业已经被数字化颠覆了。充足的计算能力甚至放缓了核弹测试，因为原子武器的的模拟爆炸测试要比真实测试方便的多。摩尔定律已经成为了一种文化隐喻：硅谷内外的人全都希望科技每年都能更进一步。但如今，半个世纪之后，摩尔定律的结束已然可以看见。晶体管的微型化已经不能保证成本更低或速度更快。但这并不意味着计算的进展会突然停止，只是发展的性质的发生了变化。芯片仍然会越做越好，但改善速度会慢一些（英特尔表示数值处理能力现在是平均每2.5年翻倍）。另外，计算的未来不仅由原始硬件性能决定，而将由其他三个领域的发展来定义。第一个是软件。本周一款能够下围棋的程序AlphaGo击败了人类最好的棋手之一李世乭，在韩国的5场比赛中赢得前两场。围棋因其复杂性一直吸引着计算机学家：棋盘上，落子的可能性比宇宙中的粒子还多。所以，围棋系统并不能简单的依靠计算暴力（译者注：计算暴力，computational brute force 指每秒算度两亿步棋和瞬间探索内含几百万个棋谱）去取胜。AlphaGo依靠深度学习技术，部分模拟人脑工作的模式。本次胜利表明了通过新算法能获得更为强大的性能。的确，硬件的缓速发展将会大大刺激软件的智能化研发。发展的第二的领域是「云」，互联网上提供服务的数据中心网络。无论是PC机还是大型机，当计算机独立运作时，它们的计算性能完全依靠处理芯片的速度。而如今，计算机在硬件性能没改变的情况下变得更加强大。当处理邮件搜索或查询最佳旅游路线等工作时，它们能够利用「云」中庞大（且灵活）的数值处理资源。此外，还拥有了互联的能力：智能手机的卫星定位功能、运动感应功能和无线支付功能都和处理器运行速度一样重要。第三个改进方面在于新的计算架构——为特定工作优化过的专用芯片，甚至其他领域的技术，比如同时利用量子机制的特异性来处理多个数据集。普通的微处理器发展如此之快，没有什么必要去追求这一类的方法，但芯片现在会被设计成针对云计算、神经网络处理、计算机视觉和其他任务等的形式。这样的专业硬件会被嵌入进云中，有需要时就进行调用。这再一次意味着终端用户的设备原始性能并没有那么重要，因为重要的任务在其他地方被完成了。速度并非一切。这在实际中意味着什么呢？摩尔定律从来不是物理定律，而是一种自我实现的预言——是中心规划的胜利，通过这种规划，技术行业能够统筹同步其行为。它的结束会使技术发展速率变得更不可预测；在新的性能增强技术不时出现并开始运用之前，这条道路可能会十分坎坷。但考虑到大部分人在评判他们的计算设备时，主要考虑的是设备的能力和特性，而不是处理速度，所以对消费者来说并不会感到明显的减速。对于公司来说，摩尔定律的结束可能会被转移至云计算遮掩起来。现在公司更新电脑已经没有那么频繁了，并且已经停止运营他们自己的e-mail服务了。然而这种模式取决于快速稳定的链接。这会增加带宽基建改进的需求：计算能力逐渐在云提供商的数据中心内部得以改进，那些信号较差的链接会更难以获利。对于技术行业本身，摩尔定律的消亡也会加强云计算中心化的思维方式，而这些已经在一些大公司身上得到了验证：亚马逊、谷歌、微软、阿里巴巴、百度和腾讯等等。他们非常努力的去改进他们的云架构的性能。也在寻找进军新领域的初创公司：谷歌在2014年收购了DeepMind，正是这家英国公司创建了Alpha Go，而Alpha Go刚刚在过去的两天内连下两局，击败了围棋世界冠军李世乭。对于过去50多年，这种看似不可阻挡的晶体管变革使得计算机稳步降价，并且更有能力。随着摩尔定律失效，进展也许不再那么有规律。但计算机和其他设备仍然会变得更强大——只是以不同的、更广阔的方式变化。
"机器学习;;对话谷歌研究员Kevin MurphyWriting Sessions是知识共享网站Quora推出的一个与专家交流互动的新板块，在这里你可以看到各个行业领域的专家、学者、名人等对引人注目的问题的独特见解。最近推出的系列围绕如今最热门的技术之一——机器学习所展开，之前机器之心推出了Andrew Ng系列，Pedro Domingos系列，本次机器之心精选谷歌研究员、《Machine Learning: A Probabilistic Perspective》作者Kevin Murphy在Quora上的回答，让我们一起看看这位机器学习研究员对机器学习等有何见解吧！机器之心后续还会陆续推出其他专家系列，敬请期待！问题一：深度学习的极限在哪里？如果你说的「深度学习」指的是「函数的嵌套组合」，那么它确实没有太多极限可言，因为所有的计算都可以被包含在这个概念里。然而在我看来，主要的问题在于目前的深度学习方法仍需要过多的时间和数据——这和人类能够通过小得多的数据样本学习，并且学得更加快速的能力相矛盾（比如，《纽约时报》语料库中的词汇量比一个三岁小孩听过的所有词汇多出100多倍）。

关键的问题是：学习的最佳表示形式，即归纳偏置（inductive bias）（译者注：当学习器去预测其未遇到过的输入的结果时，会做一些假设（Mitchell, 1980）。而学习算法中的归纳偏置则是这些假设的集合。——维基百科）是什么？当然，这因不同的学习任务而异。人类似乎综合采用了多种知识表示。具体的例子见Liz Spelke关于儿童「核心知识」的工作（以及Josh Tenenbaum及其同事的工作）。当然，这种高层次的知识由神经放电的模式予以表征。但是从统计的角度（或者计算的角度）来讲，通过操控更加结构化的表征（比如，对象和代理，以及它们的属性和关系）比起在一个超高维的连续参数空间中进行小步长计算更利于高效学习，虽然目前看来，后者似乎正大放异彩。问题二：除了Matlab和R语言这样的主流语言，今后在学术和工业界还有哪些最有用的语言？Python是目前最受欢迎的语言，虽然在科学计算领域，Julia似乎也越发受到青睐。个人来讲，我喜欢具备静态类型检查和类型推理功能的语言，比如Standard ML 和 Scala，但它们并未进入机器学习社区的主流（虽然微软研究院显然大量使用了F#语言）。在谷歌，我们主要使用C++ 和Python，也有一些同事用Jave和R语言。同时，DeepMind团队和其他一些人工智能实验室使用的是Lua语言（因为这是使用Torch最简单的方法）。问题三：你写作《机器学习：概率观》（Machine Learning: A Probabilistic Perspective）的动机是什么？大约在2006年我开始了这本书的写作，当时我是英属哥伦比亚大学的教授，给本科生和研究生讲授机器学习。我发现当时已经出版的作品（如Chris Bishop的书，以及Hastie，Tibshirani 与 Friedman合著的书）都在某方面尚有缺陷（比如Bishop的书中甚至没有提到L1范数规则化，而Hastie的书没有包括图论模型）。于是我决定自己写一本，但我没想到这本书花了整整六年才得以出版。.问题四：你怎样看待openAI？一方面，OpenAI的员工都是深度学习领域一批最优秀的初级研究人员；另一方面，我认为它成立的初衷——即Elon Musk等人担心人工智能会掌控世界——有些不靠谱。我同意吴恩达的说法，即「担心人工智能超越人类就像是担心火星上人口过剩一样」。我的主要担忧在于，担忧这些遥不可及的灾难让人们从眼前的紧迫问题上分散注意力，比如气候变化，失业问题（部分由人工智能造成），（经济和种族的）不平等，等等。问题五：机器学习中，尚未解决的问题里最重要的是哪个？非监督式学习。具体来讲，非监督学习应该采用怎样的目标函数？选取原则该是可以最大拟合已观测到的数据，还是最大拟合未来会观测到的数据？好像都不对。比如，假设我们要预测一段视频接下来N帧的每一个像素，我们会关心图像的精确亮度值吗？不，我们关心的是对下一步的预测（汽车会向左还是向右转向？如果我扔下这个杯子，它会摔碎吗？）。不知何故，人和动物似乎是在这一更抽象的层面学习预测的，这与对象和关系相关，不需要接收任何标签数据。多任务强化学习对此有所帮助，但是单单从梯度奖励（scalar reward）进行学习似乎太局限。学习预测某人的行为结果似乎有所帮助（这同样可以用于基于目标的规划）。问题六：为什么人工智能赢得围棋是意义重大的里程碑？围棋比国际象棋困难得多，因为它要求学会察觉棋盘上布局的微妙模式，而不是仅仅计算不同棋局状态下的权值。在这方面，围棋更接近于实际问题，它要求一种「模糊的」模式识别。（关于DeepMind的更多信息，请见AlphaGo: using machine learning to master the ancient game of Go）。这仍然和「人类级别的人工智能」相距甚远（比如，AlphaGo只能下围棋，却不能完成其他任务），但这仍然是令人惊叹的里程碑。问题七：除了神经网络，什么是机器学习领域目前最有前途的方法？具有优良特性的古典广义线性模型（例如，线性和逻辑回归），只要输入特征足够多（如词汇和像素），并有合适的特征引擎，它们就能够出色的解决监督式问题。你也可以把它们和字嵌入（word embeddings）结合起来。另外，随机森林算法（Random forests）也是很好的机器学习方法。问题八：学习机器学习最好的教材有哪些？显然我写的机器学习教材是不错的选择。然而不得不承认，这一版本对初学者来说有一定难度。事实上我正在编写本书的第二版，它讲述的节奏更加缓慢，也就更加适合初学者（我也在这一版中加进了深度学习、增强学习等内容）。但完成它还需要一段时间（大概两年？）。

同时，还有别的一些好书值得推荐。比如，可以参考这个书单：josephmisiti/awesome-machine-learning。我认为尤其出色的一本是James, Witten，Hastie和Tibshirani编写的《统计学习入门》（Introduction to Statistical Learning）。它包含了一些频率统计方面的概念，比如p-值（这一部分你可以放心跳过），但不足的是，没有涵盖深度学习或图论模型等主题，但无论如何这是一本很好的入门教材。问题九：人们应该怎样开始自己的机器学习领域的职业生涯？这取决于你怎样定义「机器学习领域的职业生涯」。

如果你指的是一份运用现成工具（如R程序库、scikit-learn或Dato）的工作，你只需要在本科期间上几门机器学习相关的本科课程，或是在线的开放课程（如https://www.coursera.org/learn/m...或https://www.coursera.org/special...）。

另外，你应该多多积累实际经验，比如参加kaggle竞赛，以及（或者）在github上分享你的代码（我推荐使用Python）。

如果你想要一份开发全新机器学习算法的工作，那么你需要获得计算机科学以及（或者）统计学的博士学位（当然，也有人在博士后期间从物理等领域中途转向机器学习）。"
"人工智能;;Fackbook的人工智能：玩积木，学物理看看这些积木。你觉得它们会倒下来吗？&nbsp;这个简单的问题正在推动Facebook人工智能研究实验室的新实验—— 尝试开发一个能够观察简单版本世界并且预测将会发生什么的软件。Facebook的研究人员希望该软件像人类一样，不要基于工程师撰写的规则来做判断，而是通过直觉知道物理世界将发生什么。他们写道：「我们并不需要牛顿力学定律来做这样的判断—— 相反，我们要依赖与世界互动过程中建立起来的直觉。」如果计算机像婴儿一样，可以玩积木并且观察它们如何摆动，那将会是怎样的？&nbsp;首先，研究人员创造了180,000个由计算机模拟出来，两到四个随机堆放的彩色块。他们还拍摄了439个积木塔倒塌或者待在原地的视频。

接下来发生了什么？

一些模拟和视频被输入人工神经网络。作为现代人工智能的基础，这些软件模型可以依据它们所处理的数据进行学习和作出相应的改变。在这次培训后，一些网络被展示了前所未见的场景，并做出积木是否会倒下来的预测。

最好的神经网络准确地预测出了模拟积木89.1%的下跌百分比。人工智能在真正的积木上表现较差，最好的系统也只能做出69%正确的预测。但这个成绩依然足以超过人对相同模拟积木数据的猜测，同时在对真正积木上的预测与人类持平。人工智能在预测没有见过的积木数量上也获得了好成绩。该研究表明了Facebook人工智能更大的梦想。公司的人工智能主管Yann Lecun在与新科学家去年的一次采访中表示，他的目标之一是建立「只需要观察世界」，就可以做出常识性预测的算法。论文摘要：积木是婴儿玩儿的普通玩具，能帮助婴儿动作技巧的发育，获取有关物理行为的直觉。这篇论文中，我们研究了深度前馈模型学习这些直觉物理学的能力。使用3D游戏引擎，我们建造了小型积木塔，稳定性随机而定，可能倒塌（或继续矗立）。这一数据让我们可以训练大型卷积网络模型，它可以准确预测结果以及估测积木轨迹。模型还能以两种方式得以泛化：（1）应用于新的物理场景；（2）真正木块图片，可以获得堪比人类主体的表现成绩。"
"脑科学;;新技术揭示大脑中新生神经元的遗传起源这是一个神经元在诞生后的头几个小时内的所有基因表达情况。每个圆代表着着不同发展阶段（6小时，12小时，24小时），每个圆内的带颜色的点代表着基因表达的水平。我们的大脑是不同类型神经元的居住地，每类神经元都有自己的遗传特征，能够确定它们的功能。这些神经元起源于祖细胞，也就是专门分裂形成神经元的干细胞。如今，来自日内瓦大学医学院的神经科学家们阐明了促使祖细胞分化成神经元的机制。他们开发了一种名叫FlashTag的新颖技术，这种技术可以帮助在他们神经元形成之时就将之分离出来并进行视觉性标注。凭借这种技术，他们破译了神经元构成的基本遗传密码。这一发现于3月3日发表在《科学》上，使我们不仅理解了我们的大脑是如何发育的，而且理解了如何运用这一遗传密码从干细胞入手重构神经元。研究员们将能够更深入地理解像自闭症、精神分裂症等神经系统疾病的根本机制。&nbsp;Denis Jabaudon是日内瓦大学医药学院基础神经科学部门的神经科学家以及日内瓦大学医院（HUG）的神经科医生，他带领的研究员团队研发了一种名为FlashTag的技术，可以将正在形成的神经元视觉化。利用这一方法，在祖细胞进行分裂的时刻，通过荧光标记对它进行标注，并在子代仍能保持存在。科学家能将新形成的神经元视觉化并隔离开来，以便动态观察在这些神经元存活的最初几个小时内，有哪些基因得到表达。随着时间的推移，他们可以研究基因表达的演化和变迁。「之前，我们只有少量的照片来重构神经元的历史，这给我们留下了很多猜测的余地。多亏了FlashTag，现在我们眼前呈现出充足的基因影像资料。从始至终，每一个瞬间都是可见的，这让我们得以理解神经元发育的剧本，明确这场戏剧中的主要角色以及它们的相互作用和动机。」Denis Jabaudon如此解释。科学家研究了老鼠的大脑皮层，已经鉴别出神经元发育过程中的关键基因，并且证明了这些基因表达的动态变化对于大脑的正常发育至关重要。十分精确的、原始的基因之舞的编排原理这一发现，为我们探索神经元形成过程中的原始遗传密码提供了契机，帮助我们了解神经元如何在成人大脑中发挥作用。而这些原始基因中的一部分似乎也涉及到神经发育和神经退化疾病，而这些疾病可能多年后才发生。这表明患病倾向可能在神经元的诞生之初就已露出端倪，而环境因素能影响疾病的后续发展。只有理解了神经元的基因之舞的编排原理，研究者才能探索这些基因从一开始是如何活动的，并且识别出潜在的预示着疾病的异常情况。

在成功解读了这一遗传密码之后，科学家可以改写新生神经元。通过改变特定基因的表达，科学家能促进神经生长，从而改变成长的脚本。有了FlashTag，分离新生神经元和体外重建神经回路成为可能，这使科学家能测试出它们的功能并开发出新的治疗方案。向大众开放的网站日内瓦大学科研团队发布了网站，在网站上能够输入基因的名字，观察到它是如何表达的，以及如何与其它基因相互影响的。「每个研究团队在一段时间内只能聚焦于少数基因，然而我们研究的基因组由接近20000个基因组成。因此我们完全公开了我们的工具，以供其他研究者有效使用。」Denis Jabaudon强调说。"
"神经元;;新技术揭示大脑中新生神经元的遗传起源这是一个神经元在诞生后的头几个小时内的所有基因表达情况。每个圆代表着着不同发展阶段（6小时，12小时，24小时），每个圆内的带颜色的点代表着基因表达的水平。我们的大脑是不同类型神经元的居住地，每类神经元都有自己的遗传特征，能够确定它们的功能。这些神经元起源于祖细胞，也就是专门分裂形成神经元的干细胞。如今，来自日内瓦大学医学院的神经科学家们阐明了促使祖细胞分化成神经元的机制。他们开发了一种名叫FlashTag的新颖技术，这种技术可以帮助在他们神经元形成之时就将之分离出来并进行视觉性标注。凭借这种技术，他们破译了神经元构成的基本遗传密码。这一发现于3月3日发表在《科学》上，使我们不仅理解了我们的大脑是如何发育的，而且理解了如何运用这一遗传密码从干细胞入手重构神经元。研究员们将能够更深入地理解像自闭症、精神分裂症等神经系统疾病的根本机制。&nbsp;Denis Jabaudon是日内瓦大学医药学院基础神经科学部门的神经科学家以及日内瓦大学医院（HUG）的神经科医生，他带领的研究员团队研发了一种名为FlashTag的技术，可以将正在形成的神经元视觉化。利用这一方法，在祖细胞进行分裂的时刻，通过荧光标记对它进行标注，并在子代仍能保持存在。科学家能将新形成的神经元视觉化并隔离开来，以便动态观察在这些神经元存活的最初几个小时内，有哪些基因得到表达。随着时间的推移，他们可以研究基因表达的演化和变迁。「之前，我们只有少量的照片来重构神经元的历史，这给我们留下了很多猜测的余地。多亏了FlashTag，现在我们眼前呈现出充足的基因影像资料。从始至终，每一个瞬间都是可见的，这让我们得以理解神经元发育的剧本，明确这场戏剧中的主要角色以及它们的相互作用和动机。」Denis Jabaudon如此解释。科学家研究了老鼠的大脑皮层，已经鉴别出神经元发育过程中的关键基因，并且证明了这些基因表达的动态变化对于大脑的正常发育至关重要。十分精确的、原始的基因之舞的编排原理这一发现，为我们探索神经元形成过程中的原始遗传密码提供了契机，帮助我们了解神经元如何在成人大脑中发挥作用。而这些原始基因中的一部分似乎也涉及到神经发育和神经退化疾病，而这些疾病可能多年后才发生。这表明患病倾向可能在神经元的诞生之初就已露出端倪，而环境因素能影响疾病的后续发展。只有理解了神经元的基因之舞的编排原理，研究者才能探索这些基因从一开始是如何活动的，并且识别出潜在的预示着疾病的异常情况。

在成功解读了这一遗传密码之后，科学家可以改写新生神经元。通过改变特定基因的表达，科学家能促进神经生长，从而改变成长的脚本。有了FlashTag，分离新生神经元和体外重建神经回路成为可能，这使科学家能测试出它们的功能并开发出新的治疗方案。向大众开放的网站日内瓦大学科研团队发布了网站，在网站上能够输入基因的名字，观察到它是如何表达的，以及如何与其它基因相互影响的。「每个研究团队在一段时间内只能聚焦于少数基因，然而我们研究的基因组由接近20000个基因组成。因此我们完全公开了我们的工具，以供其他研究者有效使用。」Denis Jabaudon强调说。"
"nan;;【日报】谷歌展示像儿童一样学习的机器臂Google展示了像儿童一样学习的机器臂、GNU项目发布Gneural Network神经网络软件包、 6个微型机器人能拉动近2吨重汽车、英国政府将在 2017年 允许无人驾驶汽车上高速公路测试……机器之心日报，精选一天前沿科技优质内容。Google展示了像儿童一样学习的机器臂Google的研究者今日发布了一篇报告，报告显示了科学家如何利用“卷积神经网络”来让14台机械臂相互学习如何拿起小物件。这个新方法展示了如何通过手眼协调能力来反复试验机器人学习执行任务，和1到4岁的儿童通过观察别人行为来学习一样。这个试验方法的意义在于，今后机器在遇到从没见过物体的时候，机器不需要人类调整程序，自己会找到取物的方法。AlphaGo也基于此原理。

据介绍，研究者每天训练机器人从盒子里取出物品这个动作，经过约80万次的试验后，他们观察到机器臂出现反应性动作。慢慢地，他们变得更擅于收拾物品，并且无需输入新的程序后就能够自动调整自身以适应新的任务。这样一来，机器人与人类之间的感觉运动技能差距就进一步缩小了。

外媒因而表示，此前谈论机器人替代人类这个话题的时候，我们也许会觉得人类依旧占据上风，因为我们才是那个创造机器人的角色。但如今看来，“奇点已然到来。”至少我们可以承认，奇点正在临近。GNU项目发布Gneural Network神经网络软件包GNU项目发布了神经网络软件包Gneural Network，一个重要动机是避免人工智能方面的计算机软件被大企业所垄断。 Google的AlphaGo和IBM的Watson展示了运用人工智能所取得的非凡成就，但GNU开发者认为只有大企业和实验室能访问这些技术代表着一 种危险，因为垄断会放慢科技的进步。

开发者Jean Michel Sellier因此在GPL许可证下开发了Gneural Network，目前版本还是v0.0.1。当然人工智能领域有很多开源的软件包，其中包括AlphaGo使用的软件，如Caffe、Theano、Torch 、TensorFlow、CNTK，等等。团结就是力量 6个微型机器人能拉动近2吨重汽车据《纽约时报》网络版报道，总重量为3.5盎司(99克)的6个微型机器人能拉动重3900磅(1769千克)的汽车。斯坦福大学仿生学和灵巧操作实验室研究人员从蚂蚁通过团队合作搬运重物中获得了灵感。不过，他们的灵感不仅仅来自自然界，电影《超能陆战队》(Big Hero 6)展示了大量微型机器人的威力。研究人员发现，每只蚂蚁同时使用6条腿中的3条腿，蚂蚁“团队”能产生巨大的合力。研究团队成员大卫·克里斯滕森(David Christensen)说，“通过考虑整个团队的动态，而非仅仅考虑个体，我们能够打造一支‘microTug’机器人团队，每个机器人都具有超强力量，而且它们能组成团队去完成任务。”

克里斯滕森称，6个microTug机器人拉动3900磅重的汽车，相当于一支6个人的团队搬动埃菲尔铁塔和3座自由女神像。英国政府将在 2017年 允许无人驾驶汽车上高速公路测试近日，英国政府表示将于今年在英国当地道路上测试无人驾驶汽车，2017年 在高速公路上测试无人驾驶汽车，并计划到 2020年 实现无人驾驶汽车在全英国范围内的普及。

不过英国交通部此前曾强调，在英国境内测试的无人驾驶汽车不能是完全无人驾驶的汽车，而是在必要时人可以介入控制的汽车。

虽然 Google 一直在致力于研发完全无人驾驶的汽车，但无人驾驶测试项目得到政府支持显然是 Google 求之不得的，英国市场也将是 Google 的一个新增长点。适应当地法规以获得新的测试场地和经验累积，是 Google 以及其他大大小小公司不能拒绝的机会。

英国财政部也表现出全力扫清法律障碍的热情，英国财政大臣 George Osborne 表示，“测试才能让汽车安全得到保障，这是英国政府支持无人驾驶汽车测试的初衷。” 另外，他还表示，“会提出议案消除无人驾驶汽车上路测试的障碍。”

英国政府希望藉此提升英国就业率，英国政府预计无人驾驶汽车的全球市场的近期市场份额是 1.29 万亿美元。

此前在一月份，无人驾驶汽车项目联合会曾宣布在伦敦希思罗机场附近进行为期三个月的实际道路测试，测试地点包括格林尼治市住宅区，北格林尼治地铁站和其他标志性场所。NASA 测试下一代火箭发动机，将用于送人类去火星据TC，NASA 最近成功对下一代重型火箭 SLS 的发动机 RS-25 进行了功能验证测试，测试持续了 500 秒。此前该发动机已经通过点火测试。SLS（Space Launch System）将使用 4 个 RS-25 发动机，计划将人类送往外太空，例如火星。本次测试的 RS-25 发动机正是此前航天飞机的主发动机。航天飞机项目终止后，还剩下 16 个 RS-25 发动机。Aerojet Rocketdyne 根据 SLS 的要求，把 RS-25 发动机做了对应优化，提高了最大推力。本次测试正式为了验证改进后是否满足 SLS 飞行要求。用于航天飞机时，RS-25 还会被回收重复使用，用于 SLS，这些发动机将不会被回收。

SLS 项目由 NASA 的马歇尔空间飞行中心负责，本次发动机测试在 NASA 密西西比的 Stennis 空间中心进行，SLS 火箭将会携带一个 Orion 太空舱，装载最多 6 名宇航员，最终 SLS 将在佛罗里达的肯尼迪空间中心发射。首次不载人发射测试预计在 2018年 进行。超级高铁将采用增强现实车窗前不久，美国超级高铁公司Hyperloop Transportation Technologies(以下简称Hyperloop)表示，该公司与斯洛伐克政府签订协议，考虑在该国建设超级高铁。这意味着，斯洛伐克或将会成为首个拥有Hyperloop超级高铁的国家。这则消息让传说般的Hyperloop走进现实，不过让其更为现实的是更多细节。在近日的西南偏南(South by Southwest, SXSW)音乐电影节上，Hyperloop的CEO Dirk Alhborn提出AR(Augmented Reality,增强现实)车窗概念。

Alhborn把这个概念称为“Augmented Windows”，它不仅能把车窗外的现实世界展示出来，还可以在这个基础上增加具有娱乐属性的数字信息，让乘客在旅途中充满欢乐。虽然这个想法Alhborn在很多场合中提出，但这次描述最为详细而且还推出一段视频。

他表示，车窗屏幕采用眼神追踪技术，在人眼注视的地方显示出相应的数字信息。而目前，Hyperloop正在研究不同人注视同一车窗的姿态。

Alhborn希望这项技术可以为公司创造广告收入。“从心理角度说，人们经常会在旅程中望着窗外，这是一种经历。试想一下，你可以在望着车窗的时候看到虚拟世界，比如侏罗纪公园、终结者等，会不会感到十分有趣？”，他说。欧俄火星探测器将启程 探测火星生命迹象欧洲和俄罗斯定于14日正式启动名为“火星太空生物”的合作项目，发射一个轨道飞行器，寻找火星过去或现在的生命迹象。轨道飞行器将在火星大气中寻找可能表明微生物存在的甲烷和其他气体。由地球和火星运行轨道等因素决定，今年3月会出现一个发射火星探测器的窗口期，为火星探测创造了条件。利用这个窗口期，欧俄联手制造的“追踪气体轨道飞行器”将于14日在哈萨克斯坦境内的拜科努尔发射场发射升空。

这一轨道飞行器配有全套高科技设备，预计将于今年10月19日飞抵火星，行程长达4.96亿公里。它的主要任务是为这颗红色星球拍照，分析其大气层成分。

欧洲航天局11日在社交网站上说：“火箭登场——我们的‘火星太空生物2016’项目已在发射坪上。”

作为欧洲航天局和俄罗斯联邦航天署的合作项目，“火星太空生物”分为两个阶段，发射轨道飞行器是第一个阶段。项目的第二阶段涉及在2018年发射一个火星漫游器，2019年着陆。漫游器将在这颗红色星球的表面行驶以寻找有机物：它将钻到火星表层之下两米取样并进行现场分析。但由于资金问题，第二阶段很可能要延期两年实施。科学家研发新材料：可随时改变形状大小硬度北京时间3月14日消息，科学家近日研制出了一种能够改变形状和大小的新型材料。动画显示了该材料的模块单元在气动传输器作用下的变形过程。
该材料由若干个单独的模块构成，每个模块包含6个开口的正方体，在气动传输器的作用下进行变形。研究人员将64个独立单元组合成一个4x4x4的结构，它的体积可以忽大忽小，可以改变形状，还能忽然变成一张平平的薄片。在它形状改变的同时，该材料的硬度也会发生改变。这意味着它可以用来制造一种独特的材料，处于某个形状时容易变形，处于另一个形状时则坚硬无比。人工智能取代人类？韩国写稿机器人上岗环球科技3月14日报道，最近，人工智能与人类的围棋大战引起了全世界的关注。在Google人工智能AlphaGo连续拿下三局胜利之后，韩国棋手李世石于昨日使出“神来一手”，终于赢得了胜利，为人类赢回了尊严。

而随着“人机大战”的白热化，人工智能取代人类的担忧也再一次被提及。继美国《纽约时报》与中国新华、腾讯之后，韩国《金融新闻》编辑部日前也正式启用了一名人工智能记者。

据悉，这台电脑安装了人工智能记者程序，每天股市收盘时，它便基于韩国证券交易所的数据，0.3秒就可写出一篇股市行情的新闻报道。而且据调查显示，一半以上的读者看后分不清到底是不是人写的。更重要的是不仅是写稿快，人工智能记者只需首次设置费用，随后运营的费用接近于0。

韩国《经济新闻》编辑部主编严虎动表示，启用人工智能记者是为了将记者从复杂的重复化的劳动中解脱出来，促使他们向深度调查记者转变。"
"谷歌;;这一次，谷歌把数据中心的解决方案开源了如今，这个星球上最具创新性的公司都在将「他们成功的钥匙交出去」，那就是开源。据《连线》杂志报道，谷歌日前宣布，正式加入开放计算项目（Open Compute Project），通过这个项目，将其服务器和数据中心的解决方案开源。谷歌加入开放计算项目开放计算项目是由Facebook在2011年创建，其背景是随着Facebook业务的扩大，过去的数据中心、服务器解决方案无法满足其需求，而且定制成本高昂，包括谷歌、Facebook在内的互联网公司需要更廉价、高效以及可扩展性的硬件资源，因此，他们在幕后悄悄地从头开始设计硬件，并将硬件的制造外包给亚洲的鲜为人知的公司。&nbsp;这个潜在的硬件市场很少得到公开讨论。像谷歌这样的公司就将其数据中心解决方案作为公司竞争的优势，一度处于高级保密阶段。Facebook技术业务副总裁 Heiliger表示：五年前的数据中心领域就像一个「搏击俱乐部」。「是时候停止像对待《搏击俱乐部》一样对待数据中心设计方案了，也是时候把这些方法去神秘化了。 Heiliger 说道。在Facebook的努力下，开放计算项目得到包括惠普、戴尔、微软等公司的支持，而最后的两家巨头就是谷歌和亚马逊。此次谷歌的加入，被业界认为是谷歌业务战略的一大挑战，对此谷歌资深员工Urs Hölzle 告诉《连线》杂志，他无法认同业界将此举定义「一个重大转变」，他指出谷歌之前就已经公开讨论过它的内部硬件设计方案。「我知道新闻界过去倾向于提出这件事，把开放计算项目和谷歌对立起来。但事实从来不是这样。」他说，「在过去十年里，我们已经分享了行业内许许多多的事情。这是最近的一件事。诚然，谷歌在2009年揭示了它的服务器设计方案的一部分，而且，去年，它撩起窗帘，展示了处理计算机网络硬件的重要方法。但是，谷歌只是在转移设备后才揭示它的设计方案。并且它没有像脸书那样开放设备资源。不过谷歌和脸书最近积极合作，合作内容涉及他们意欲公开源代码的硬件，这将是两家公司优先发展的亮点。不过，谷歌的举动至少也从另一个侧面反映了互联网大玩家们内部的其它变化。《连线》杂志指出，谷歌加入 Facebook 的这个项目与深度学习的崛起有关联，这一人工智能技术迅速地重塑了现代社会的很多方面。两家公司都明白人工智能是他们未来发展的关键部分，他们都相信如果他们合作并分享驱动神经网络的一些核心技术，就能尽快达到目标。Hölzle 介绍了谷歌的计划，他们将和 Facebook 共同开发数据中心服务器架构。这个新的支架能为所有机器传送大约4倍的电力，从12伏到48伏。 Hölzle 表示，随着我们将越来越多的硬件打包装进越来越小的空间，数据中心的架构需要越来越多的能源，这种需要不仅随着数据中心内部 GPUs 的增加而增加，也随着深度神经网络越来越重要而增加。&nbsp;GPUs 最初被设计用于为游戏或其它需要密集图像的程序应用提供效果图。但是结果呢，它们也能很好地适用于操作深度神经网络，这种人工智能技术如今帮助向谷歌这样的公司辨认图象、识别输入智能手机里的语音命令、有针对地投放广告、生成研究结果和完成其它更多事情。 Hölzle 透露：「整个性能都在不断提高， GPUs加快或者说放大了这个过程。」为什么开源？从技术发展的趋势来看，开源日渐成为一股不可阻挡的趋势。作为美国国防部的一个研究机构，很难想象 DARPA 这样的组织竟不在意别人利用自己公开的信息。然而，DARPA 已经向开源机器学习技术迈出了一大步。事实上，DARPA XDATA 项目导致产生一个目前最先进的机器学习、可视化和其他技术的目录，任何人都可以下载、使用和修改这些技术以打造定制化的人工智能工具。DARPA 和国防部如此支持开源的事实有力地表明开源的优点大于将高质量的工具提供给潜在对手的缺点。&nbsp;另一个开源项目则是 OpenAI 项目，该项目最近由技术企业家 Elon Musk 和 Sam Altman 等人发起，这项工作的目的是研究具有越来越强的理解世界和与世界交互的能力的机器的创造与发布背后的伦理道德。&nbsp;DARPA 和 OpenAI 的动机都不能解释到底为什么这些商业技术公司要开源他们的人工智能代码。毕竟，作为技术公司，他们关注的问题更加直接和具体。毕竟如果没人使用他们的产品，那好而整洁的代码和用心良苦的算法又有什么用呢？&nbsp;业内存在一个共识，即谷歌、Facebook 和亚马逊这样的公司的业务模式和人们所想的并不一样。从长远来看，谷歌和Facebook都没有真正的广告销售业务。这些技术公司都是由你的眼球(和数据)驱动的。他们的通货是用户。以谷歌为例，免费提供电子邮箱和搜索服务将用户吸引到它的产品上；它需要快速创新、产出更多更好地产品以确保用户留存下来。对于 TensorFlow 为何要开源，谷歌官方的解释是，将技术免费开放是希望可以加速人工智能领域的发展。所有人都可以帮助 Google 改进其技术，并将成果反馈回来。正如 Google 深度学习项目的主要推动者 Jeff Dean 所说：「我们希望的是，整个研究、开发者社区将 TensorFlow 作为一种很好的手段来实现各种各样的机器学习算法，同时也为其在各种场景下的应用带来改进。」如果此次开源能够使更多的数据科学家开始使用谷歌的系统来从事机器学习方面的研究，那么这将有利于谷歌对日益发展的机器学习行业拥有更多的主导权。谷歌敢于开放 Tensor Flow 的代码，是因为它所拥有的数据对于建造一个强力的人工智能引擎更具价值。该公司希望开源能将其打造成机器学习领域的领先者，并发展与开发者和合作伙伴的关系。Tensor Flow「从某种程度上给了我们一个共同说话的语言。」&nbsp;艾伦人工智能研究所执行董事 Oren Etzioni 对谷歌的这一行为评价道，这是谷歌整个平台战略的一部分，来吸引开发者和机器学习人才。但比起提供云服务的 IBM、微软和亚马逊，谷歌确实在做一些更加开放的工作。开源人工智能的举措能够保证这些公司在前沿技术领域保持自己的领先地位。从这个意义上看，它们并没有交出自己成功的钥匙，而只是在给自己的未来铺路。当然，科技巨头将深度学习平台也势必会带来更多的商业利益，Jeff Dean 说：「我们从使用过 Tensor Flow 的开发者们身上获取益处，这并不是纯粹的无私行为。」，MIT 斯隆管理学院的教授 Michael A. Cusumano 就认为，即便 TensorFlow 是开源，但如果它能获得成功，将毫无疑问成为谷歌的赚钱机器。&nbsp;这些公司开源它们的人工智能软件是因为它们希望成为其他人创新的基础。成功的企业可以借此壮大，而这些科技公司也可以将它们整合到自己的产品集群中。人工智能是其中的核心，因为通过设计，它可以学习、适应甚至决策。人工智能不只是一种产品：它是一个产品生成器。在不远的未来，人工智能并不会被直接用来提供图像服务或消费类产品，但会通过创新新产品，帮助企业找到新的创新机会。开源人工智能的举措能够保证这些公司在前沿技术领域保持自己的领先地位。从这个意义上看，它们并没有交出自己成功的钥匙，而只是在给自己的未来铺路。科技巨头的开源竞赛正式因为开源所带来的各种价值，谷歌、Facebook等科技巨头也开始了激烈的开源竞赛。谷歌开源了TensorFlow ，Facebook 紧接着开源人工智能硬件 Big Sur，之后IBM、百度和雅虎也相继加入。1）谷歌开源 TensorFlow2015年12月，谷歌开源了第二代深度学习系统 TensorFlow，该系统将机器学习算法变成了符号表达的各类图表，从而有效缩短了重新写代码的时间。谷歌在官方博客上表示，比起旧系统，TensorFlow 没有被束缚在谷歌自身的IT架构内，能够被任何有相关背景的人基于合适的IT资源进行配置。它更快、更灵活以及更聪明，在建立和训练机器学习模型方面比第一代人工智能系统快五倍。谷歌 CEO Sundar Pichai 在博客中写到，TensorFlow更快的速度使我们能够更快的提升产品表现。&nbsp;当然，谷歌也并非完全毫无保留。目前开源的是其引擎中较为顶层的算法，也没有开源其硬件基础设施系统。而且，谷歌也不是第一个将深度学习系统开源的科技巨头。2）Torch和硬件Facebook开源TensorFlow之后，Yann LeCun在Facebook上转了一篇纽约时报Bits报道TensorFlow的文章，并评论说：「如果放在几年前，谁会想到一篇关于深度学习开源库的文章会发布在纽约时报科技频道（Bits）上？」补充一下 (以便大家不要误解我的含义)： 我认为TensorFlow 非常酷，我对谷歌的朋友们将其开源表深表赞同。&nbsp;其实，Yann LeCun是在非常狡猾的提醒用户，Facebook早在今年一月份就公布了一个机器学习的开源项目，他们将一些基于机器神经网络的产品免费放在了Torch（一个关注深度学习的开源软件项目）上，可以用来处理数据，分析信息的共同特征。Facebook人工智能实验室的研发工程师Soumith Chintala对此表示，将人工智能和神经网络公开是十分有用的，他也是Torch项目的创始人之一。他说，除了大公司之外，Torch也会用于创业公司和大学实验室。2015年12月，Facebook开始为他们的人工智能工作建造定制化的服务器，并在周四宣布将向全世界公布这个强大硬件的设计——而且是免费。这个服务器设计蓝图的开源计划名为「大索尔（Big Sur）」。其他公司和研究者将能从Facebook开发者的研究进展中获利。上个月，谷歌曾发布了构建AI的软件系统TensorFlow。微软、IBM和三星也都发布了自己的软件工具。Big Sur服务器是围绕英伟达的GPU（图形处理单元）建造的。GPU在人工智能中的应用十分广泛，因为这种芯片上搭载的处理核心数量多于英特尔生产的传统处理器，使得它们十分适用于AI软件所需要的海量计算。这个硬件设计将作为开放计算项目（OCP，Open Compute Project）的一部分。高盛投资公司说，他们在2012年使用了OCP的设计，节省的计算支出多达30%。2014年1月，扎克伯格说这个系统的使用为Facebook节省了12亿美元。3）IBM开源机器学习平台2015年11与，IBM周一宣布旗下机器学习平台 SystemML正式开源，成为Apache孵化器下面的一个开源项目。根据IBM官方的说法，SystemML使用 Java编译， 能够实现以下三点：(1) 可定制算法；(2) 多个执行模式，包括单个，Hadoop 批量和 Spark 批量；(3) 自动优化。&nbsp;Apache孵化器是Apache基金会成立于2002年10月，为那些意图成为Apache基金会努力的一部分的项目和代码库，提供一个进入到Apache软件基金会的路径。那些从外部组织捐赠的所有代码，以及意图移动到Apache的现有外部项目，都必须进入Apache孵化器。IBM表示，将在6月份捐献SystemML代码。从某种意义上说，IBM此举，也是为了抢占机器学习领域的话语权。各大巨头希望通过吸引越来越多开发者参与到自己平台上，鼓励他们使用自己的平台进行数据训练，随着训练数据越来越多，机器也会变得越来越聪明，这也有利于形成良好的生态循环。4）百度开源人工智能代码2016年1月5号，百度本周宣布开源人工智能代码，从而在人工智能技术的标准发展中掌握一定的主动权。此前，谷歌和Facebook也宣布将开源相关技术。百度硅谷实验室已经向GitHub上传了Warp-CTC C代码库。与此同时，百度在一篇博客文章中鼓励开发者试用这些代码。5）雅虎开源 CaffeOnSpark 深度学习软件2015年3月，雅虎的 Big ML 团队成员 Andy Feng, Jun Shi 以及 Mridul Jain 在他们的博客中说道：CaffeOnSpark 这一深学习系统,现在已经可以通过开源社区获取并且进行进一步的开发了。

CaffeOnSpark 是一Hadoop/Spark 的分布式学习系统，基于Apache Spark 开源集群计算框架。正是这个深度学习系统支持着雅虎 Flickr 网站的图像功能，Yahoo 就是用这项技术来识别照片中的不同内容，以此改良 Flickr 网站的搜索结果。而现在，雅虎正式将这一系统开源。这个系统提供了很多数据分类和数据处理的方法，对于开发者来说，无疑又是一个好消息。"
"Facebook;;这一次，谷歌把数据中心的解决方案开源了如今，这个星球上最具创新性的公司都在将「他们成功的钥匙交出去」，那就是开源。据《连线》杂志报道，谷歌日前宣布，正式加入开放计算项目（Open Compute Project），通过这个项目，将其服务器和数据中心的解决方案开源。谷歌加入开放计算项目开放计算项目是由Facebook在2011年创建，其背景是随着Facebook业务的扩大，过去的数据中心、服务器解决方案无法满足其需求，而且定制成本高昂，包括谷歌、Facebook在内的互联网公司需要更廉价、高效以及可扩展性的硬件资源，因此，他们在幕后悄悄地从头开始设计硬件，并将硬件的制造外包给亚洲的鲜为人知的公司。&nbsp;这个潜在的硬件市场很少得到公开讨论。像谷歌这样的公司就将其数据中心解决方案作为公司竞争的优势，一度处于高级保密阶段。Facebook技术业务副总裁 Heiliger表示：五年前的数据中心领域就像一个「搏击俱乐部」。「是时候停止像对待《搏击俱乐部》一样对待数据中心设计方案了，也是时候把这些方法去神秘化了。 Heiliger 说道。在Facebook的努力下，开放计算项目得到包括惠普、戴尔、微软等公司的支持，而最后的两家巨头就是谷歌和亚马逊。此次谷歌的加入，被业界认为是谷歌业务战略的一大挑战，对此谷歌资深员工Urs Hölzle 告诉《连线》杂志，他无法认同业界将此举定义「一个重大转变」，他指出谷歌之前就已经公开讨论过它的内部硬件设计方案。「我知道新闻界过去倾向于提出这件事，把开放计算项目和谷歌对立起来。但事实从来不是这样。」他说，「在过去十年里，我们已经分享了行业内许许多多的事情。这是最近的一件事。诚然，谷歌在2009年揭示了它的服务器设计方案的一部分，而且，去年，它撩起窗帘，展示了处理计算机网络硬件的重要方法。但是，谷歌只是在转移设备后才揭示它的设计方案。并且它没有像脸书那样开放设备资源。不过谷歌和脸书最近积极合作，合作内容涉及他们意欲公开源代码的硬件，这将是两家公司优先发展的亮点。不过，谷歌的举动至少也从另一个侧面反映了互联网大玩家们内部的其它变化。《连线》杂志指出，谷歌加入 Facebook 的这个项目与深度学习的崛起有关联，这一人工智能技术迅速地重塑了现代社会的很多方面。两家公司都明白人工智能是他们未来发展的关键部分，他们都相信如果他们合作并分享驱动神经网络的一些核心技术，就能尽快达到目标。Hölzle 介绍了谷歌的计划，他们将和 Facebook 共同开发数据中心服务器架构。这个新的支架能为所有机器传送大约4倍的电力，从12伏到48伏。 Hölzle 表示，随着我们将越来越多的硬件打包装进越来越小的空间，数据中心的架构需要越来越多的能源，这种需要不仅随着数据中心内部 GPUs 的增加而增加，也随着深度神经网络越来越重要而增加。&nbsp;GPUs 最初被设计用于为游戏或其它需要密集图像的程序应用提供效果图。但是结果呢，它们也能很好地适用于操作深度神经网络，这种人工智能技术如今帮助向谷歌这样的公司辨认图象、识别输入智能手机里的语音命令、有针对地投放广告、生成研究结果和完成其它更多事情。 Hölzle 透露：「整个性能都在不断提高， GPUs加快或者说放大了这个过程。」为什么开源？从技术发展的趋势来看，开源日渐成为一股不可阻挡的趋势。作为美国国防部的一个研究机构，很难想象 DARPA 这样的组织竟不在意别人利用自己公开的信息。然而，DARPA 已经向开源机器学习技术迈出了一大步。事实上，DARPA XDATA 项目导致产生一个目前最先进的机器学习、可视化和其他技术的目录，任何人都可以下载、使用和修改这些技术以打造定制化的人工智能工具。DARPA 和国防部如此支持开源的事实有力地表明开源的优点大于将高质量的工具提供给潜在对手的缺点。&nbsp;另一个开源项目则是 OpenAI 项目，该项目最近由技术企业家 Elon Musk 和 Sam Altman 等人发起，这项工作的目的是研究具有越来越强的理解世界和与世界交互的能力的机器的创造与发布背后的伦理道德。&nbsp;DARPA 和 OpenAI 的动机都不能解释到底为什么这些商业技术公司要开源他们的人工智能代码。毕竟，作为技术公司，他们关注的问题更加直接和具体。毕竟如果没人使用他们的产品，那好而整洁的代码和用心良苦的算法又有什么用呢？&nbsp;业内存在一个共识，即谷歌、Facebook 和亚马逊这样的公司的业务模式和人们所想的并不一样。从长远来看，谷歌和Facebook都没有真正的广告销售业务。这些技术公司都是由你的眼球(和数据)驱动的。他们的通货是用户。以谷歌为例，免费提供电子邮箱和搜索服务将用户吸引到它的产品上；它需要快速创新、产出更多更好地产品以确保用户留存下来。对于 TensorFlow 为何要开源，谷歌官方的解释是，将技术免费开放是希望可以加速人工智能领域的发展。所有人都可以帮助 Google 改进其技术，并将成果反馈回来。正如 Google 深度学习项目的主要推动者 Jeff Dean 所说：「我们希望的是，整个研究、开发者社区将 TensorFlow 作为一种很好的手段来实现各种各样的机器学习算法，同时也为其在各种场景下的应用带来改进。」如果此次开源能够使更多的数据科学家开始使用谷歌的系统来从事机器学习方面的研究，那么这将有利于谷歌对日益发展的机器学习行业拥有更多的主导权。谷歌敢于开放 Tensor Flow 的代码，是因为它所拥有的数据对于建造一个强力的人工智能引擎更具价值。该公司希望开源能将其打造成机器学习领域的领先者，并发展与开发者和合作伙伴的关系。Tensor Flow「从某种程度上给了我们一个共同说话的语言。」&nbsp;艾伦人工智能研究所执行董事 Oren Etzioni 对谷歌的这一行为评价道，这是谷歌整个平台战略的一部分，来吸引开发者和机器学习人才。但比起提供云服务的 IBM、微软和亚马逊，谷歌确实在做一些更加开放的工作。开源人工智能的举措能够保证这些公司在前沿技术领域保持自己的领先地位。从这个意义上看，它们并没有交出自己成功的钥匙，而只是在给自己的未来铺路。当然，科技巨头将深度学习平台也势必会带来更多的商业利益，Jeff Dean 说：「我们从使用过 Tensor Flow 的开发者们身上获取益处，这并不是纯粹的无私行为。」，MIT 斯隆管理学院的教授 Michael A. Cusumano 就认为，即便 TensorFlow 是开源，但如果它能获得成功，将毫无疑问成为谷歌的赚钱机器。&nbsp;这些公司开源它们的人工智能软件是因为它们希望成为其他人创新的基础。成功的企业可以借此壮大，而这些科技公司也可以将它们整合到自己的产品集群中。人工智能是其中的核心，因为通过设计，它可以学习、适应甚至决策。人工智能不只是一种产品：它是一个产品生成器。在不远的未来，人工智能并不会被直接用来提供图像服务或消费类产品，但会通过创新新产品，帮助企业找到新的创新机会。开源人工智能的举措能够保证这些公司在前沿技术领域保持自己的领先地位。从这个意义上看，它们并没有交出自己成功的钥匙，而只是在给自己的未来铺路。科技巨头的开源竞赛正式因为开源所带来的各种价值，谷歌、Facebook等科技巨头也开始了激烈的开源竞赛。谷歌开源了TensorFlow ，Facebook 紧接着开源人工智能硬件 Big Sur，之后IBM、百度和雅虎也相继加入。1）谷歌开源 TensorFlow2015年12月，谷歌开源了第二代深度学习系统 TensorFlow，该系统将机器学习算法变成了符号表达的各类图表，从而有效缩短了重新写代码的时间。谷歌在官方博客上表示，比起旧系统，TensorFlow 没有被束缚在谷歌自身的IT架构内，能够被任何有相关背景的人基于合适的IT资源进行配置。它更快、更灵活以及更聪明，在建立和训练机器学习模型方面比第一代人工智能系统快五倍。谷歌 CEO Sundar Pichai 在博客中写到，TensorFlow更快的速度使我们能够更快的提升产品表现。&nbsp;当然，谷歌也并非完全毫无保留。目前开源的是其引擎中较为顶层的算法，也没有开源其硬件基础设施系统。而且，谷歌也不是第一个将深度学习系统开源的科技巨头。2）Torch和硬件Facebook开源TensorFlow之后，Yann LeCun在Facebook上转了一篇纽约时报Bits报道TensorFlow的文章，并评论说：「如果放在几年前，谁会想到一篇关于深度学习开源库的文章会发布在纽约时报科技频道（Bits）上？」补充一下 (以便大家不要误解我的含义)： 我认为TensorFlow 非常酷，我对谷歌的朋友们将其开源表深表赞同。&nbsp;其实，Yann LeCun是在非常狡猾的提醒用户，Facebook早在今年一月份就公布了一个机器学习的开源项目，他们将一些基于机器神经网络的产品免费放在了Torch（一个关注深度学习的开源软件项目）上，可以用来处理数据，分析信息的共同特征。Facebook人工智能实验室的研发工程师Soumith Chintala对此表示，将人工智能和神经网络公开是十分有用的，他也是Torch项目的创始人之一。他说，除了大公司之外，Torch也会用于创业公司和大学实验室。2015年12月，Facebook开始为他们的人工智能工作建造定制化的服务器，并在周四宣布将向全世界公布这个强大硬件的设计——而且是免费。这个服务器设计蓝图的开源计划名为「大索尔（Big Sur）」。其他公司和研究者将能从Facebook开发者的研究进展中获利。上个月，谷歌曾发布了构建AI的软件系统TensorFlow。微软、IBM和三星也都发布了自己的软件工具。Big Sur服务器是围绕英伟达的GPU（图形处理单元）建造的。GPU在人工智能中的应用十分广泛，因为这种芯片上搭载的处理核心数量多于英特尔生产的传统处理器，使得它们十分适用于AI软件所需要的海量计算。这个硬件设计将作为开放计算项目（OCP，Open Compute Project）的一部分。高盛投资公司说，他们在2012年使用了OCP的设计，节省的计算支出多达30%。2014年1月，扎克伯格说这个系统的使用为Facebook节省了12亿美元。3）IBM开源机器学习平台2015年11与，IBM周一宣布旗下机器学习平台 SystemML正式开源，成为Apache孵化器下面的一个开源项目。根据IBM官方的说法，SystemML使用 Java编译， 能够实现以下三点：(1) 可定制算法；(2) 多个执行模式，包括单个，Hadoop 批量和 Spark 批量；(3) 自动优化。&nbsp;Apache孵化器是Apache基金会成立于2002年10月，为那些意图成为Apache基金会努力的一部分的项目和代码库，提供一个进入到Apache软件基金会的路径。那些从外部组织捐赠的所有代码，以及意图移动到Apache的现有外部项目，都必须进入Apache孵化器。IBM表示，将在6月份捐献SystemML代码。从某种意义上说，IBM此举，也是为了抢占机器学习领域的话语权。各大巨头希望通过吸引越来越多开发者参与到自己平台上，鼓励他们使用自己的平台进行数据训练，随着训练数据越来越多，机器也会变得越来越聪明，这也有利于形成良好的生态循环。4）百度开源人工智能代码2016年1月5号，百度本周宣布开源人工智能代码，从而在人工智能技术的标准发展中掌握一定的主动权。此前，谷歌和Facebook也宣布将开源相关技术。百度硅谷实验室已经向GitHub上传了Warp-CTC C代码库。与此同时，百度在一篇博客文章中鼓励开发者试用这些代码。5）雅虎开源 CaffeOnSpark 深度学习软件2015年3月，雅虎的 Big ML 团队成员 Andy Feng, Jun Shi 以及 Mridul Jain 在他们的博客中说道：CaffeOnSpark 这一深学习系统,现在已经可以通过开源社区获取并且进行进一步的开发了。

CaffeOnSpark 是一Hadoop/Spark 的分布式学习系统，基于Apache Spark 开源集群计算框架。正是这个深度学习系统支持着雅虎 Flickr 网站的图像功能，Yahoo 就是用这项技术来识别照片中的不同内容，以此改良 Flickr 网站的搜索结果。而现在，雅虎正式将这一系统开源。这个系统提供了很多数据分类和数据处理的方法，对于开发者来说，无疑又是一个好消息。"
"开源;;这一次，谷歌把数据中心的解决方案开源了如今，这个星球上最具创新性的公司都在将「他们成功的钥匙交出去」，那就是开源。据《连线》杂志报道，谷歌日前宣布，正式加入开放计算项目（Open Compute Project），通过这个项目，将其服务器和数据中心的解决方案开源。谷歌加入开放计算项目开放计算项目是由Facebook在2011年创建，其背景是随着Facebook业务的扩大，过去的数据中心、服务器解决方案无法满足其需求，而且定制成本高昂，包括谷歌、Facebook在内的互联网公司需要更廉价、高效以及可扩展性的硬件资源，因此，他们在幕后悄悄地从头开始设计硬件，并将硬件的制造外包给亚洲的鲜为人知的公司。&nbsp;这个潜在的硬件市场很少得到公开讨论。像谷歌这样的公司就将其数据中心解决方案作为公司竞争的优势，一度处于高级保密阶段。Facebook技术业务副总裁 Heiliger表示：五年前的数据中心领域就像一个「搏击俱乐部」。「是时候停止像对待《搏击俱乐部》一样对待数据中心设计方案了，也是时候把这些方法去神秘化了。 Heiliger 说道。在Facebook的努力下，开放计算项目得到包括惠普、戴尔、微软等公司的支持，而最后的两家巨头就是谷歌和亚马逊。此次谷歌的加入，被业界认为是谷歌业务战略的一大挑战，对此谷歌资深员工Urs Hölzle 告诉《连线》杂志，他无法认同业界将此举定义「一个重大转变」，他指出谷歌之前就已经公开讨论过它的内部硬件设计方案。「我知道新闻界过去倾向于提出这件事，把开放计算项目和谷歌对立起来。但事实从来不是这样。」他说，「在过去十年里，我们已经分享了行业内许许多多的事情。这是最近的一件事。诚然，谷歌在2009年揭示了它的服务器设计方案的一部分，而且，去年，它撩起窗帘，展示了处理计算机网络硬件的重要方法。但是，谷歌只是在转移设备后才揭示它的设计方案。并且它没有像脸书那样开放设备资源。不过谷歌和脸书最近积极合作，合作内容涉及他们意欲公开源代码的硬件，这将是两家公司优先发展的亮点。不过，谷歌的举动至少也从另一个侧面反映了互联网大玩家们内部的其它变化。《连线》杂志指出，谷歌加入 Facebook 的这个项目与深度学习的崛起有关联，这一人工智能技术迅速地重塑了现代社会的很多方面。两家公司都明白人工智能是他们未来发展的关键部分，他们都相信如果他们合作并分享驱动神经网络的一些核心技术，就能尽快达到目标。Hölzle 介绍了谷歌的计划，他们将和 Facebook 共同开发数据中心服务器架构。这个新的支架能为所有机器传送大约4倍的电力，从12伏到48伏。 Hölzle 表示，随着我们将越来越多的硬件打包装进越来越小的空间，数据中心的架构需要越来越多的能源，这种需要不仅随着数据中心内部 GPUs 的增加而增加，也随着深度神经网络越来越重要而增加。&nbsp;GPUs 最初被设计用于为游戏或其它需要密集图像的程序应用提供效果图。但是结果呢，它们也能很好地适用于操作深度神经网络，这种人工智能技术如今帮助向谷歌这样的公司辨认图象、识别输入智能手机里的语音命令、有针对地投放广告、生成研究结果和完成其它更多事情。 Hölzle 透露：「整个性能都在不断提高， GPUs加快或者说放大了这个过程。」为什么开源？从技术发展的趋势来看，开源日渐成为一股不可阻挡的趋势。作为美国国防部的一个研究机构，很难想象 DARPA 这样的组织竟不在意别人利用自己公开的信息。然而，DARPA 已经向开源机器学习技术迈出了一大步。事实上，DARPA XDATA 项目导致产生一个目前最先进的机器学习、可视化和其他技术的目录，任何人都可以下载、使用和修改这些技术以打造定制化的人工智能工具。DARPA 和国防部如此支持开源的事实有力地表明开源的优点大于将高质量的工具提供给潜在对手的缺点。&nbsp;另一个开源项目则是 OpenAI 项目，该项目最近由技术企业家 Elon Musk 和 Sam Altman 等人发起，这项工作的目的是研究具有越来越强的理解世界和与世界交互的能力的机器的创造与发布背后的伦理道德。&nbsp;DARPA 和 OpenAI 的动机都不能解释到底为什么这些商业技术公司要开源他们的人工智能代码。毕竟，作为技术公司，他们关注的问题更加直接和具体。毕竟如果没人使用他们的产品，那好而整洁的代码和用心良苦的算法又有什么用呢？&nbsp;业内存在一个共识，即谷歌、Facebook 和亚马逊这样的公司的业务模式和人们所想的并不一样。从长远来看，谷歌和Facebook都没有真正的广告销售业务。这些技术公司都是由你的眼球(和数据)驱动的。他们的通货是用户。以谷歌为例，免费提供电子邮箱和搜索服务将用户吸引到它的产品上；它需要快速创新、产出更多更好地产品以确保用户留存下来。对于 TensorFlow 为何要开源，谷歌官方的解释是，将技术免费开放是希望可以加速人工智能领域的发展。所有人都可以帮助 Google 改进其技术，并将成果反馈回来。正如 Google 深度学习项目的主要推动者 Jeff Dean 所说：「我们希望的是，整个研究、开发者社区将 TensorFlow 作为一种很好的手段来实现各种各样的机器学习算法，同时也为其在各种场景下的应用带来改进。」如果此次开源能够使更多的数据科学家开始使用谷歌的系统来从事机器学习方面的研究，那么这将有利于谷歌对日益发展的机器学习行业拥有更多的主导权。谷歌敢于开放 Tensor Flow 的代码，是因为它所拥有的数据对于建造一个强力的人工智能引擎更具价值。该公司希望开源能将其打造成机器学习领域的领先者，并发展与开发者和合作伙伴的关系。Tensor Flow「从某种程度上给了我们一个共同说话的语言。」&nbsp;艾伦人工智能研究所执行董事 Oren Etzioni 对谷歌的这一行为评价道，这是谷歌整个平台战略的一部分，来吸引开发者和机器学习人才。但比起提供云服务的 IBM、微软和亚马逊，谷歌确实在做一些更加开放的工作。开源人工智能的举措能够保证这些公司在前沿技术领域保持自己的领先地位。从这个意义上看，它们并没有交出自己成功的钥匙，而只是在给自己的未来铺路。当然，科技巨头将深度学习平台也势必会带来更多的商业利益，Jeff Dean 说：「我们从使用过 Tensor Flow 的开发者们身上获取益处，这并不是纯粹的无私行为。」，MIT 斯隆管理学院的教授 Michael A. Cusumano 就认为，即便 TensorFlow 是开源，但如果它能获得成功，将毫无疑问成为谷歌的赚钱机器。&nbsp;这些公司开源它们的人工智能软件是因为它们希望成为其他人创新的基础。成功的企业可以借此壮大，而这些科技公司也可以将它们整合到自己的产品集群中。人工智能是其中的核心，因为通过设计，它可以学习、适应甚至决策。人工智能不只是一种产品：它是一个产品生成器。在不远的未来，人工智能并不会被直接用来提供图像服务或消费类产品，但会通过创新新产品，帮助企业找到新的创新机会。开源人工智能的举措能够保证这些公司在前沿技术领域保持自己的领先地位。从这个意义上看，它们并没有交出自己成功的钥匙，而只是在给自己的未来铺路。科技巨头的开源竞赛正式因为开源所带来的各种价值，谷歌、Facebook等科技巨头也开始了激烈的开源竞赛。谷歌开源了TensorFlow ，Facebook 紧接着开源人工智能硬件 Big Sur，之后IBM、百度和雅虎也相继加入。1）谷歌开源 TensorFlow2015年12月，谷歌开源了第二代深度学习系统 TensorFlow，该系统将机器学习算法变成了符号表达的各类图表，从而有效缩短了重新写代码的时间。谷歌在官方博客上表示，比起旧系统，TensorFlow 没有被束缚在谷歌自身的IT架构内，能够被任何有相关背景的人基于合适的IT资源进行配置。它更快、更灵活以及更聪明，在建立和训练机器学习模型方面比第一代人工智能系统快五倍。谷歌 CEO Sundar Pichai 在博客中写到，TensorFlow更快的速度使我们能够更快的提升产品表现。&nbsp;当然，谷歌也并非完全毫无保留。目前开源的是其引擎中较为顶层的算法，也没有开源其硬件基础设施系统。而且，谷歌也不是第一个将深度学习系统开源的科技巨头。2）Torch和硬件Facebook开源TensorFlow之后，Yann LeCun在Facebook上转了一篇纽约时报Bits报道TensorFlow的文章，并评论说：「如果放在几年前，谁会想到一篇关于深度学习开源库的文章会发布在纽约时报科技频道（Bits）上？」补充一下 (以便大家不要误解我的含义)： 我认为TensorFlow 非常酷，我对谷歌的朋友们将其开源表深表赞同。&nbsp;其实，Yann LeCun是在非常狡猾的提醒用户，Facebook早在今年一月份就公布了一个机器学习的开源项目，他们将一些基于机器神经网络的产品免费放在了Torch（一个关注深度学习的开源软件项目）上，可以用来处理数据，分析信息的共同特征。Facebook人工智能实验室的研发工程师Soumith Chintala对此表示，将人工智能和神经网络公开是十分有用的，他也是Torch项目的创始人之一。他说，除了大公司之外，Torch也会用于创业公司和大学实验室。2015年12月，Facebook开始为他们的人工智能工作建造定制化的服务器，并在周四宣布将向全世界公布这个强大硬件的设计——而且是免费。这个服务器设计蓝图的开源计划名为「大索尔（Big Sur）」。其他公司和研究者将能从Facebook开发者的研究进展中获利。上个月，谷歌曾发布了构建AI的软件系统TensorFlow。微软、IBM和三星也都发布了自己的软件工具。Big Sur服务器是围绕英伟达的GPU（图形处理单元）建造的。GPU在人工智能中的应用十分广泛，因为这种芯片上搭载的处理核心数量多于英特尔生产的传统处理器，使得它们十分适用于AI软件所需要的海量计算。这个硬件设计将作为开放计算项目（OCP，Open Compute Project）的一部分。高盛投资公司说，他们在2012年使用了OCP的设计，节省的计算支出多达30%。2014年1月，扎克伯格说这个系统的使用为Facebook节省了12亿美元。3）IBM开源机器学习平台2015年11与，IBM周一宣布旗下机器学习平台 SystemML正式开源，成为Apache孵化器下面的一个开源项目。根据IBM官方的说法，SystemML使用 Java编译， 能够实现以下三点：(1) 可定制算法；(2) 多个执行模式，包括单个，Hadoop 批量和 Spark 批量；(3) 自动优化。&nbsp;Apache孵化器是Apache基金会成立于2002年10月，为那些意图成为Apache基金会努力的一部分的项目和代码库，提供一个进入到Apache软件基金会的路径。那些从外部组织捐赠的所有代码，以及意图移动到Apache的现有外部项目，都必须进入Apache孵化器。IBM表示，将在6月份捐献SystemML代码。从某种意义上说，IBM此举，也是为了抢占机器学习领域的话语权。各大巨头希望通过吸引越来越多开发者参与到自己平台上，鼓励他们使用自己的平台进行数据训练，随着训练数据越来越多，机器也会变得越来越聪明，这也有利于形成良好的生态循环。4）百度开源人工智能代码2016年1月5号，百度本周宣布开源人工智能代码，从而在人工智能技术的标准发展中掌握一定的主动权。此前，谷歌和Facebook也宣布将开源相关技术。百度硅谷实验室已经向GitHub上传了Warp-CTC C代码库。与此同时，百度在一篇博客文章中鼓励开发者试用这些代码。5）雅虎开源 CaffeOnSpark 深度学习软件2015年3月，雅虎的 Big ML 团队成员 Andy Feng, Jun Shi 以及 Mridul Jain 在他们的博客中说道：CaffeOnSpark 这一深学习系统,现在已经可以通过开源社区获取并且进行进一步的开发了。

CaffeOnSpark 是一Hadoop/Spark 的分布式学习系统，基于Apache Spark 开源集群计算框架。正是这个深度学习系统支持着雅虎 Flickr 网站的图像功能，Yahoo 就是用这项技术来识别照片中的不同内容，以此改良 Flickr 网站的搜索结果。而现在，雅虎正式将这一系统开源。这个系统提供了很多数据分类和数据处理的方法，对于开发者来说，无疑又是一个好消息。"
"日报;;【日报】融合深度学习的Google翻译要来了融合深度学习的Google翻译要来了、Hyperloop将要建一条8分钟连接欧洲中部的超级高铁、维基百科将开发众包语音引擎、微软投资五亿打造华盛顿智能城市……机器之心日报，精选一天前沿科技优质内容。融合深度学习的Google翻译要来了Google已经利用深度学习技术提升了旗下多个产品的智能体验，该技术藉由大量的数据来训练神经网络，从而对新数据做出预测。比如Google地图、 Google照片、Gmail等等产品的用户体验提升都与这种增强技术不无关系。现在得到的最新消息是，Google翻译也将开始引入这一深度学习技术。&nbsp;事实上，Google翻译早已开始在部分功能上使用深度学习技术，比如摄像头即时取词翻译功能。但是如果你之前使用过Google翻译的“全文翻译”功能的话，你就会发现翻译的准确率其实远达不到100%准确的程度。&nbsp;在今天的洛杉矶结构数据会议上，曾参与Google核心搜索广告技术研发，现担任Google大脑研发团队负责人的Google高级研究员Jeff Dean表示，他的团队已经在尝试把深度学习融入Google翻译之中。具体来说，这项工作是基于2014年的一篇名为“序列学习与神经网络”（Sequence to Sequence Learning with Neural Networks）论文中的技术描述所展开。Dean表示：“简单来说，这项工作的最终目标就是要把Google大脑融入到Google翻译之中。我认为我们未来将能够取得一些实质性的突破。”

把深度学习技术融入Google翻译之中无疑将大幅提升翻译的准确度。目前的翻译大多依赖于一些传统意义上的各类技术，而基于神经网络进行翻译将能够使之变得更加精确，尤其是对于LSTM这种时间递归神经网络而言。

此外，不只是Google，百度和微软等科技巨头也在尝试将深度学习融入机翻之中。Hyperloop将要建一条8分钟连接欧洲中部的超级高铁超级高铁Hyperloop周四宣布，该公司已和斯洛伐克共和国政府签订了协议，以共同探索建设一个连接斯洛伐克首都伯拉第斯拉瓦、奥地利维也纳和匈牙利布达佩斯的Hyperloop超级高铁系统。“斯洛伐克是汽车、材料科学、能源产业的技术领先者，而这些领域对Hyperloop来说都是必不可少的，”

yperloop Transportation Technologies CEO德克·阿尔博恩（Dirk Ahlborn）表示，“而欧洲超级高铁的诞生将能推动斯洛伐克以至整个欧洲的协作创新。”维基百科将开发众包语音引擎 为视障者提供便利3月11日消息，据国外媒体Engadget报道，维基百科周四宣布，它将与来自瑞典皇家理工学院的研究人员合作开发开放的众包式语音引擎，未来该在线百科全书将变得更便于有阅读困难或视觉障碍的人使用。那将会是全球首个众包式语音合成平台。维基百科估计，将有25%的用户（约1.25亿人）从该项新服务中受益。据PTS称，这部分用户需要或者偏爱语音形式的文本。虽然该引擎将会针对维基百科进行优化，但任何使用MediaWiki软件的网站也都将能够将其整合。&nbsp;瑞典皇家理工学院的语音技术专家约阿基姆·古斯塔夫森（Joakim Gustafson）在声明中说道，“一开始，我们将专注于做瑞典语，我们将会充分利用我们自己的语音资源。之后，我们将会做基本的英语语音，鉴于开源语言资源相当多，预计我们将能够做得很好。最后，我们将会做基本的阿拉伯语音，这将更多地作为概念验证。”&nbsp;跟维基百科的文本内容一样，其语音输出也将会采用众包形式，即让用户为语音合成器的持续发展做贡献。维基百科计划今年年底之前完成英语、瑞典语和阿拉伯语的语音支持工作，而后将会处理其网站支持的其余280种语言。微软将投资5亿美元参与华盛顿“智能城市”项目据外媒报道，微软公司今天宣布投资5亿美元，参与Minh Le提出的一个名为“ Gramercy District”的房产计划。该项目有意打造一个具有“混合功能的智能城市”，占地16英亩，总建筑面积达到250万平方英尺，毗邻华盛顿特区即将开发的Ashburn地铁站。据《华盛顿商业杂志》报道，Minh Le再次提出了他希望能打造一个全新智能城市的愿景，希望借助科技的进步帮助改善人们的生活。Minh Le表示：“我们现在的愿望是成立一个伟大的高科技房地产公司。我们相信科技将成为改变人们生活方式、学习方式及社交方式的一个主要力量。”&nbsp;据悉，微软还计划为“Gramercy District”项目打造一个“智能生活平台”。不过该项目的其他具体细节目前尚未透露。人工智能APP使用社交信息监察公共健康上个月，在美国凤凰城人工智能发展协会（AAAI）大会上，一款名为nEmesis的APP获得了人工智能创新应用大奖。uEmesis由美国罗切斯特大学研发,使用人工智能和自然语言处理技术精准定位社交媒体上用户发布的信息，从而追踪食物中毒、重大疾病等医疗事件爆发的源头。蓝色起源公司计划2017年进行首次载人试飞北京时间3月10日消息，私人航空公司Blue Origin创始人杰夫?贝佐斯(Jeff Bezos)称，该公司将于2017年进行首次载人试飞。&nbsp;贝佐斯在参观该公司位于西雅图城郊的研发中心时表示，已经有数千人对花钱乘坐亚轨道飞行器表示了兴趣。但该公司还没有开始收取资金，因此我们目前还不清楚，该公司能否将数千名感兴趣的“太空旅行家”转化为公司收益。&nbsp;杰夫·贝佐斯也是在线零售商亚马逊的创始人，他目前已经将亚马逊赚取的数十亿美元投入了高科技设备的研发中，还雇佣了约600名之前在一家波音旗下的零部件制造公司就职的员工。Blue Origin公司成立于2000年，目前已经将一艘宇宙飞船发射了两次，并使其安全着陆。该公司计划继续对其进行测试，直到其寿终正寝，然后再利用其它宇宙飞船进行载人航天测试。&nbsp;

贝佐斯表示，他们将通过向其它计划发射卫星和宇宙飞船的公司出售火箭引擎来盈利。联合发射联盟公司(United Launch Alliance)已经请Blue Origin公司为自己的新运载火箭生产引擎，这样该公司就不需要依赖俄罗斯制造的引擎了。谷歌计划在英国测试自动驾驶汽车北京时间3月10日晚间消息，谷歌母公司Alphabet董事长埃里克·施密特(Eric Schmidt)今日在接受采访时表示，谷歌正考虑在英国进行自动驾驶汽车路测。&nbsp;施密特称，英国政府官员已建议谷歌先在英国一个城市试驾自动驾驶汽车，然后再推广到其他城市，最终让所有人都坐上自动驾驶汽车。施密特说：“一位官员建议我们先选择一个城市测试自动驾驶汽车，对相关事宜进行评估。在此之前，我们必须要得到英国政府的许可。”他还表示：“在美国，我们需要一个州一个州普及；在全球，需要一个国家一个国家来推广。我们正在为此而努力，这需要时间。” &nbsp;谷歌打造自动驾驶汽车已有6年多时间，测试里程已超过140万英里。但到目前为止，谷歌仅在美国加州和德州的特定城市进行了路测。因此，英国有可能成为谷歌自动驾驶汽车国际试驾的首站。福特雪中测试无人驾驶汽车据外媒报道，福特日前发布了一段视频显示，自家开发的无人驾驶汽车可以成功的在雪地里进行行驶。福特的无人驾驶使用了激光雷达技术，而这个技术可以通过激光测量与目标之间的距离。通常来说，在雪地里驾驶要比普通路面驾驶更危险，因此无人驾驶汽车如果能在雪地里安全又顺畅的行进，的确让人感到高兴。“在雪地里行驶需要面对多种挑战，尤其是一阵夹杂着大雪的大风甚至会影响视线。因此如果无人驾驶汽车能够自主的在雪地中行驶，那么未来我们再也不用亲自在这样危险的道路上驾驶了。”福特表示。&nbsp;据悉，福特的无人驾驶使用了激光雷达技术，而这个技术可以通过激光测量与目标之间的距离。福特表示，无人驾驶汽车在一个小时内处理的数据量要比普通用户使用智能手机10年所处理的数据还要多。今年年初，福特在接受媒体采访时表示，到2020年普通消费者就会在马路上亲身体验到无人驾驶汽车所带来的好处了。另外，谷歌早前也表示，将会在美国华盛顿州的柯克兰市（Kirkland），进行自动驾驶汽车的广泛测试。目的是让自动驾驶汽车接受更恶劣路况的挑战，其中包括雨路、山路等。中国科学家获得“反物质”新华社上海3月10日电（记者王琳琳）记者从中国科学院上海光机所获悉，该所强场激光物理国家重点实验室近日利用超强超短激光，成功产生反物质——超快正电子源，这一发现将在材料的无损探测、激光驱动正负电子对撞机、癌症诊断等领域具有重大应用。相关研究成果已于近日发表在《等离子体物理》杂志上。长期以来，科学家们一直在探索“利用激光产生反物质”的有效方法，为了获得反物质——超快正电子源，上海光机所经历了长达15年的持续研究。强场激光物理国家重点实验室研究员沈百飞介绍，此次反物质的获得经历了一个相对复杂的过程和优化：首先将飞秒拍瓦激光装置与高压气体靶进行相互作用，产生大量高能电子；高能电子再和高原子序数材料靶（如铜、金）相互作用，产生高强度伽马射线；伽马射线再和高原子序数原子核作用产生正负电子对。&nbsp;沈百飞表示，经过特殊设计的正电子谱仪，成功解决了伽马射线带来的噪声问题，利用正负电子在磁场中的不同偏转特性，最终成功观测到了正电子。据了解，获得反物质超快正电子源将对激光驱动正负电子对撞机等具有重要意义。未来，在高能物理、材料无损探测、癌症诊断领域有应用前景，由于其脉宽只有飞秒量级，可使探测的时间分辨大大提高，进而研究物质性质的超快演化。"
"人工智能;;专访深度学习元老：这个实验室如何孕育DeepMind？举世瞩目的人机围棋大战已战罢两番棋，人工智能应用Alpha Go两胜李世石，引发公众对于人工智能潜力的热烈讨论。「机器可以像人一样学习吗？」「人工智能会超越人类的智力吗？」为回答这些问题，InfoQ专访了瑞士人工智能实验室IDSIA的科学主任Jürgen Schmidhuber教授。Jürgen Schmidhuber 教授是深度学习领域的元老级专家，毕业于慕尼黑工业大学，现在是瑞士人工智能实验室（IDSIA）主任。他在15岁就希望能开发一种比它聪明并且能够自我完善的人工智能，然后他就可以退休了。从1987年开始，他引领了自我完善的通用问题解决方案的研究，又在1991年引领了深度学习神经网络的研究，其团队的卷积神经网络研究成为首个赢得官方国际大赛的项目。该技术对手写识别、语音识别、机器翻译、图像捕捉等诸多领域带来革命性的创新，如今该技术在谷歌、微软、IBM、百度等互联网公司的产品被广泛使用，惠及数以亿计的用户。而如今「网红」的DeepMind公司也与该实验室有渊远，DeepMind创始初期四人中的两人以及他们招募的第一个人工智能博士都来自Jürgen Schmidhuberwei的这个实验室。Jürgen Schmidhuberwei的团队在多个领域创造了第一，比如其「Deep Learners 」是第一个赢得物体识别和图像分割竞赛冠军，也创造了世界首个超常视觉分类成绩，在9项国际性的机器学习和模式识别领域获得冠军。InfoQ: 什么是深度学习，它的历史情况是怎么样的？Schmidhuber：这是旧帽子的新标签。主要就是有许多（而不仅仅是几个）后续处理阶段的深度神经网络。随着今天计算机速度越来越快，这类网络已经彻底革新了模式识别和机器学习。Dechter在1986年首次把「深度学习」引入机器学习，Aizenberg等人在2000年将其引入人工神经网络 (NNs)。

乌克兰数学家Ivakhnenko是深度学习之父。他 (与Lapa) 在1965年发表了第一个针对监督深度前馈多层感知的通用、可行的学习算法。在1971年，他已经描述过八层的神经网络，以目前的标准来看依旧很深，其使用的训练方法仍流行于新千年。他远远领先于自己的时代——当时，电脑比现在慢十亿倍。InfoQ：你对《科学》上的《 Human-level concept learning through probabilistic program》（有关人类级别的概念学习）这篇文章怎么看？论文通过贝叶斯程序学习 (BPL)框架实现了「看一眼就会（one-shot learning）」。Schmidhuber：那篇论文很有趣。不过，人们也可以用标准迁移学习来实现，首先用不同视觉训练集「慢慢」训练深度神经网络，如此以来，前10层就变成一个相当通用的视觉预处理器，然后冻结那10层，并且仅新图像上的高学习率重新训练第十一层顶层。多年来，这个方法一直很管用。InfoQ: 你如何比较贝叶斯方法和深度学习方法？哪个更可行？为什么？Schmidhuber：我之前（现为教授）的博士后学生 Marcus Hutter，用AIXI模型 (2002) 展现了最优化（ultimate optimal）的贝叶斯研究方法。任何计算问题都可以用一个回报函数的最大值来表述。AIXI模型基于Solomonoff的通用混合值M，其中包括所有可计算的概率分布。如果世界对一些强化学习代理行为的反应概率是可计算的 （还没有反对证明），那么，该代理或许能使用M （而不是真实却未知的概率分布），预测自己未来的感官（sensory）输入和奖励。该代理的确可以通过选择那些最大化M预测奖励值的行为顺序，优化行为。这或许可以被称为无敌、终极的人工智能的统计研究方法——它证实了什么才是可能在数学上的极限。然而，AIXI的优化概念忽略了计算时间，这就是为什么我们仍与通用性较差但更具实践可能性的方法打交道，比如，基于更加有限的本地搜索技术 （比如梯度下降）的深度学习。InfoQ: 上述《科学》论文把结果描述为「通过了视觉图灵测试」。半个多世纪前提出的图灵测试，至今还有效吗？Schmidhuber：我的聊天伙伴感觉上像是人类吗？（如果是），它已经通过了我个人的图灵测试。正如Weizenbaum几十年前的看法，主观性是这个测试的核心问题。有些人比别人更容易上当。InfoQ: 你怎么看待谷歌在《自然》发表的关于AlphaGo程序击败职业棋手的论文？AlphaGo是不是这个领域的一大突破？帮助它成功的因素是什么？Schmidhuber：我为谷歌DeepMind的成功感到高兴，同时也因为这家公司在很大程度上受我以前的学生影响：DeepMind的头四个成员中有两个来自IDSIA，他们的第一个人工智能领域的博士雇员也来自IDSIA，其中一个是联合创始人，另一个是公司的第一名员工；我的其他博士学生也稍后加入了DeepMind，其中包括我们在2010年Atari-Go上发布论文的联合作者。

围棋是棋盘游戏，所以马尔科夫假设 (Markov assumption)成立：原则上来说，当前的输入 (棋盘的状态) 传达了决定最佳下一步所需要的全部信息 (无需考虑历史状态)。也就是说，可以用传统的强化学习 (RL) 解决比赛，这有点像20多年前， 那时，Tesauro在IBM使用RL跟一位相当于人类世界冠军（1994）的西洋双陆琪玩家从头学起。然而，在今天，我们在很大程度上受益于这一事实：计算机每美元至少快一万倍。在过去几年内，自动围棋选手进步得很快。在向好围棋手学习时，DeepMind的系统结合了多种传统方法，例如监督学习 (从人类专家) 和基于蒙特卡洛树搜索的RL。在不久将来，观看电脑系统对战顶尖人类围棋手，会非常有意思。

然而，不幸的是，马尔科夫假设在真实世界场景里无法成立。这也是为什么现实世界的游戏，例如橄榄球比国际象棋或围棋更难，针对 生活在部分可观测环境中的RL机器人的强人工智能 (AGI) 将需要更成熟的学习算法，例如，递归神经网络 (recurrent neural networks)的RL。InfoQ：最近，谷歌DeepMind宣布进军医疗保健市场。你怎么看？Schmidhuber：我们对深度学习在医疗保健方面的应用非常感兴趣。事实上，2012年的时候我们在IDSIA（第一作者为Dan Ciresan）的团队为了赢得医学成像的比赛，第一次引入了深度学习。我很高兴看到现在许多公司在医学成像和类似的应用上使用深度学习。全世界超过 10% 的GDP都被用在了医疗保健上（每年超过7万亿美元），其中昂贵的专家的医疗诊断占到了很大部分。这方面的部分自动化不仅可以节约数十亿美元，还能将专家诊断推广到现在还无力负担的人。在这种背景下，医学最有价值的资产应该就是它们的数据——这就是IBM要耗资十亿美元收集这些数据的原因。InfoQ：你怎么看待IBM新的沃森物联网平台？人工智能在物联网领域有怎样的潜力？「AI即服务（AI as a service）」会成为人工智能一个有前景的趋势吗？Schmidhuber：物联网（IoT: Internet of Things）将会远远大于人联网（IoH: Internet of Humans），因为机器将远多于人类。而许多机器确实会向其它机器提供「AI即服务」。广告让IoH有利可图；然而IoT的商业模式看起来就没那么明显了。InfoQ：有些人说，未来与无监督学习有关，你认同吗？Schmidhuber：我得说即使过去也是关于无监督学习的，它涉及到在没有老师的观察中检测规律性，它本质上是关于自适应的数据压缩（adaptive data compression），例如通过预测性编码（predictive coding）实现。四分之一个世纪前，我在这个主题上发表了我的第一篇论文——事实上在1991年这导致了第一个能用的「非常深度的学习者（very deep learner）」的诞生，它可以处理数百个后续计算层。InfoQ：机器可以像人类一样学习吗？Schmidhuber：现在还不能，但可能很快了。也可参看这个关于「学习去思考（learning to think）」的报道：无监督数据压缩（正如前面提到过的）是基于RNN的自适应代理的核心成分，该代理可以利用基于RNN的predictive world model来更好地规划和实现目标。1990年，我们首次就这方面的研究发表文章，自那以后，我们也已取得了很大的进步。InfoQ：人工智能有局限吗（ a limit of artificial intelligence）？Schmidhuber：这个局限本质上就是1985年由理论计算机科学（1931年）的创始人库尔德·哥德尔确定出的可计算的局限。哥德尔说明传统数学要么在特定算法感知上存在缺陷，要么包含了无法通过计算程序证明的真实陈述（true statement）——无论人类还是人工智能都无法证明。InfoQ：在你眼中，人类与机器之间的完美分工是怎样的？Schmidhuber：人类完全不应该做辛苦而枯燥的工作，计算机来做。InfoQ：你因在递归神经网络（RNN），尤其是长短期记忆（LSTM）上的开创性成果而声名远播，这种技术现已在深度学习中得到了广泛的应用。你可以给我们简短说明一下LSTM的背景和技术吗？你认为LSTM最适合哪些领域？有什么现实世界的案例吗？Schmidhuber：监督LSTM RNN是通用目的的计算机，可以学习处理视频和语音等各种序列任务的并行序列程序。自90年代早期以来，它们已在我的实验室中被一些优秀的博士生和博士后开发出来，其中包括Sepp Hochreiter、Felix Gers、Alex Graves、Santi Fernandez、Faustino Gomez、Daan Wierstra、Justin Bayer等人。部分LSTM RNN的设计让反向传播的错误既不消失也不爆发，而是以一种「文明的」方式通过几千甚至更多个步骤倒流回去。因此，LSTM的变体版本可以从之前不可学习的「Very Deep Learning」任务中进行学习，这些任务要求发现（和记忆）发生在数千个离散时间步骤之前的事件的重要性；而之前的标准RNN在最短10步时间延迟的情况下已经失败。它甚至可能演化出很好的针对特定问题的LSTM一样的拓扑结构。

大约2007年的时候，我们的CTC（2006年）训练的LSTM开始革新语音识别，性能表现超越了键盘识别任务中传统方法。谷歌后来也用LSTM以帮助改进现有的技术，包括图像字幕（2014年）、机器翻译（2014年）、文本到语音合成（2015年，现在可在谷歌Android上使用）、自然语言处理的句法分析（2015年）等其它许多应用。2015年，CTC训练的LSTM极大地改善了Google Voice（49%）——现在有超过10亿智能手机用户可以使用它。微软和IBM和其它著名公司也在大量使用LSTM。InfoQ：你的团队赢得了九次国际模式识别大赛，举一两个例子，例如手写识别和交通标志识别。你们是怎么办到的？Schmidhuber：我的团队确实为多次赢得比赛而感到自豪，其中包括：MICCAI 2013有丝分裂检测挑战赛ICPR 2012乳腺癌组织学图片有丝分裂检测大赛ISBI 2012脑图像分割挑战赛IJCNN 2011交通标志识别大赛ICDAR 2011离线中国书法大赛在线德国交通标志识别大赛ICDAR 2009阿拉伯语连接手写大赛ICDAR 2009波斯语/阿拉伯语手写字符识别大赛ICDAR 2009法语连接手写大赛我们团队又是如何做到的？通过创新、执着、拼搏和奉献。InfoQ：你也在very deep nets上做出了特殊的重要性，不是吗？Schmidhuber：既然深度意味着计算力和效率，我们从一开始就关注着very deep neural nets。比如说，1990年代早期，当其他人还受限于少于10个后续计算层的相当浅的网络时，我们的方法已经可以启用超过1000个这样的计算层了。我得说，我们就是将神经网络做得非常深的人，尤其是递归网络——它们中最深最强大的网络。当时，很少有研究者对此感兴趣，但我们坚持了下来，随着计算力越来越便宜，通过这样的方法赢得比赛只是时间问题。我很高兴看到其它深度学习实验室和公司现在也大量使用我们的算法。InfoQ：上面的比赛是关于模式识别的——对于强化学习（reinforcement learning）和无师自通序贯决策（sequential decision）的更加通用的领域，你推荐什么方法？Schmidhuber：我们喜欢我们的压缩网络研究，它超越了单纯的模式识别，发现了权重值为一百万的复杂神经控制器，并且（在2012年）成为了第一种依靠强化学习直接从高维度感官输入学会控制策略的方法。如果想了解更多，可查看前面提到的关于「学会思考（learning to think）」的报告。InfoQ: 对于深度学习和人工智能，你最近的研究兴趣是什么？Schmidhuber：我最近的研究兴趣仍然是我早在20世纪80年代阐述过的那些：「开发出比我更聪明的人工智能，这样我就可以退休了。」这需要的不仅仅是普通的深度学习。它需要自我指涉通用目的的学习算法，这种算法不仅改善给定领域某些系统性能，还改善它们学习的方式，以及它们学习方式的方式，等等，仅受限于可计算性的根本局限性。从1987年将这个问题作为学位论文选题以来，我一直在研究这个包罗万象的内容，但是现在我能看到这个主题正开始变成一个可能实现的现实。&nbsp;InfoQ: 自从去年作为一家深度学习创业公司启动以来，NNAISENSE 已经受到关注。你是这家公司掌门人，能和我们多谈谈 NNAISENSE 吗？对于这次新冒险，你的计划是什么？Schmidhuber：NNAISENSE 的发音像「nascence」，因为它与孕育一个通用目的的以神经网络为基础的人工智能（ NNAI ）有关。公司有5位联合创始人，几位雇员，非常强的研究团队，收益来自正在工业和金融（以及与投资人交谈）领域进行的最先进的应用。我们相信，我们能实现巨大的实践性突破，这一突破将改变一切，与上世纪80年代的老座右铭相符：「开发出比我更聪明的人工智能，这样我就可以退休了。」InfoQ: 在不久的将来，人工智能产业的发展前景是什么？哪些领域会冒出杀手级 apps ？会有瓶颈吗？Schmidhuber: 在 reddit 的 AMA 上，我指出，机器学习和神经网络算法将在许多领域（从医疗诊断到更加智能的电话）取得许多重要的超人般的成绩，更好理解和解决你的许多难题，并且让你更依赖它们。我推测我们正在见证这一领域爆炸式发展的点火阶段。但是，如何从内部预测爆炸时细节？假定计算能力以每十年100欧元的速度继续变得便宜，到了2036年，同等价位的计算机将比如今快10,000倍。这听上去多少有点像一个小巧的便携式设备拥有了人的脑力，或者像更大的计算机拥有了城市那么大的大脑能力。 鉴于这种尚未成熟的计算能力，我预期（以今天的标准）在专用硬件上运行的巨大RNNs能同时从许多资料来源中感知和分析海量的多模态数据流（语音、文本、视频和许多其它模态），学会关联所有这些输入，并且使用提取出的信息实现无数的商业和非商业目标。递归神经网络将持续快速地在已知的基础上学习新技能。这里应该有无数的应用，虽然我甚至不确定「应用」这个词在这里是否仍有意义。InfoQ: 那么，下一步是什么？Schmidhuber：孩子甚至某些小动物仍然比最好的自我学习（self-learning）机器人聪明得多。但是，我相信，在不那么多年之内，我们就能搭建起基于NN的人工智能（NNAI），逐渐学会和小动物一样聪明，以非常通用的方式学会规划、推理以及将各种各样问题快速分解成可以解决（或已经解决）的子问题。通过关于乐趣的形式理论（formal theory of fun），甚至有可能让机器具有好奇心和创造力，打造出无监督式的人工科学家。InfoQ：一旦我们实现动物水平的人工智能，将发生什么？Schmidhuber：迈向人类水平的人工智能的下一步可能不会那么巨大：大自然花了数十亿年时间演化出智能动物，在此基础上，只花了数百万年演化出人类。技术进化远比生物进化快速地多。也就是说，一旦我们实现动物水平的人工智能，几年或数十年以后，我们或许就能实现人类水平的人工智能，将有真正无限多的应用，而且每个行业都将改变，整个文明都将改变，一切都将改变。InfoQ：人工智能的长远未来是什么？Schmidhuber：超级聪明的人工智能或许不久将殖民太阳系，然后在数百万年内殖民整个银河系。宇宙想要让它迈出通往越来越深不可测复杂性的下一步。"
"深度学习;;专访深度学习元老：这个实验室如何孕育DeepMind？举世瞩目的人机围棋大战已战罢两番棋，人工智能应用Alpha Go两胜李世石，引发公众对于人工智能潜力的热烈讨论。「机器可以像人一样学习吗？」「人工智能会超越人类的智力吗？」为回答这些问题，InfoQ专访了瑞士人工智能实验室IDSIA的科学主任Jürgen Schmidhuber教授。Jürgen Schmidhuber 教授是深度学习领域的元老级专家，毕业于慕尼黑工业大学，现在是瑞士人工智能实验室（IDSIA）主任。他在15岁就希望能开发一种比它聪明并且能够自我完善的人工智能，然后他就可以退休了。从1987年开始，他引领了自我完善的通用问题解决方案的研究，又在1991年引领了深度学习神经网络的研究，其团队的卷积神经网络研究成为首个赢得官方国际大赛的项目。该技术对手写识别、语音识别、机器翻译、图像捕捉等诸多领域带来革命性的创新，如今该技术在谷歌、微软、IBM、百度等互联网公司的产品被广泛使用，惠及数以亿计的用户。而如今「网红」的DeepMind公司也与该实验室有渊远，DeepMind创始初期四人中的两人以及他们招募的第一个人工智能博士都来自Jürgen Schmidhuberwei的这个实验室。Jürgen Schmidhuberwei的团队在多个领域创造了第一，比如其「Deep Learners 」是第一个赢得物体识别和图像分割竞赛冠军，也创造了世界首个超常视觉分类成绩，在9项国际性的机器学习和模式识别领域获得冠军。InfoQ: 什么是深度学习，它的历史情况是怎么样的？Schmidhuber：这是旧帽子的新标签。主要就是有许多（而不仅仅是几个）后续处理阶段的深度神经网络。随着今天计算机速度越来越快，这类网络已经彻底革新了模式识别和机器学习。Dechter在1986年首次把「深度学习」引入机器学习，Aizenberg等人在2000年将其引入人工神经网络 (NNs)。

乌克兰数学家Ivakhnenko是深度学习之父。他 (与Lapa) 在1965年发表了第一个针对监督深度前馈多层感知的通用、可行的学习算法。在1971年，他已经描述过八层的神经网络，以目前的标准来看依旧很深，其使用的训练方法仍流行于新千年。他远远领先于自己的时代——当时，电脑比现在慢十亿倍。InfoQ：你对《科学》上的《 Human-level concept learning through probabilistic program》（有关人类级别的概念学习）这篇文章怎么看？论文通过贝叶斯程序学习 (BPL)框架实现了「看一眼就会（one-shot learning）」。Schmidhuber：那篇论文很有趣。不过，人们也可以用标准迁移学习来实现，首先用不同视觉训练集「慢慢」训练深度神经网络，如此以来，前10层就变成一个相当通用的视觉预处理器，然后冻结那10层，并且仅新图像上的高学习率重新训练第十一层顶层。多年来，这个方法一直很管用。InfoQ: 你如何比较贝叶斯方法和深度学习方法？哪个更可行？为什么？Schmidhuber：我之前（现为教授）的博士后学生 Marcus Hutter，用AIXI模型 (2002) 展现了最优化（ultimate optimal）的贝叶斯研究方法。任何计算问题都可以用一个回报函数的最大值来表述。AIXI模型基于Solomonoff的通用混合值M，其中包括所有可计算的概率分布。如果世界对一些强化学习代理行为的反应概率是可计算的 （还没有反对证明），那么，该代理或许能使用M （而不是真实却未知的概率分布），预测自己未来的感官（sensory）输入和奖励。该代理的确可以通过选择那些最大化M预测奖励值的行为顺序，优化行为。这或许可以被称为无敌、终极的人工智能的统计研究方法——它证实了什么才是可能在数学上的极限。然而，AIXI的优化概念忽略了计算时间，这就是为什么我们仍与通用性较差但更具实践可能性的方法打交道，比如，基于更加有限的本地搜索技术 （比如梯度下降）的深度学习。InfoQ: 上述《科学》论文把结果描述为「通过了视觉图灵测试」。半个多世纪前提出的图灵测试，至今还有效吗？Schmidhuber：我的聊天伙伴感觉上像是人类吗？（如果是），它已经通过了我个人的图灵测试。正如Weizenbaum几十年前的看法，主观性是这个测试的核心问题。有些人比别人更容易上当。InfoQ: 你怎么看待谷歌在《自然》发表的关于AlphaGo程序击败职业棋手的论文？AlphaGo是不是这个领域的一大突破？帮助它成功的因素是什么？Schmidhuber：我为谷歌DeepMind的成功感到高兴，同时也因为这家公司在很大程度上受我以前的学生影响：DeepMind的头四个成员中有两个来自IDSIA，他们的第一个人工智能领域的博士雇员也来自IDSIA，其中一个是联合创始人，另一个是公司的第一名员工；我的其他博士学生也稍后加入了DeepMind，其中包括我们在2010年Atari-Go上发布论文的联合作者。

围棋是棋盘游戏，所以马尔科夫假设 (Markov assumption)成立：原则上来说，当前的输入 (棋盘的状态) 传达了决定最佳下一步所需要的全部信息 (无需考虑历史状态)。也就是说，可以用传统的强化学习 (RL) 解决比赛，这有点像20多年前， 那时，Tesauro在IBM使用RL跟一位相当于人类世界冠军（1994）的西洋双陆琪玩家从头学起。然而，在今天，我们在很大程度上受益于这一事实：计算机每美元至少快一万倍。在过去几年内，自动围棋选手进步得很快。在向好围棋手学习时，DeepMind的系统结合了多种传统方法，例如监督学习 (从人类专家) 和基于蒙特卡洛树搜索的RL。在不久将来，观看电脑系统对战顶尖人类围棋手，会非常有意思。

然而，不幸的是，马尔科夫假设在真实世界场景里无法成立。这也是为什么现实世界的游戏，例如橄榄球比国际象棋或围棋更难，针对 生活在部分可观测环境中的RL机器人的强人工智能 (AGI) 将需要更成熟的学习算法，例如，递归神经网络 (recurrent neural networks)的RL。InfoQ：最近，谷歌DeepMind宣布进军医疗保健市场。你怎么看？Schmidhuber：我们对深度学习在医疗保健方面的应用非常感兴趣。事实上，2012年的时候我们在IDSIA（第一作者为Dan Ciresan）的团队为了赢得医学成像的比赛，第一次引入了深度学习。我很高兴看到现在许多公司在医学成像和类似的应用上使用深度学习。全世界超过 10% 的GDP都被用在了医疗保健上（每年超过7万亿美元），其中昂贵的专家的医疗诊断占到了很大部分。这方面的部分自动化不仅可以节约数十亿美元，还能将专家诊断推广到现在还无力负担的人。在这种背景下，医学最有价值的资产应该就是它们的数据——这就是IBM要耗资十亿美元收集这些数据的原因。InfoQ：你怎么看待IBM新的沃森物联网平台？人工智能在物联网领域有怎样的潜力？「AI即服务（AI as a service）」会成为人工智能一个有前景的趋势吗？Schmidhuber：物联网（IoT: Internet of Things）将会远远大于人联网（IoH: Internet of Humans），因为机器将远多于人类。而许多机器确实会向其它机器提供「AI即服务」。广告让IoH有利可图；然而IoT的商业模式看起来就没那么明显了。InfoQ：有些人说，未来与无监督学习有关，你认同吗？Schmidhuber：我得说即使过去也是关于无监督学习的，它涉及到在没有老师的观察中检测规律性，它本质上是关于自适应的数据压缩（adaptive data compression），例如通过预测性编码（predictive coding）实现。四分之一个世纪前，我在这个主题上发表了我的第一篇论文——事实上在1991年这导致了第一个能用的「非常深度的学习者（very deep learner）」的诞生，它可以处理数百个后续计算层。InfoQ：机器可以像人类一样学习吗？Schmidhuber：现在还不能，但可能很快了。也可参看这个关于「学习去思考（learning to think）」的报道：无监督数据压缩（正如前面提到过的）是基于RNN的自适应代理的核心成分，该代理可以利用基于RNN的predictive world model来更好地规划和实现目标。1990年，我们首次就这方面的研究发表文章，自那以后，我们也已取得了很大的进步。InfoQ：人工智能有局限吗（ a limit of artificial intelligence）？Schmidhuber：这个局限本质上就是1985年由理论计算机科学（1931年）的创始人库尔德·哥德尔确定出的可计算的局限。哥德尔说明传统数学要么在特定算法感知上存在缺陷，要么包含了无法通过计算程序证明的真实陈述（true statement）——无论人类还是人工智能都无法证明。InfoQ：在你眼中，人类与机器之间的完美分工是怎样的？Schmidhuber：人类完全不应该做辛苦而枯燥的工作，计算机来做。InfoQ：你因在递归神经网络（RNN），尤其是长短期记忆（LSTM）上的开创性成果而声名远播，这种技术现已在深度学习中得到了广泛的应用。你可以给我们简短说明一下LSTM的背景和技术吗？你认为LSTM最适合哪些领域？有什么现实世界的案例吗？Schmidhuber：监督LSTM RNN是通用目的的计算机，可以学习处理视频和语音等各种序列任务的并行序列程序。自90年代早期以来，它们已在我的实验室中被一些优秀的博士生和博士后开发出来，其中包括Sepp Hochreiter、Felix Gers、Alex Graves、Santi Fernandez、Faustino Gomez、Daan Wierstra、Justin Bayer等人。部分LSTM RNN的设计让反向传播的错误既不消失也不爆发，而是以一种「文明的」方式通过几千甚至更多个步骤倒流回去。因此，LSTM的变体版本可以从之前不可学习的「Very Deep Learning」任务中进行学习，这些任务要求发现（和记忆）发生在数千个离散时间步骤之前的事件的重要性；而之前的标准RNN在最短10步时间延迟的情况下已经失败。它甚至可能演化出很好的针对特定问题的LSTM一样的拓扑结构。

大约2007年的时候，我们的CTC（2006年）训练的LSTM开始革新语音识别，性能表现超越了键盘识别任务中传统方法。谷歌后来也用LSTM以帮助改进现有的技术，包括图像字幕（2014年）、机器翻译（2014年）、文本到语音合成（2015年，现在可在谷歌Android上使用）、自然语言处理的句法分析（2015年）等其它许多应用。2015年，CTC训练的LSTM极大地改善了Google Voice（49%）——现在有超过10亿智能手机用户可以使用它。微软和IBM和其它著名公司也在大量使用LSTM。InfoQ：你的团队赢得了九次国际模式识别大赛，举一两个例子，例如手写识别和交通标志识别。你们是怎么办到的？Schmidhuber：我的团队确实为多次赢得比赛而感到自豪，其中包括：MICCAI 2013有丝分裂检测挑战赛ICPR 2012乳腺癌组织学图片有丝分裂检测大赛ISBI 2012脑图像分割挑战赛IJCNN 2011交通标志识别大赛ICDAR 2011离线中国书法大赛在线德国交通标志识别大赛ICDAR 2009阿拉伯语连接手写大赛ICDAR 2009波斯语/阿拉伯语手写字符识别大赛ICDAR 2009法语连接手写大赛我们团队又是如何做到的？通过创新、执着、拼搏和奉献。InfoQ：你也在very deep nets上做出了特殊的重要性，不是吗？Schmidhuber：既然深度意味着计算力和效率，我们从一开始就关注着very deep neural nets。比如说，1990年代早期，当其他人还受限于少于10个后续计算层的相当浅的网络时，我们的方法已经可以启用超过1000个这样的计算层了。我得说，我们就是将神经网络做得非常深的人，尤其是递归网络——它们中最深最强大的网络。当时，很少有研究者对此感兴趣，但我们坚持了下来，随着计算力越来越便宜，通过这样的方法赢得比赛只是时间问题。我很高兴看到其它深度学习实验室和公司现在也大量使用我们的算法。InfoQ：上面的比赛是关于模式识别的——对于强化学习（reinforcement learning）和无师自通序贯决策（sequential decision）的更加通用的领域，你推荐什么方法？Schmidhuber：我们喜欢我们的压缩网络研究，它超越了单纯的模式识别，发现了权重值为一百万的复杂神经控制器，并且（在2012年）成为了第一种依靠强化学习直接从高维度感官输入学会控制策略的方法。如果想了解更多，可查看前面提到的关于「学会思考（learning to think）」的报告。InfoQ: 对于深度学习和人工智能，你最近的研究兴趣是什么？Schmidhuber：我最近的研究兴趣仍然是我早在20世纪80年代阐述过的那些：「开发出比我更聪明的人工智能，这样我就可以退休了。」这需要的不仅仅是普通的深度学习。它需要自我指涉通用目的的学习算法，这种算法不仅改善给定领域某些系统性能，还改善它们学习的方式，以及它们学习方式的方式，等等，仅受限于可计算性的根本局限性。从1987年将这个问题作为学位论文选题以来，我一直在研究这个包罗万象的内容，但是现在我能看到这个主题正开始变成一个可能实现的现实。&nbsp;InfoQ: 自从去年作为一家深度学习创业公司启动以来，NNAISENSE 已经受到关注。你是这家公司掌门人，能和我们多谈谈 NNAISENSE 吗？对于这次新冒险，你的计划是什么？Schmidhuber：NNAISENSE 的发音像「nascence」，因为它与孕育一个通用目的的以神经网络为基础的人工智能（ NNAI ）有关。公司有5位联合创始人，几位雇员，非常强的研究团队，收益来自正在工业和金融（以及与投资人交谈）领域进行的最先进的应用。我们相信，我们能实现巨大的实践性突破，这一突破将改变一切，与上世纪80年代的老座右铭相符：「开发出比我更聪明的人工智能，这样我就可以退休了。」InfoQ: 在不久的将来，人工智能产业的发展前景是什么？哪些领域会冒出杀手级 apps ？会有瓶颈吗？Schmidhuber: 在 reddit 的 AMA 上，我指出，机器学习和神经网络算法将在许多领域（从医疗诊断到更加智能的电话）取得许多重要的超人般的成绩，更好理解和解决你的许多难题，并且让你更依赖它们。我推测我们正在见证这一领域爆炸式发展的点火阶段。但是，如何从内部预测爆炸时细节？假定计算能力以每十年100欧元的速度继续变得便宜，到了2036年，同等价位的计算机将比如今快10,000倍。这听上去多少有点像一个小巧的便携式设备拥有了人的脑力，或者像更大的计算机拥有了城市那么大的大脑能力。 鉴于这种尚未成熟的计算能力，我预期（以今天的标准）在专用硬件上运行的巨大RNNs能同时从许多资料来源中感知和分析海量的多模态数据流（语音、文本、视频和许多其它模态），学会关联所有这些输入，并且使用提取出的信息实现无数的商业和非商业目标。递归神经网络将持续快速地在已知的基础上学习新技能。这里应该有无数的应用，虽然我甚至不确定「应用」这个词在这里是否仍有意义。InfoQ: 那么，下一步是什么？Schmidhuber：孩子甚至某些小动物仍然比最好的自我学习（self-learning）机器人聪明得多。但是，我相信，在不那么多年之内，我们就能搭建起基于NN的人工智能（NNAI），逐渐学会和小动物一样聪明，以非常通用的方式学会规划、推理以及将各种各样问题快速分解成可以解决（或已经解决）的子问题。通过关于乐趣的形式理论（formal theory of fun），甚至有可能让机器具有好奇心和创造力，打造出无监督式的人工科学家。InfoQ：一旦我们实现动物水平的人工智能，将发生什么？Schmidhuber：迈向人类水平的人工智能的下一步可能不会那么巨大：大自然花了数十亿年时间演化出智能动物，在此基础上，只花了数百万年演化出人类。技术进化远比生物进化快速地多。也就是说，一旦我们实现动物水平的人工智能，几年或数十年以后，我们或许就能实现人类水平的人工智能，将有真正无限多的应用，而且每个行业都将改变，整个文明都将改变，一切都将改变。InfoQ：人工智能的长远未来是什么？Schmidhuber：超级聪明的人工智能或许不久将殖民太阳系，然后在数百万年内殖民整个银河系。宇宙想要让它迈出通往越来越深不可测复杂性的下一步。"
"Deepmind;;专访深度学习元老：这个实验室如何孕育DeepMind？举世瞩目的人机围棋大战已战罢两番棋，人工智能应用Alpha Go两胜李世石，引发公众对于人工智能潜力的热烈讨论。「机器可以像人一样学习吗？」「人工智能会超越人类的智力吗？」为回答这些问题，InfoQ专访了瑞士人工智能实验室IDSIA的科学主任Jürgen Schmidhuber教授。Jürgen Schmidhuber 教授是深度学习领域的元老级专家，毕业于慕尼黑工业大学，现在是瑞士人工智能实验室（IDSIA）主任。他在15岁就希望能开发一种比它聪明并且能够自我完善的人工智能，然后他就可以退休了。从1987年开始，他引领了自我完善的通用问题解决方案的研究，又在1991年引领了深度学习神经网络的研究，其团队的卷积神经网络研究成为首个赢得官方国际大赛的项目。该技术对手写识别、语音识别、机器翻译、图像捕捉等诸多领域带来革命性的创新，如今该技术在谷歌、微软、IBM、百度等互联网公司的产品被广泛使用，惠及数以亿计的用户。而如今「网红」的DeepMind公司也与该实验室有渊远，DeepMind创始初期四人中的两人以及他们招募的第一个人工智能博士都来自Jürgen Schmidhuberwei的这个实验室。Jürgen Schmidhuberwei的团队在多个领域创造了第一，比如其「Deep Learners 」是第一个赢得物体识别和图像分割竞赛冠军，也创造了世界首个超常视觉分类成绩，在9项国际性的机器学习和模式识别领域获得冠军。InfoQ: 什么是深度学习，它的历史情况是怎么样的？Schmidhuber：这是旧帽子的新标签。主要就是有许多（而不仅仅是几个）后续处理阶段的深度神经网络。随着今天计算机速度越来越快，这类网络已经彻底革新了模式识别和机器学习。Dechter在1986年首次把「深度学习」引入机器学习，Aizenberg等人在2000年将其引入人工神经网络 (NNs)。

乌克兰数学家Ivakhnenko是深度学习之父。他 (与Lapa) 在1965年发表了第一个针对监督深度前馈多层感知的通用、可行的学习算法。在1971年，他已经描述过八层的神经网络，以目前的标准来看依旧很深，其使用的训练方法仍流行于新千年。他远远领先于自己的时代——当时，电脑比现在慢十亿倍。InfoQ：你对《科学》上的《 Human-level concept learning through probabilistic program》（有关人类级别的概念学习）这篇文章怎么看？论文通过贝叶斯程序学习 (BPL)框架实现了「看一眼就会（one-shot learning）」。Schmidhuber：那篇论文很有趣。不过，人们也可以用标准迁移学习来实现，首先用不同视觉训练集「慢慢」训练深度神经网络，如此以来，前10层就变成一个相当通用的视觉预处理器，然后冻结那10层，并且仅新图像上的高学习率重新训练第十一层顶层。多年来，这个方法一直很管用。InfoQ: 你如何比较贝叶斯方法和深度学习方法？哪个更可行？为什么？Schmidhuber：我之前（现为教授）的博士后学生 Marcus Hutter，用AIXI模型 (2002) 展现了最优化（ultimate optimal）的贝叶斯研究方法。任何计算问题都可以用一个回报函数的最大值来表述。AIXI模型基于Solomonoff的通用混合值M，其中包括所有可计算的概率分布。如果世界对一些强化学习代理行为的反应概率是可计算的 （还没有反对证明），那么，该代理或许能使用M （而不是真实却未知的概率分布），预测自己未来的感官（sensory）输入和奖励。该代理的确可以通过选择那些最大化M预测奖励值的行为顺序，优化行为。这或许可以被称为无敌、终极的人工智能的统计研究方法——它证实了什么才是可能在数学上的极限。然而，AIXI的优化概念忽略了计算时间，这就是为什么我们仍与通用性较差但更具实践可能性的方法打交道，比如，基于更加有限的本地搜索技术 （比如梯度下降）的深度学习。InfoQ: 上述《科学》论文把结果描述为「通过了视觉图灵测试」。半个多世纪前提出的图灵测试，至今还有效吗？Schmidhuber：我的聊天伙伴感觉上像是人类吗？（如果是），它已经通过了我个人的图灵测试。正如Weizenbaum几十年前的看法，主观性是这个测试的核心问题。有些人比别人更容易上当。InfoQ: 你怎么看待谷歌在《自然》发表的关于AlphaGo程序击败职业棋手的论文？AlphaGo是不是这个领域的一大突破？帮助它成功的因素是什么？Schmidhuber：我为谷歌DeepMind的成功感到高兴，同时也因为这家公司在很大程度上受我以前的学生影响：DeepMind的头四个成员中有两个来自IDSIA，他们的第一个人工智能领域的博士雇员也来自IDSIA，其中一个是联合创始人，另一个是公司的第一名员工；我的其他博士学生也稍后加入了DeepMind，其中包括我们在2010年Atari-Go上发布论文的联合作者。

围棋是棋盘游戏，所以马尔科夫假设 (Markov assumption)成立：原则上来说，当前的输入 (棋盘的状态) 传达了决定最佳下一步所需要的全部信息 (无需考虑历史状态)。也就是说，可以用传统的强化学习 (RL) 解决比赛，这有点像20多年前， 那时，Tesauro在IBM使用RL跟一位相当于人类世界冠军（1994）的西洋双陆琪玩家从头学起。然而，在今天，我们在很大程度上受益于这一事实：计算机每美元至少快一万倍。在过去几年内，自动围棋选手进步得很快。在向好围棋手学习时，DeepMind的系统结合了多种传统方法，例如监督学习 (从人类专家) 和基于蒙特卡洛树搜索的RL。在不久将来，观看电脑系统对战顶尖人类围棋手，会非常有意思。

然而，不幸的是，马尔科夫假设在真实世界场景里无法成立。这也是为什么现实世界的游戏，例如橄榄球比国际象棋或围棋更难，针对 生活在部分可观测环境中的RL机器人的强人工智能 (AGI) 将需要更成熟的学习算法，例如，递归神经网络 (recurrent neural networks)的RL。InfoQ：最近，谷歌DeepMind宣布进军医疗保健市场。你怎么看？Schmidhuber：我们对深度学习在医疗保健方面的应用非常感兴趣。事实上，2012年的时候我们在IDSIA（第一作者为Dan Ciresan）的团队为了赢得医学成像的比赛，第一次引入了深度学习。我很高兴看到现在许多公司在医学成像和类似的应用上使用深度学习。全世界超过 10% 的GDP都被用在了医疗保健上（每年超过7万亿美元），其中昂贵的专家的医疗诊断占到了很大部分。这方面的部分自动化不仅可以节约数十亿美元，还能将专家诊断推广到现在还无力负担的人。在这种背景下，医学最有价值的资产应该就是它们的数据——这就是IBM要耗资十亿美元收集这些数据的原因。InfoQ：你怎么看待IBM新的沃森物联网平台？人工智能在物联网领域有怎样的潜力？「AI即服务（AI as a service）」会成为人工智能一个有前景的趋势吗？Schmidhuber：物联网（IoT: Internet of Things）将会远远大于人联网（IoH: Internet of Humans），因为机器将远多于人类。而许多机器确实会向其它机器提供「AI即服务」。广告让IoH有利可图；然而IoT的商业模式看起来就没那么明显了。InfoQ：有些人说，未来与无监督学习有关，你认同吗？Schmidhuber：我得说即使过去也是关于无监督学习的，它涉及到在没有老师的观察中检测规律性，它本质上是关于自适应的数据压缩（adaptive data compression），例如通过预测性编码（predictive coding）实现。四分之一个世纪前，我在这个主题上发表了我的第一篇论文——事实上在1991年这导致了第一个能用的「非常深度的学习者（very deep learner）」的诞生，它可以处理数百个后续计算层。InfoQ：机器可以像人类一样学习吗？Schmidhuber：现在还不能，但可能很快了。也可参看这个关于「学习去思考（learning to think）」的报道：无监督数据压缩（正如前面提到过的）是基于RNN的自适应代理的核心成分，该代理可以利用基于RNN的predictive world model来更好地规划和实现目标。1990年，我们首次就这方面的研究发表文章，自那以后，我们也已取得了很大的进步。InfoQ：人工智能有局限吗（ a limit of artificial intelligence）？Schmidhuber：这个局限本质上就是1985年由理论计算机科学（1931年）的创始人库尔德·哥德尔确定出的可计算的局限。哥德尔说明传统数学要么在特定算法感知上存在缺陷，要么包含了无法通过计算程序证明的真实陈述（true statement）——无论人类还是人工智能都无法证明。InfoQ：在你眼中，人类与机器之间的完美分工是怎样的？Schmidhuber：人类完全不应该做辛苦而枯燥的工作，计算机来做。InfoQ：你因在递归神经网络（RNN），尤其是长短期记忆（LSTM）上的开创性成果而声名远播，这种技术现已在深度学习中得到了广泛的应用。你可以给我们简短说明一下LSTM的背景和技术吗？你认为LSTM最适合哪些领域？有什么现实世界的案例吗？Schmidhuber：监督LSTM RNN是通用目的的计算机，可以学习处理视频和语音等各种序列任务的并行序列程序。自90年代早期以来，它们已在我的实验室中被一些优秀的博士生和博士后开发出来，其中包括Sepp Hochreiter、Felix Gers、Alex Graves、Santi Fernandez、Faustino Gomez、Daan Wierstra、Justin Bayer等人。部分LSTM RNN的设计让反向传播的错误既不消失也不爆发，而是以一种「文明的」方式通过几千甚至更多个步骤倒流回去。因此，LSTM的变体版本可以从之前不可学习的「Very Deep Learning」任务中进行学习，这些任务要求发现（和记忆）发生在数千个离散时间步骤之前的事件的重要性；而之前的标准RNN在最短10步时间延迟的情况下已经失败。它甚至可能演化出很好的针对特定问题的LSTM一样的拓扑结构。

大约2007年的时候，我们的CTC（2006年）训练的LSTM开始革新语音识别，性能表现超越了键盘识别任务中传统方法。谷歌后来也用LSTM以帮助改进现有的技术，包括图像字幕（2014年）、机器翻译（2014年）、文本到语音合成（2015年，现在可在谷歌Android上使用）、自然语言处理的句法分析（2015年）等其它许多应用。2015年，CTC训练的LSTM极大地改善了Google Voice（49%）——现在有超过10亿智能手机用户可以使用它。微软和IBM和其它著名公司也在大量使用LSTM。InfoQ：你的团队赢得了九次国际模式识别大赛，举一两个例子，例如手写识别和交通标志识别。你们是怎么办到的？Schmidhuber：我的团队确实为多次赢得比赛而感到自豪，其中包括：MICCAI 2013有丝分裂检测挑战赛ICPR 2012乳腺癌组织学图片有丝分裂检测大赛ISBI 2012脑图像分割挑战赛IJCNN 2011交通标志识别大赛ICDAR 2011离线中国书法大赛在线德国交通标志识别大赛ICDAR 2009阿拉伯语连接手写大赛ICDAR 2009波斯语/阿拉伯语手写字符识别大赛ICDAR 2009法语连接手写大赛我们团队又是如何做到的？通过创新、执着、拼搏和奉献。InfoQ：你也在very deep nets上做出了特殊的重要性，不是吗？Schmidhuber：既然深度意味着计算力和效率，我们从一开始就关注着very deep neural nets。比如说，1990年代早期，当其他人还受限于少于10个后续计算层的相当浅的网络时，我们的方法已经可以启用超过1000个这样的计算层了。我得说，我们就是将神经网络做得非常深的人，尤其是递归网络——它们中最深最强大的网络。当时，很少有研究者对此感兴趣，但我们坚持了下来，随着计算力越来越便宜，通过这样的方法赢得比赛只是时间问题。我很高兴看到其它深度学习实验室和公司现在也大量使用我们的算法。InfoQ：上面的比赛是关于模式识别的——对于强化学习（reinforcement learning）和无师自通序贯决策（sequential decision）的更加通用的领域，你推荐什么方法？Schmidhuber：我们喜欢我们的压缩网络研究，它超越了单纯的模式识别，发现了权重值为一百万的复杂神经控制器，并且（在2012年）成为了第一种依靠强化学习直接从高维度感官输入学会控制策略的方法。如果想了解更多，可查看前面提到的关于「学会思考（learning to think）」的报告。InfoQ: 对于深度学习和人工智能，你最近的研究兴趣是什么？Schmidhuber：我最近的研究兴趣仍然是我早在20世纪80年代阐述过的那些：「开发出比我更聪明的人工智能，这样我就可以退休了。」这需要的不仅仅是普通的深度学习。它需要自我指涉通用目的的学习算法，这种算法不仅改善给定领域某些系统性能，还改善它们学习的方式，以及它们学习方式的方式，等等，仅受限于可计算性的根本局限性。从1987年将这个问题作为学位论文选题以来，我一直在研究这个包罗万象的内容，但是现在我能看到这个主题正开始变成一个可能实现的现实。&nbsp;InfoQ: 自从去年作为一家深度学习创业公司启动以来，NNAISENSE 已经受到关注。你是这家公司掌门人，能和我们多谈谈 NNAISENSE 吗？对于这次新冒险，你的计划是什么？Schmidhuber：NNAISENSE 的发音像「nascence」，因为它与孕育一个通用目的的以神经网络为基础的人工智能（ NNAI ）有关。公司有5位联合创始人，几位雇员，非常强的研究团队，收益来自正在工业和金融（以及与投资人交谈）领域进行的最先进的应用。我们相信，我们能实现巨大的实践性突破，这一突破将改变一切，与上世纪80年代的老座右铭相符：「开发出比我更聪明的人工智能，这样我就可以退休了。」InfoQ: 在不久的将来，人工智能产业的发展前景是什么？哪些领域会冒出杀手级 apps ？会有瓶颈吗？Schmidhuber: 在 reddit 的 AMA 上，我指出，机器学习和神经网络算法将在许多领域（从医疗诊断到更加智能的电话）取得许多重要的超人般的成绩，更好理解和解决你的许多难题，并且让你更依赖它们。我推测我们正在见证这一领域爆炸式发展的点火阶段。但是，如何从内部预测爆炸时细节？假定计算能力以每十年100欧元的速度继续变得便宜，到了2036年，同等价位的计算机将比如今快10,000倍。这听上去多少有点像一个小巧的便携式设备拥有了人的脑力，或者像更大的计算机拥有了城市那么大的大脑能力。 鉴于这种尚未成熟的计算能力，我预期（以今天的标准）在专用硬件上运行的巨大RNNs能同时从许多资料来源中感知和分析海量的多模态数据流（语音、文本、视频和许多其它模态），学会关联所有这些输入，并且使用提取出的信息实现无数的商业和非商业目标。递归神经网络将持续快速地在已知的基础上学习新技能。这里应该有无数的应用，虽然我甚至不确定「应用」这个词在这里是否仍有意义。InfoQ: 那么，下一步是什么？Schmidhuber：孩子甚至某些小动物仍然比最好的自我学习（self-learning）机器人聪明得多。但是，我相信，在不那么多年之内，我们就能搭建起基于NN的人工智能（NNAI），逐渐学会和小动物一样聪明，以非常通用的方式学会规划、推理以及将各种各样问题快速分解成可以解决（或已经解决）的子问题。通过关于乐趣的形式理论（formal theory of fun），甚至有可能让机器具有好奇心和创造力，打造出无监督式的人工科学家。InfoQ：一旦我们实现动物水平的人工智能，将发生什么？Schmidhuber：迈向人类水平的人工智能的下一步可能不会那么巨大：大自然花了数十亿年时间演化出智能动物，在此基础上，只花了数百万年演化出人类。技术进化远比生物进化快速地多。也就是说，一旦我们实现动物水平的人工智能，几年或数十年以后，我们或许就能实现人类水平的人工智能，将有真正无限多的应用，而且每个行业都将改变，整个文明都将改变，一切都将改变。InfoQ：人工智能的长远未来是什么？Schmidhuber：超级聪明的人工智能或许不久将殖民太阳系，然后在数百万年内殖民整个银河系。宇宙想要让它迈出通往越来越深不可测复杂性的下一步。"
"机器学习;;对话机器学习明星Nando de FreitasNando de Freitas是一名来自牛津大学的拥有高声望和优良业界口碑的机器学习教授。在2000年拿到Trinity College的博士学位后，1999至2001年他在 UC Berkeley担任博后，2001至2014年在 University of British Columbia担任教授，他还是加拿大高级科研学会（CIFAR）的一员，并拿到了许多学术类的奖项。Nando本人在其网站上这样简洁地描述他的兴趣：我想明白智能以及思考的机理。我的工具有计算机科学，统计学，数学和无尽的思考。2015年12月26日，Nando de Freitas加入了由Reddit管理的AMA（Ask Me Anything）平台，本文是作者 Matthew Mayo对 Nando教授在AMA平台上的回答以及相应评论的总结。Nando de Freitas除了对目前机器学习、学习理论和深度学习的状态的特定问答外，在整个AMA问答过程中，Nando主要有如下观点：&nbsp;1、Nando似乎对那些影响人工智能未来与机器学习研究和实现的公平性问题很关心。他认为需要解决相较于白人男性，女性、少数民族和其他群体代表性不足的问题，这不仅仅是简单的数字问题，这将会对社会有很大影响。Freitas认为让所有的社会群体共同塑造其未来至关重要，他相信教育及教育质量会在其中起作用，在这一领域几个有关不平等的问题需要解决，包括：恶意地将教育质量与物质财产相关联。 Nando说道：&nbsp;我并没有说这一定是谁的错。相反，我想表达的是我们需要找到问题的本质并理解它。我觉得只有白人讨论的未来是非常愚蠢的。&nbsp;2、与过去一年中一些针对于AI人格的论调不同的是，Nando似乎对于天网式人工智能灭世理论并不太担心。但是他确实意识到这类技术正在改变人类和其生活方式，我们应该对于这类发展和带来的反响有深刻的认知。同时他也提到了一些关于「自我意识人工智能」的谣言。我认为对于那些担心类似于《终结者》电影的情节并采取措施有点偏离问题本身了， 我对于这些媒体的报道并不感冒。但是，我们确实应该担心科技正在改变人类的这个事实。并且有必要担心诸如科技在战争中的开发和使用、人工智能研究者缺乏种族多样性和女性、有人喜欢利用人工智能来吓唬别人却不关心如何使用人工智能来改善我们的世界等问题。&nbsp;3、Nando教授花时间清晰地思考、讨论和理性地解释了什么是「智能」。&nbsp;智能真的只是一个环境的产物么？它深不可测吗？或者只不过是一个记忆，感觉和行动的单纯结合体（就好像我早上起来会感觉到饿）？&nbsp;4、他似乎对人工智能将给人类所带来的未来持积极观点。&nbsp;我认为深度网络只是迈向更智能的计算机的一小步。通过用机器来拓展我们的智能，我认为我们会更有希望解决很多诸如财富分配和癌症等复杂问题。但是为了让这一切发生我们需要强有力的领导者。&nbsp;在技术层面，用户们提出了很多关于深度学习未来的普遍问题，包括 Nando教授的研究背景以及大量与贝叶斯方法和深度学习结合的问题。下面，我们就来看一些很棒的问题以及Nando de Freitas的相应回复。许多问题揭示了Nando对于未来人工智能、机器学习和深度学习发展方向的洞察和思考。&nbsp;以下则为Nando教授的问答内容：人工智能是否在蓄势待发？Reddit用户dexter89_kp 提问：我曾经问过AI 领域的专家LeCun教授一个类似的问题：您认为在机器学习领域中，接下来的五年内最亟待解决的两个问题是什么？希望能够站在一个想要读取机器学习博士学位学生的角度来回答。Nando回复：有这样一些主题：低样本复杂度的深度强化学习和深度学习。它们在医疗健康、环境、探索新数据方面的应用对人类很有用。可以考虑这些项目，类似于目标，逻辑关系，计划，算法等等，高效利用的机器学习。rmcantin提问：蒙特卡洛以及神经网络方法最大的一个特点就是他们能够向上扩展可用资源的潜在能力。你认为在近期内，如果我们有足够的计算能力对十亿（或者万亿）级别的粒子抽样进行深度网络权值预测或者全贝叶斯深度学习，是否会出现蒙特卡洛方法的二次复兴？或者是说，你是否认为贝叶斯优化方法可以在这个问题领域中追赶上来？Nando回复：我在期待着Yee Whye Teh或是Arnaud Doucet来引领新的蒙特卡洛革新，然而，我们首先需要确保的是，我们已经理解了深度学习。其实，这些高维度模型背后的数学原理以及学习过程中优化的具体手段都还没有得到很好的理解。我确实认为贝叶斯优化对深度学习来说是非常重要的，但是它需要被恰到好处地使用，这也确实不简单，并且需要很多工作。我也期待着像你这样的人去研究相关细节。spaceanubisl提问：我想知道你对于无监督学习（或者one-shot学习）有什么看法？在可见的未来你认为这些将如何得以实现？Nando 回复：对于我来说，学习从不是无监督的。无论是预测当前的数据（自动编码器），下一帧数据，或者其他数据形态，这些任务中总会出现一个目标。真正的问题是说我们怎么想出比较好的目标信号（标签）来自动进行学习？诸如ImageNet的人现在正花费大量精力研究时间标记数据集这方面的问题。maltoss提问：根据你自身的研究，能否请你详细描述接下来在贝叶斯方法或者深度学习中会有什么样的具体研究工作步骤？Nando回复：一部分人运用信息理论来学习自动编码器——在这样的设置之下我们无法了解其优先价值。另有些人就利用了贝叶斯的相关算法思想来存留置信区间---但是引导程序也能够得以同等使用。真正使它变得有趣起来的地方是人们可以运用类似的深度学习想法去做贝叶斯推理。与此相关的一个实例是Kevin Murphy和他的同事们使用提取法（又名黑知识）来减弱贝叶斯模型平均的代价消耗。我也认为深度网络有足够大能力来实现贝叶斯相关法则以及采样法则。这将会产生非常多的乐趣。

继续针对贝叶斯方法，HillbillyBoy提问：贝叶斯优化看起来是现今一个热门的话题：

1.自从90s年代之后，在研究方面现在有什么样变革性的突破呢？

2.你如何看待接下来五年内这一领域的走向趋势？Nando回复：1.这领域有很多的方法学或者理论上的进展。Ryan Adams和他的团队，Philipp Hennig，Frank Hutter , Matt Hofmann，Ziyu Wang，Bobak Shahriari，Ruben Martinez-Cantin 以及其他很多很多人（详见我们最近的贝叶斯优化概览）都在做着非常重要的创新工作。
2.我们需要一个特别的证明：比如全自动化的Torch或者Caffe,所以在给定一个数据集和问题说明的情况下（比如ImageNet网站），贝叶斯优化自动生成了代码（包含具体结构和算法说明）赢得了ImageNet比赛。关于Nando本人的问题zhongwenxu提问：如果不考虑主要的基础设施和设备资源方面的因素，您觉得在DeepMind与在牛津大学的科研经历最关键的差异是什么？Nando回复：DeepMind的工作氛围十分有活力，这里聚集着一批专注于解决问题的卓越人才，每周都会有成员让我惊喜。各项支持也非常棒，同事关系和谐。牛津大学同样是鼎鼎大名。然而相较于技术层面，在DeepMind工作会更加关注问题本身和攻坚（当然两者同样重要）。其行业内的管理干预会相对更少，薪资待遇也比高校要好很多。你无法想象计算机科学的教授和教师的酬劳有多低，尤其是在欧洲，在我看来较之其他的许多工作，其贡献也更少。教授们至少要能付得起房租，毕竟他们工作如此辛苦。up7up提问：强人工智能可能产生吗？是什么阻碍了它的实现？组合性爆炸？维数灾难？P/NP问题？还是另有其他？Nando回复：谢谢。我不认为我们能很好的把握智能究竟为何物。同样，我们对于「 智能由什么构成」这个问题的理解也在不断变化。

创造与人类能力相当的机器看似是合理的。但人类要解决NP问题或组合性爆炸问题却没那么容易。似乎有比「让机器具备人工智能」要复杂得多的问题。

作为以上内容的相关随访，也是为了展示Nando是如何花时间思索「 智能」这个问题的，下面的内容是摘自与此相关的一个其他问题的回答：

如果你将整个人类置于一个只把一点点食物直接注射到静脉里的黑暗的无声房间中，你觉得会发生什么？十年后我怀疑也不会产生什么智能，尽管事实上几千年的环境适应具象化事实已经通过基因传递了下来。lars_的问题能够让我们了解Nando如何考虑这些的：近些天你问过自己什么问题？什么样的问题你最想寻找出它的答案？

以下是摘自Nando的回答（有很多非常棒的问题，这里无法全部囊括）：我该利用怎样的数据集来获取有效信息？我非常赞同用创造性的方式使用数据。举例来说，最近一篇由Karl Moritz Hermann和其同事们撰写的论文，论述了如何教机器进行阅读。我们该如何使其自动化？这种自动化对于我而言就是无监督式学习。

智能仅仅就是对环境的一种映射结论吗？它是否有更深层次的含义？又或是如我上述所提到的，仅仅是对于记忆、知觉以及行为的多模式联合？

我们何时才能最终使Vanilla递归网络和卷积神经网络的架构完全自动化？贝叶斯优化算法目前无疑是可以完成此项工作的。使用Torch框架来编写神经网络是可以自动化的。我们需要弄明白的是怎样为其进行设计代码，或者是搞清其中的绊脚石是什么。Nando教授对专业与学术生涯的建议datagibus420提问：你好Nando教授！如果只有一本机器学习方面的书可以推荐，你会选哪一本？——你会计划在MOOC上开设有关深度学习的课程吗，或者还是关于机器学习？另外，很感谢你在YouTube上传的课程，它们棒极了！Nando回复：我很喜欢Kevin Murphy的书。他现在正在写一版新的，其中将会有更好的关于深度学习的章节。它能够或多或少地与我在YouTube上传的深度学习课程接轨。谢谢你的支持与积极反馈。learnin_no_bully_pls提问：我想学习所有机器学习研究所需要的数学知识并理解它们。我需要在读书列表中加上什么呢？Nando回复：微积分与线性几何是基础，请确定你知道梯度、线性方程组、优化基础、特征值等等，Kreyszig的《Advanced Engineering Mathematics 》提供了足够的背景知识。数学之所以非常有用是因为它让我们学习新的抽象知识（例如递归和函数）并且能够对它们进行逻辑推理。学习过程可以带来新的发现、更快更简洁的参数以及思想间更准确的交流。Pafnouti 提问：我读了很多Facebook、谷歌和一些公司的文章，看似过于经验主义，例如「我们试了这个，还试了那个，然后这是我们的结果blablabla」，没有足够的理论工作。因此我很好奇博士为了毕业论文花费3到4年的时间去做这种东西到底有何意义，或者在这个领域有经验（当然不像博士的强度一样大）在现实工作中是否有用处。Nando回复：大部分行业试验室的确要求有博士学位。我真的很推荐在机器学习领域去读取一个博士学位，因为你会学到很多。我不认为「我试了这个还有那个然后这是我们的结果」是对于谷歌、Facebook、Twitter、微软和其他实验室所做的工作的准确描述。在方法和理论方面我们有了很多重要的进步，而这些来自于行业内的实践。

作者按：说到这一点，图灵在他改变了AI和哲学世界时也没有得到PhD对不对？&nbsp;最重要的，vivanov提问：Tensorflow和Torch，选哪个？Nando既圆滑地又实际地回复：哈哈！两个现在都要。

在分享了许多私人故事之后，他在过去几年学会了很多经验，也融合了许多核心的信念，大部分来自于看起来非常深层的正义感，（必要地）专注于世界糟糕的部分以解释为何一些特殊的事件能够将一个人定型，他引用这句话说道，虽然与机器学习无关，但是对于这篇文章是一个完美的结束。

幸运的是，这个世界和过去相比已经变成了更好的地方。Yoshua Bengio告诉我他相信人类，宽恕与热情将会绵延不绝，我希望他是对的。

我强烈推荐阅读完整的AMA，它不会令你失望的。作者：Matthew Mayo是一位计算机科学研究生，正在进行有关并行机器学习算法的论文。他还学习过数据挖掘，是一位数据发烧友，也是一位有热情的机器学习科学家。"
产业;;腾讯AI Lab启动首届学术论坛，正式宣布张潼出任实验室主任2017 年 3 月 23 日，腾讯宣布任命人工智能领域顶尖科学家张潼博士担任腾讯 AI Lab（腾讯人工智能实验室）主任。张潼博士将作为腾讯 AI Lab 第一负责人，带领 50 余位 AI 科学家及 200 多位 AI 应用工程师团队，专注于人工智能的基础研究，主要包括计算机视觉、语音识别、自然语言处理和机器学习这四个垂直领域。同时，基于腾讯自身的业务需求，腾讯 AI Lab 还会在内容、社交、游戏和平台工具型 AI 四个方向进行研发与应用合作。腾讯公司总裁刘炽平表示，「张潼博士是人工智能领域的技术权威。我们很高兴能够邀请到张潼博士加盟腾讯，全面负责腾讯 AI Lab。人工智能的高速发展除了依靠算法和计算能力的快速提升外，也离不开丰富的应用场景、海量的大数据及强大的计算能力。在过去 18 年里，腾讯在这些方面有了很多的积累，这对于我们 AI Lab 的发展来说是一个重要的基础。未来，我们还会持续加大在科研领域的资源投入，专注提升 AI 的技术能力和应用场景，以科技提升人们的生活品质。」腾讯 AI Lab 主任张潼表示：「我很荣幸能够参与腾讯 AI Lab 的筹建。我们将专注于人工智能的基础研究及应用探索，不断提升 AI 的决策、理解及创造能力，同时为腾讯的各产品业务提供 AI 技术支撑。腾讯在场景、数据和计算能力上的丰富积累，是 AI 领域研究人员所渴求的基础条件。我注意到，世界范围内的华裔人才在 AI 领域有很强的技术优势，这是中国发展 AI 的机会。目前，腾讯 AI Lab 已经吸引了一批顶尖的研发人才，50 余名科研人员中 90% 以上有 AI 相关博士学位和海外留学背景。我们还将通过构建产学研一体化生态，激发 AI 领域的人才深度研究和探索的机会。可以说，腾讯的 AI 非常具有想象力。」当天，腾讯 AI Lab 在深圳启动首届学术论坛，邀请来自普林斯顿大学、北京大学、复旦大学等 10 位海内外顶级 AI 学者出席，分享了计算机视觉、机器学习和自然语言处理等领域最新研究成果并作交流。张潼博士在论坛的演讲中提到了一些自己在腾讯 AI Lab 所做的事情，以及 AI Lab 的整体方向。他表示，腾讯在这个时间点做 AI 是非常合适的，而且有着非常好的优势。首先腾讯有着非常丰富的业务场景，有了业务场景之后才可以非常好的输入技术。腾讯有游戏、社交、内容这让非常好的业务场景。第二点优势是有海量的数据。国内互联网公司，尤其是 BAT 都会有海量的数据。此外还有计算资源的优势等。张潼博士还谈到的一点是为什么中国的 AI 能够走到与美国接近的地步？原因就是国内的互联网企业培养了一系列的人才，这些工程师都有很强的数据处理能力。张潼介绍说腾讯 AI Lab 的整体方向可分为四块：核心的底层技术机器学习、垂直的应用计算机视觉、语音识别与自然语言处理。从研究角度来说，张潼表示他们会专注于强化学习，此外还有生成式模型和认知科学，这三个研究方面分别与机器的决策、创造、理解有关。谈到张潼博士在腾讯做的项目，他提到 3 月 19 日刚刚落幕的第 10 届 UEC 杯计算机围棋大赛上，腾讯 AI Lab 研发的围棋人工智能程序「绝艺」（Fine Art）11 战全胜斩获冠军，并将于 26 日与日本著名新锐棋手一力辽在「电圣战」中进行人机对弈。「绝艺」团队在东京 UEC 杯夺冠此外，张潼表示之后腾讯会把逐渐积累的人工智能技术通过云或者开放平台这样不同的形式（API 等）服务于更多的人。谈到最近紧缺的人工智能人才，张潼表示腾讯会一方面吸引人才、一方面自己培训人才，且与多所大学有紧密的合作。张潼简介张潼博士是中央组织部「千人计划」特聘专家，拥有美国康奈尔大学数学系和计算机系学士，以及斯坦福大学计算机系硕士和博士学位。加入腾讯前，张潼博士曾经担任美国新泽西州立大学教授、IBM 研究院研究员、雅虎研究院主任研究员，百度研究院副院长和大数据实验室负责人，期间参与和领导开发过多项机器学习算法和应用系统。张潼博士曾参加美国国家科学院大数据专家委员会，并负责过多个美国国家科学基金（National Science Foundation）资助的大数据研究项目。此外，张潼博士是美国统计学会和国际数理统计学会 Fellow，并担任 NIPS（神经信息处理系统进展大会）、ICML（国际机器学习大会）、COLT（学习理论大会）等国际顶级机器学习会议主席或领域主席，以及 JMLR（机器学习研究期刊）和 Machine Learning Journal（机器学习期刊）等国际一流人工智能期刊编委。 &nbsp;
张潼;;腾讯AI Lab启动首届学术论坛，正式宣布张潼出任实验室主任2017 年 3 月 23 日，腾讯宣布任命人工智能领域顶尖科学家张潼博士担任腾讯 AI Lab（腾讯人工智能实验室）主任。张潼博士将作为腾讯 AI Lab 第一负责人，带领 50 余位 AI 科学家及 200 多位 AI 应用工程师团队，专注于人工智能的基础研究，主要包括计算机视觉、语音识别、自然语言处理和机器学习这四个垂直领域。同时，基于腾讯自身的业务需求，腾讯 AI Lab 还会在内容、社交、游戏和平台工具型 AI 四个方向进行研发与应用合作。腾讯公司总裁刘炽平表示，「张潼博士是人工智能领域的技术权威。我们很高兴能够邀请到张潼博士加盟腾讯，全面负责腾讯 AI Lab。人工智能的高速发展除了依靠算法和计算能力的快速提升外，也离不开丰富的应用场景、海量的大数据及强大的计算能力。在过去 18 年里，腾讯在这些方面有了很多的积累，这对于我们 AI Lab 的发展来说是一个重要的基础。未来，我们还会持续加大在科研领域的资源投入，专注提升 AI 的技术能力和应用场景，以科技提升人们的生活品质。」腾讯 AI Lab 主任张潼表示：「我很荣幸能够参与腾讯 AI Lab 的筹建。我们将专注于人工智能的基础研究及应用探索，不断提升 AI 的决策、理解及创造能力，同时为腾讯的各产品业务提供 AI 技术支撑。腾讯在场景、数据和计算能力上的丰富积累，是 AI 领域研究人员所渴求的基础条件。我注意到，世界范围内的华裔人才在 AI 领域有很强的技术优势，这是中国发展 AI 的机会。目前，腾讯 AI Lab 已经吸引了一批顶尖的研发人才，50 余名科研人员中 90% 以上有 AI 相关博士学位和海外留学背景。我们还将通过构建产学研一体化生态，激发 AI 领域的人才深度研究和探索的机会。可以说，腾讯的 AI 非常具有想象力。」当天，腾讯 AI Lab 在深圳启动首届学术论坛，邀请来自普林斯顿大学、北京大学、复旦大学等 10 位海内外顶级 AI 学者出席，分享了计算机视觉、机器学习和自然语言处理等领域最新研究成果并作交流。张潼博士在论坛的演讲中提到了一些自己在腾讯 AI Lab 所做的事情，以及 AI Lab 的整体方向。他表示，腾讯在这个时间点做 AI 是非常合适的，而且有着非常好的优势。首先腾讯有着非常丰富的业务场景，有了业务场景之后才可以非常好的输入技术。腾讯有游戏、社交、内容这让非常好的业务场景。第二点优势是有海量的数据。国内互联网公司，尤其是 BAT 都会有海量的数据。此外还有计算资源的优势等。张潼博士还谈到的一点是为什么中国的 AI 能够走到与美国接近的地步？原因就是国内的互联网企业培养了一系列的人才，这些工程师都有很强的数据处理能力。张潼介绍说腾讯 AI Lab 的整体方向可分为四块：核心的底层技术机器学习、垂直的应用计算机视觉、语音识别与自然语言处理。从研究角度来说，张潼表示他们会专注于强化学习，此外还有生成式模型和认知科学，这三个研究方面分别与机器的决策、创造、理解有关。谈到张潼博士在腾讯做的项目，他提到 3 月 19 日刚刚落幕的第 10 届 UEC 杯计算机围棋大赛上，腾讯 AI Lab 研发的围棋人工智能程序「绝艺」（Fine Art）11 战全胜斩获冠军，并将于 26 日与日本著名新锐棋手一力辽在「电圣战」中进行人机对弈。「绝艺」团队在东京 UEC 杯夺冠此外，张潼表示之后腾讯会把逐渐积累的人工智能技术通过云或者开放平台这样不同的形式（API 等）服务于更多的人。谈到最近紧缺的人工智能人才，张潼表示腾讯会一方面吸引人才、一方面自己培训人才，且与多所大学有紧密的合作。张潼简介张潼博士是中央组织部「千人计划」特聘专家，拥有美国康奈尔大学数学系和计算机系学士，以及斯坦福大学计算机系硕士和博士学位。加入腾讯前，张潼博士曾经担任美国新泽西州立大学教授、IBM 研究院研究员、雅虎研究院主任研究员，百度研究院副院长和大数据实验室负责人，期间参与和领导开发过多项机器学习算法和应用系统。张潼博士曾参加美国国家科学院大数据专家委员会，并负责过多个美国国家科学基金（National Science Foundation）资助的大数据研究项目。此外，张潼博士是美国统计学会和国际数理统计学会 Fellow，并担任 NIPS（神经信息处理系统进展大会）、ICML（国际机器学习大会）、COLT（学习理论大会）等国际顶级机器学习会议主席或领域主席，以及 JMLR（机器学习研究期刊）和 Machine Learning Journal（机器学习期刊）等国际一流人工智能期刊编委。 &nbsp;
应用;;腾讯AI Lab启动首届学术论坛，正式宣布张潼出任实验室主任2017 年 3 月 23 日，腾讯宣布任命人工智能领域顶尖科学家张潼博士担任腾讯 AI Lab（腾讯人工智能实验室）主任。张潼博士将作为腾讯 AI Lab 第一负责人，带领 50 余位 AI 科学家及 200 多位 AI 应用工程师团队，专注于人工智能的基础研究，主要包括计算机视觉、语音识别、自然语言处理和机器学习这四个垂直领域。同时，基于腾讯自身的业务需求，腾讯 AI Lab 还会在内容、社交、游戏和平台工具型 AI 四个方向进行研发与应用合作。腾讯公司总裁刘炽平表示，「张潼博士是人工智能领域的技术权威。我们很高兴能够邀请到张潼博士加盟腾讯，全面负责腾讯 AI Lab。人工智能的高速发展除了依靠算法和计算能力的快速提升外，也离不开丰富的应用场景、海量的大数据及强大的计算能力。在过去 18 年里，腾讯在这些方面有了很多的积累，这对于我们 AI Lab 的发展来说是一个重要的基础。未来，我们还会持续加大在科研领域的资源投入，专注提升 AI 的技术能力和应用场景，以科技提升人们的生活品质。」腾讯 AI Lab 主任张潼表示：「我很荣幸能够参与腾讯 AI Lab 的筹建。我们将专注于人工智能的基础研究及应用探索，不断提升 AI 的决策、理解及创造能力，同时为腾讯的各产品业务提供 AI 技术支撑。腾讯在场景、数据和计算能力上的丰富积累，是 AI 领域研究人员所渴求的基础条件。我注意到，世界范围内的华裔人才在 AI 领域有很强的技术优势，这是中国发展 AI 的机会。目前，腾讯 AI Lab 已经吸引了一批顶尖的研发人才，50 余名科研人员中 90% 以上有 AI 相关博士学位和海外留学背景。我们还将通过构建产学研一体化生态，激发 AI 领域的人才深度研究和探索的机会。可以说，腾讯的 AI 非常具有想象力。」当天，腾讯 AI Lab 在深圳启动首届学术论坛，邀请来自普林斯顿大学、北京大学、复旦大学等 10 位海内外顶级 AI 学者出席，分享了计算机视觉、机器学习和自然语言处理等领域最新研究成果并作交流。张潼博士在论坛的演讲中提到了一些自己在腾讯 AI Lab 所做的事情，以及 AI Lab 的整体方向。他表示，腾讯在这个时间点做 AI 是非常合适的，而且有着非常好的优势。首先腾讯有着非常丰富的业务场景，有了业务场景之后才可以非常好的输入技术。腾讯有游戏、社交、内容这让非常好的业务场景。第二点优势是有海量的数据。国内互联网公司，尤其是 BAT 都会有海量的数据。此外还有计算资源的优势等。张潼博士还谈到的一点是为什么中国的 AI 能够走到与美国接近的地步？原因就是国内的互联网企业培养了一系列的人才，这些工程师都有很强的数据处理能力。张潼介绍说腾讯 AI Lab 的整体方向可分为四块：核心的底层技术机器学习、垂直的应用计算机视觉、语音识别与自然语言处理。从研究角度来说，张潼表示他们会专注于强化学习，此外还有生成式模型和认知科学，这三个研究方面分别与机器的决策、创造、理解有关。谈到张潼博士在腾讯做的项目，他提到 3 月 19 日刚刚落幕的第 10 届 UEC 杯计算机围棋大赛上，腾讯 AI Lab 研发的围棋人工智能程序「绝艺」（Fine Art）11 战全胜斩获冠军，并将于 26 日与日本著名新锐棋手一力辽在「电圣战」中进行人机对弈。「绝艺」团队在东京 UEC 杯夺冠此外，张潼表示之后腾讯会把逐渐积累的人工智能技术通过云或者开放平台这样不同的形式（API 等）服务于更多的人。谈到最近紧缺的人工智能人才，张潼表示腾讯会一方面吸引人才、一方面自己培训人才，且与多所大学有紧密的合作。张潼简介张潼博士是中央组织部「千人计划」特聘专家，拥有美国康奈尔大学数学系和计算机系学士，以及斯坦福大学计算机系硕士和博士学位。加入腾讯前，张潼博士曾经担任美国新泽西州立大学教授、IBM 研究院研究员、雅虎研究院主任研究员，百度研究院副院长和大数据实验室负责人，期间参与和领导开发过多项机器学习算法和应用系统。张潼博士曾参加美国国家科学院大数据专家委员会，并负责过多个美国国家科学基金（National Science Foundation）资助的大数据研究项目。此外，张潼博士是美国统计学会和国际数理统计学会 Fellow，并担任 NIPS（神经信息处理系统进展大会）、ICML（国际机器学习大会）、COLT（学习理论大会）等国际顶级机器学习会议主席或领域主席，以及 JMLR（机器学习研究期刊）和 Machine Learning Journal（机器学习期刊）等国际一流人工智能期刊编委。 &nbsp;
腾讯AI Lab;;腾讯AI Lab启动首届学术论坛，正式宣布张潼出任实验室主任2017 年 3 月 23 日，腾讯宣布任命人工智能领域顶尖科学家张潼博士担任腾讯 AI Lab（腾讯人工智能实验室）主任。张潼博士将作为腾讯 AI Lab 第一负责人，带领 50 余位 AI 科学家及 200 多位 AI 应用工程师团队，专注于人工智能的基础研究，主要包括计算机视觉、语音识别、自然语言处理和机器学习这四个垂直领域。同时，基于腾讯自身的业务需求，腾讯 AI Lab 还会在内容、社交、游戏和平台工具型 AI 四个方向进行研发与应用合作。腾讯公司总裁刘炽平表示，「张潼博士是人工智能领域的技术权威。我们很高兴能够邀请到张潼博士加盟腾讯，全面负责腾讯 AI Lab。人工智能的高速发展除了依靠算法和计算能力的快速提升外，也离不开丰富的应用场景、海量的大数据及强大的计算能力。在过去 18 年里，腾讯在这些方面有了很多的积累，这对于我们 AI Lab 的发展来说是一个重要的基础。未来，我们还会持续加大在科研领域的资源投入，专注提升 AI 的技术能力和应用场景，以科技提升人们的生活品质。」腾讯 AI Lab 主任张潼表示：「我很荣幸能够参与腾讯 AI Lab 的筹建。我们将专注于人工智能的基础研究及应用探索，不断提升 AI 的决策、理解及创造能力，同时为腾讯的各产品业务提供 AI 技术支撑。腾讯在场景、数据和计算能力上的丰富积累，是 AI 领域研究人员所渴求的基础条件。我注意到，世界范围内的华裔人才在 AI 领域有很强的技术优势，这是中国发展 AI 的机会。目前，腾讯 AI Lab 已经吸引了一批顶尖的研发人才，50 余名科研人员中 90% 以上有 AI 相关博士学位和海外留学背景。我们还将通过构建产学研一体化生态，激发 AI 领域的人才深度研究和探索的机会。可以说，腾讯的 AI 非常具有想象力。」当天，腾讯 AI Lab 在深圳启动首届学术论坛，邀请来自普林斯顿大学、北京大学、复旦大学等 10 位海内外顶级 AI 学者出席，分享了计算机视觉、机器学习和自然语言处理等领域最新研究成果并作交流。张潼博士在论坛的演讲中提到了一些自己在腾讯 AI Lab 所做的事情，以及 AI Lab 的整体方向。他表示，腾讯在这个时间点做 AI 是非常合适的，而且有着非常好的优势。首先腾讯有着非常丰富的业务场景，有了业务场景之后才可以非常好的输入技术。腾讯有游戏、社交、内容这让非常好的业务场景。第二点优势是有海量的数据。国内互联网公司，尤其是 BAT 都会有海量的数据。此外还有计算资源的优势等。张潼博士还谈到的一点是为什么中国的 AI 能够走到与美国接近的地步？原因就是国内的互联网企业培养了一系列的人才，这些工程师都有很强的数据处理能力。张潼介绍说腾讯 AI Lab 的整体方向可分为四块：核心的底层技术机器学习、垂直的应用计算机视觉、语音识别与自然语言处理。从研究角度来说，张潼表示他们会专注于强化学习，此外还有生成式模型和认知科学，这三个研究方面分别与机器的决策、创造、理解有关。谈到张潼博士在腾讯做的项目，他提到 3 月 19 日刚刚落幕的第 10 届 UEC 杯计算机围棋大赛上，腾讯 AI Lab 研发的围棋人工智能程序「绝艺」（Fine Art）11 战全胜斩获冠军，并将于 26 日与日本著名新锐棋手一力辽在「电圣战」中进行人机对弈。「绝艺」团队在东京 UEC 杯夺冠此外，张潼表示之后腾讯会把逐渐积累的人工智能技术通过云或者开放平台这样不同的形式（API 等）服务于更多的人。谈到最近紧缺的人工智能人才，张潼表示腾讯会一方面吸引人才、一方面自己培训人才，且与多所大学有紧密的合作。张潼简介张潼博士是中央组织部「千人计划」特聘专家，拥有美国康奈尔大学数学系和计算机系学士，以及斯坦福大学计算机系硕士和博士学位。加入腾讯前，张潼博士曾经担任美国新泽西州立大学教授、IBM 研究院研究员、雅虎研究院主任研究员，百度研究院副院长和大数据实验室负责人，期间参与和领导开发过多项机器学习算法和应用系统。张潼博士曾参加美国国家科学院大数据专家委员会，并负责过多个美国国家科学基金（National Science Foundation）资助的大数据研究项目。此外，张潼博士是美国统计学会和国际数理统计学会 Fellow，并担任 NIPS（神经信息处理系统进展大会）、ICML（国际机器学习大会）、COLT（学习理论大会）等国际顶级机器学习会议主席或领域主席，以及 JMLR（机器学习研究期刊）和 Machine Learning Journal（机器学习期刊）等国际一流人工智能期刊编委。 &nbsp;
人工智能;;Facebook推出人工智能引擎DeepText引言：前几天，有新闻报道在查举不良图片方面，Facebook 的人工智能战胜了人工。今天，这家公司人工智能研究团队与应用机器学习团队合作，推出了一款文本理解引擎 DeepText ，试图让它理解用户贴出的每篇文章。媒体预测，这款人工智能引擎将会深刻变革公司核心产品体验。 Clarifai CEO Matthew Zeiler 曾说，谷歌真不是一家搜索公司，而是机器学习公司。谷歌 CEO 也多次表示，公司正在践行「AI 优先」的理念。Facebook 或许与之殊途同归？Facebook 的搜索世界比不上谷歌的大，不过，其规模仍然蔚为可观。有超过十亿用户每天都会刷Facebook，网络服务器上每天有数万亿的状态更新，活动邀请，相册以及视频。Facebook 正坐拥日益增长的海量数据。公司一直希望通过真正理解这些信息，将那些拥有共同兴趣的人有效连接起来，帮助用户找到正在寻找的东西，卖出更多的广告。Facebook 已经使用了用户共享的人口数据信息。不过，Facebook 希望打造新的功能，追踪网站上的所有信息，就像谷歌抓取整个互联网信息并作出索引。对于Facebook 用户来说，这意味着，他们可以更加容易地找到埋藏在那些数以万亿计博文中的有用信息，这就像去年谷歌开始使用人工智能，试图真正理解用户查询，将真正相关的信息呈现在搜索结果中。正如公司博文所介绍的，文本，是Facebook 上流行的沟通方式。理解Facebook 上各种不同文本使用方式，有助于改善用户体验，无论是让更多用户喜闻乐见的内容呈现出来，还是过滤掉讨厌的内容，比如垃圾邮件。去年，Facebook 已经升级了自己的搜索功能，将更多的搜索结果包括进来。比如，搜索“taco（墨西哥卷饼），你会得到包括朋友发的taco照片或者与taco有关的新闻报道。不过，理论上，Deep Text 可以让搜索更进一步。DeepText是一款基于深度学习的文本理解引擎，每秒能理解几千篇博文内容，语言种类多达20多种，准确度近似人类水平。比如，当一些好友或者品牌上po 出与taco有关的内容是，它可以分析出他们到底在说什么，然后给出最有用的结果。比如，如果你想要知道哪里可以买到好的taco，它可能会分析你朋友当中关于taco相关的博文中的内容，给你推荐一家可以吃到taco的餐馆。如果你在查询taco对健康有哪些好处，他会推荐这方面的最新科学文章。DeepText 充分利用了几个深度神经网络结构，包括卷积和循环（recurrent）神经网络，并能完成以单词、字符为基础的学习任务。我们使用 Fb Learner Flow 和 Torch 进行模型训练。通过 FBLearner Predictor 平台（提供可扩展且可靠的分布式架构），轻松点击按键就能调用训练过的模型。Facebook 的工程师们能够通过DeepText 提供的自助服务结构，轻松打造新的 DeepText 模型。为什么采用深度学习？文本理解包括多项任务，比如，通过一般分类来决定某篇博文内容是否与篮球有关——以及识别实体，比如演员名字以及其他有意义的信息。不过，想要接近人类的理解水平，我们需要让计算机学会理解一些事情，比如俚语和语义消歧。比如，如果某人说，「我喜欢 blackberry 」，这是指水果还是电子设备？理解 Facebook 上的文本需要解决两个难题：棘手的体量上的挑战以及语言难题，传统自然语言理解技术在这两个问题上没效果。使用深度学习，我们可以更好地了解多种语言文本，在使用标签数据方面，也比传统自然语言理解技术高效地多。DeepText 以深度学习为基础，并延伸了其中思想，深度学习最初源自 Ronan Collobert 以及 Yann LeCun 的 Facebook AI Research。1.更加快速地理解更多语言Facebook 社区确实全球化，因此，对 DeepText 来说，尽可能多地理解不同语言很重要。传统自然语言理解需要丰富的、建立在复杂工程学以及语言知识上的预处理逻辑。当人们使用俚语或不同拼写方式交流同一想法时，即使在同一种语言中，也会存在变化。使用了深度学习，我们就可以减少对语言依赖性知识的依靠，因为系统可以从文本中学习，几乎不需要预处理。这有助于我们以最小的工程学成本迅速解决多语言问题。2. 更加深入地理解在传统自然语言处理方法中，语词被转为一种机器算法可以理解的形式。比如，「brother」可能用一个完整ID表示，比如4598，而「bro」可能会使用另一种表示，比如 986665。这种表征方式要求训练数据中，每一个会被看到、有具体拼写的单词都要得到理解。如果使用深度学习，我们就可以使用「词嵌入（word embeddings）」，一个保存单词之间语义联系的数学概念。因此，合理计算后，我们就可以看到「brother」和「bro」的词嵌入距离很近。这类表征方式可以让捕捉到更为深入的单词语义意思。使用字嵌入，我们还可以理解不同语言中的相同语义表达。比如，英语的「Happy birthday」和西班牙语的 「feliz cumpleaños」，在共同的嵌入空间中，彼此应该非常接近。通过将语词和短语映射到一个共同的嵌入空间，DeepText 就能建造起与语言无关（ language-agnostic）的模型。3.标签数据的匮乏书面语言，尽管具有上面提到的诸多变化，但是，通过使用无监督学习，我们也可以从未标签文本中提取出许多结构。深度学习为充分利用这些嵌入提供了好的框架，通过使用小规模的标签数据组，就能进一步精细化它们。这是胜过传统方法的显著优势，后者通常需要大量人类标签过的数据，这不仅低效，也很难适应新任务。在许多情况下，无监督学习和监督学习的结合，可以显著提升效果，因为弥补了标签数据组的不足。Facebook 上的探索我们已经在一些 Facebook 的使用体验中，测试 DeepText 了。例如，Messenger 现在能够更好地了解某个人可能想去某个地方。DeepText 被用于感知用户意图和提取要点，当用户说「我刚从出租车里出来」时，它能够理解这句话与「我需要一辆车」的区别，从而不会误解成用户在找出租车。DeepText 帮助 Messenger 识别用户用车需求，并建议用户使用Uber或Lyft不过，鉴于 Tay 事件效应，Facebook 机器学习团队的工程主管 Mehanna 并没有确认公司是否已经将Deep Text 用于 M，一款以人工智能为基础的虚拟助手。不过，他确实说，Deep Text 「正在 Messenger 上缓慢而更加广泛地铺开。」我们也开始使用高精确度、多语言的 DeepText 模型，来帮助人们寻找他们需要的工具。例如，用户可能会发一条状态说「我的自行车 200 美元出售，有感兴趣的吗？」通过提炼售卖物品和价格等信息，DeepText 能够发现这条状态是关于售卖某样东西的，并向用户推荐在 Facebook 平台上的相关产品.通过理解博文内容，提取其中意图、情感和实体（比如，人物、地点和事件），DeepText 有望进一步提升FB 体验，使用混合的内容信号，比如文本和图片并自动去除会被拒绝的内容，比如垃圾邮件。许多名人和公众人物都在使用 Facebook 与大家交流，这些互动往往会产生几百甚至上千条评论。要从这些不同语言的评论中找出最有关联的内容，同时保证评论质量，到现在还是一个挑战。所以， DeepText 还有可能解决的另一个难题就是，找出关联性最高或最有质量的评论。下一步我们不会停止改进 DeepText 的脚步，我们也在与 Facebook 的人工智能研究小组合作，探索它的应用。以下是一些例子。1.更好地了解人们的兴趣所在个性化 Facebook 用户体验的任务之一，就是向用户推荐他们感兴趣的内容。为了做到这一点，我们必须首先能够将任何文本与某一特定话题相关联，而这需要大量的标签数据。虽然这类数据集很难手动生产，但是，我们正在尝试通过公开的 Facebook 页面，来生成含有半监督标签的大型数据集。 我们有理由假定，这些页面上的信息将代表一个专门话题——例如，Steelers 页面的状态会包括 Steelers 橄榄球队的信息。我们用这类内容训练一个我们称为 PageSpace 的大众兴趣分类器（a general interest classifier），而它的技术核心就是 DeepText。反过来，这也将进一步改善其他 Facebook 体验中的文本理解系统。也就是说，团队会使用匹兹堡 Steelers 的页面来学习人们如何谈论美式足球以及 Steelers。所有这种数据会帮助团队建立起一个了解人类在线聊天方式、以及语词与句子联系的人工智能系统。2.文本的和视觉内容的综合理解人们经常会发一些含有图片或视频的状态，并用文字来描述相关内容。在这类情况下，了解用户意图离不开对文本和图像内容的共同理解。例如，你的朋友发了一张自己的小宝宝的照片，然后在正文里写「第 25 天」。无论是单看图片，还是仅阅读文本，都没办法搞清楚这篇博文到底什么意思。但是，如果一起分析图片和文本，系统就可以根据经验猜出内容，这些经验告诉系统，孩子是用户贴出图片的一部分，而且这位用户每天都会贴出这样的图片，这张图片不过是其中一分部。这样，系统就能正确将这张博文划分到标题为「家庭新闻」的类别中，并将它展示给过去那些对用户”家庭新闻“感兴趣的好友们。将图像和文本结合之后，我们能很清楚地知道，这条状态分享了家庭新添成员的信息。我们正在与 Facebook 的图像内容分析团队合作，来构建能够将文本和图像信息相结合的深度学习架构。3.新深度神经网络架构我们在持续地开发和寻找新的深度神经网络架构。双向循环神经网络（BRNNs）看起来可能会很有希望，因为它们有两个目标，通过循环（recurrence）获得单词间的语境依存（contextual dependencies），以及通过卷积捕捉位置不变的（position-invariant）语义。比起用以分类的常规卷积或循环神经网络，我们发现 BRNNs 在分类时的错误率更低；有时错误率甚至只有 20%。将深度学习技术应用于文本理解，会继续提升 Facebook 的产品和用户体验质量，而反过来也是如此。对文本理解系统来说，Facebook 产生的非结构化数据，是它们从语言中自动学习的绝好机会，因为使用不同语言的人都会自然用到它，而这也会进一步推动最先进的自然语言处理技术。Hussein Mehana 说，「朝着打造能智能地与人类交流的机器，我们又迈出了一步。」不过，对于 Facebook 最受欢迎的产品，从Messenger 到 新闻推送来说，Deep Text 带来的变革到底有多深，还有待观察。
机器学习;;Facebook推出人工智能引擎DeepText引言：前几天，有新闻报道在查举不良图片方面，Facebook 的人工智能战胜了人工。今天，这家公司人工智能研究团队与应用机器学习团队合作，推出了一款文本理解引擎 DeepText ，试图让它理解用户贴出的每篇文章。媒体预测，这款人工智能引擎将会深刻变革公司核心产品体验。 Clarifai CEO Matthew Zeiler 曾说，谷歌真不是一家搜索公司，而是机器学习公司。谷歌 CEO 也多次表示，公司正在践行「AI 优先」的理念。Facebook 或许与之殊途同归？Facebook 的搜索世界比不上谷歌的大，不过，其规模仍然蔚为可观。有超过十亿用户每天都会刷Facebook，网络服务器上每天有数万亿的状态更新，活动邀请，相册以及视频。Facebook 正坐拥日益增长的海量数据。公司一直希望通过真正理解这些信息，将那些拥有共同兴趣的人有效连接起来，帮助用户找到正在寻找的东西，卖出更多的广告。Facebook 已经使用了用户共享的人口数据信息。不过，Facebook 希望打造新的功能，追踪网站上的所有信息，就像谷歌抓取整个互联网信息并作出索引。对于Facebook 用户来说，这意味着，他们可以更加容易地找到埋藏在那些数以万亿计博文中的有用信息，这就像去年谷歌开始使用人工智能，试图真正理解用户查询，将真正相关的信息呈现在搜索结果中。正如公司博文所介绍的，文本，是Facebook 上流行的沟通方式。理解Facebook 上各种不同文本使用方式，有助于改善用户体验，无论是让更多用户喜闻乐见的内容呈现出来，还是过滤掉讨厌的内容，比如垃圾邮件。去年，Facebook 已经升级了自己的搜索功能，将更多的搜索结果包括进来。比如，搜索“taco（墨西哥卷饼），你会得到包括朋友发的taco照片或者与taco有关的新闻报道。不过，理论上，Deep Text 可以让搜索更进一步。DeepText是一款基于深度学习的文本理解引擎，每秒能理解几千篇博文内容，语言种类多达20多种，准确度近似人类水平。比如，当一些好友或者品牌上po 出与taco有关的内容是，它可以分析出他们到底在说什么，然后给出最有用的结果。比如，如果你想要知道哪里可以买到好的taco，它可能会分析你朋友当中关于taco相关的博文中的内容，给你推荐一家可以吃到taco的餐馆。如果你在查询taco对健康有哪些好处，他会推荐这方面的最新科学文章。DeepText 充分利用了几个深度神经网络结构，包括卷积和循环（recurrent）神经网络，并能完成以单词、字符为基础的学习任务。我们使用 Fb Learner Flow 和 Torch 进行模型训练。通过 FBLearner Predictor 平台（提供可扩展且可靠的分布式架构），轻松点击按键就能调用训练过的模型。Facebook 的工程师们能够通过DeepText 提供的自助服务结构，轻松打造新的 DeepText 模型。为什么采用深度学习？文本理解包括多项任务，比如，通过一般分类来决定某篇博文内容是否与篮球有关——以及识别实体，比如演员名字以及其他有意义的信息。不过，想要接近人类的理解水平，我们需要让计算机学会理解一些事情，比如俚语和语义消歧。比如，如果某人说，「我喜欢 blackberry 」，这是指水果还是电子设备？理解 Facebook 上的文本需要解决两个难题：棘手的体量上的挑战以及语言难题，传统自然语言理解技术在这两个问题上没效果。使用深度学习，我们可以更好地了解多种语言文本，在使用标签数据方面，也比传统自然语言理解技术高效地多。DeepText 以深度学习为基础，并延伸了其中思想，深度学习最初源自 Ronan Collobert 以及 Yann LeCun 的 Facebook AI Research。1.更加快速地理解更多语言Facebook 社区确实全球化，因此，对 DeepText 来说，尽可能多地理解不同语言很重要。传统自然语言理解需要丰富的、建立在复杂工程学以及语言知识上的预处理逻辑。当人们使用俚语或不同拼写方式交流同一想法时，即使在同一种语言中，也会存在变化。使用了深度学习，我们就可以减少对语言依赖性知识的依靠，因为系统可以从文本中学习，几乎不需要预处理。这有助于我们以最小的工程学成本迅速解决多语言问题。2. 更加深入地理解在传统自然语言处理方法中，语词被转为一种机器算法可以理解的形式。比如，「brother」可能用一个完整ID表示，比如4598，而「bro」可能会使用另一种表示，比如 986665。这种表征方式要求训练数据中，每一个会被看到、有具体拼写的单词都要得到理解。如果使用深度学习，我们就可以使用「词嵌入（word embeddings）」，一个保存单词之间语义联系的数学概念。因此，合理计算后，我们就可以看到「brother」和「bro」的词嵌入距离很近。这类表征方式可以让捕捉到更为深入的单词语义意思。使用字嵌入，我们还可以理解不同语言中的相同语义表达。比如，英语的「Happy birthday」和西班牙语的 「feliz cumpleaños」，在共同的嵌入空间中，彼此应该非常接近。通过将语词和短语映射到一个共同的嵌入空间，DeepText 就能建造起与语言无关（ language-agnostic）的模型。3.标签数据的匮乏书面语言，尽管具有上面提到的诸多变化，但是，通过使用无监督学习，我们也可以从未标签文本中提取出许多结构。深度学习为充分利用这些嵌入提供了好的框架，通过使用小规模的标签数据组，就能进一步精细化它们。这是胜过传统方法的显著优势，后者通常需要大量人类标签过的数据，这不仅低效，也很难适应新任务。在许多情况下，无监督学习和监督学习的结合，可以显著提升效果，因为弥补了标签数据组的不足。Facebook 上的探索我们已经在一些 Facebook 的使用体验中，测试 DeepText 了。例如，Messenger 现在能够更好地了解某个人可能想去某个地方。DeepText 被用于感知用户意图和提取要点，当用户说「我刚从出租车里出来」时，它能够理解这句话与「我需要一辆车」的区别，从而不会误解成用户在找出租车。DeepText 帮助 Messenger 识别用户用车需求，并建议用户使用Uber或Lyft不过，鉴于 Tay 事件效应，Facebook 机器学习团队的工程主管 Mehanna 并没有确认公司是否已经将Deep Text 用于 M，一款以人工智能为基础的虚拟助手。不过，他确实说，Deep Text 「正在 Messenger 上缓慢而更加广泛地铺开。」我们也开始使用高精确度、多语言的 DeepText 模型，来帮助人们寻找他们需要的工具。例如，用户可能会发一条状态说「我的自行车 200 美元出售，有感兴趣的吗？」通过提炼售卖物品和价格等信息，DeepText 能够发现这条状态是关于售卖某样东西的，并向用户推荐在 Facebook 平台上的相关产品.通过理解博文内容，提取其中意图、情感和实体（比如，人物、地点和事件），DeepText 有望进一步提升FB 体验，使用混合的内容信号，比如文本和图片并自动去除会被拒绝的内容，比如垃圾邮件。许多名人和公众人物都在使用 Facebook 与大家交流，这些互动往往会产生几百甚至上千条评论。要从这些不同语言的评论中找出最有关联的内容，同时保证评论质量，到现在还是一个挑战。所以， DeepText 还有可能解决的另一个难题就是，找出关联性最高或最有质量的评论。下一步我们不会停止改进 DeepText 的脚步，我们也在与 Facebook 的人工智能研究小组合作，探索它的应用。以下是一些例子。1.更好地了解人们的兴趣所在个性化 Facebook 用户体验的任务之一，就是向用户推荐他们感兴趣的内容。为了做到这一点，我们必须首先能够将任何文本与某一特定话题相关联，而这需要大量的标签数据。虽然这类数据集很难手动生产，但是，我们正在尝试通过公开的 Facebook 页面，来生成含有半监督标签的大型数据集。 我们有理由假定，这些页面上的信息将代表一个专门话题——例如，Steelers 页面的状态会包括 Steelers 橄榄球队的信息。我们用这类内容训练一个我们称为 PageSpace 的大众兴趣分类器（a general interest classifier），而它的技术核心就是 DeepText。反过来，这也将进一步改善其他 Facebook 体验中的文本理解系统。也就是说，团队会使用匹兹堡 Steelers 的页面来学习人们如何谈论美式足球以及 Steelers。所有这种数据会帮助团队建立起一个了解人类在线聊天方式、以及语词与句子联系的人工智能系统。2.文本的和视觉内容的综合理解人们经常会发一些含有图片或视频的状态，并用文字来描述相关内容。在这类情况下，了解用户意图离不开对文本和图像内容的共同理解。例如，你的朋友发了一张自己的小宝宝的照片，然后在正文里写「第 25 天」。无论是单看图片，还是仅阅读文本，都没办法搞清楚这篇博文到底什么意思。但是，如果一起分析图片和文本，系统就可以根据经验猜出内容，这些经验告诉系统，孩子是用户贴出图片的一部分，而且这位用户每天都会贴出这样的图片，这张图片不过是其中一分部。这样，系统就能正确将这张博文划分到标题为「家庭新闻」的类别中，并将它展示给过去那些对用户”家庭新闻“感兴趣的好友们。将图像和文本结合之后，我们能很清楚地知道，这条状态分享了家庭新添成员的信息。我们正在与 Facebook 的图像内容分析团队合作，来构建能够将文本和图像信息相结合的深度学习架构。3.新深度神经网络架构我们在持续地开发和寻找新的深度神经网络架构。双向循环神经网络（BRNNs）看起来可能会很有希望，因为它们有两个目标，通过循环（recurrence）获得单词间的语境依存（contextual dependencies），以及通过卷积捕捉位置不变的（position-invariant）语义。比起用以分类的常规卷积或循环神经网络，我们发现 BRNNs 在分类时的错误率更低；有时错误率甚至只有 20%。将深度学习技术应用于文本理解，会继续提升 Facebook 的产品和用户体验质量，而反过来也是如此。对文本理解系统来说，Facebook 产生的非结构化数据，是它们从语言中自动学习的绝好机会，因为使用不同语言的人都会自然用到它，而这也会进一步推动最先进的自然语言处理技术。Hussein Mehana 说，「朝着打造能智能地与人类交流的机器，我们又迈出了一步。」不过，对于 Facebook 最受欢迎的产品，从Messenger 到 新闻推送来说，Deep Text 带来的变革到底有多深，还有待观察。
Facebook;;Facebook推出人工智能引擎DeepText引言：前几天，有新闻报道在查举不良图片方面，Facebook 的人工智能战胜了人工。今天，这家公司人工智能研究团队与应用机器学习团队合作，推出了一款文本理解引擎 DeepText ，试图让它理解用户贴出的每篇文章。媒体预测，这款人工智能引擎将会深刻变革公司核心产品体验。 Clarifai CEO Matthew Zeiler 曾说，谷歌真不是一家搜索公司，而是机器学习公司。谷歌 CEO 也多次表示，公司正在践行「AI 优先」的理念。Facebook 或许与之殊途同归？Facebook 的搜索世界比不上谷歌的大，不过，其规模仍然蔚为可观。有超过十亿用户每天都会刷Facebook，网络服务器上每天有数万亿的状态更新，活动邀请，相册以及视频。Facebook 正坐拥日益增长的海量数据。公司一直希望通过真正理解这些信息，将那些拥有共同兴趣的人有效连接起来，帮助用户找到正在寻找的东西，卖出更多的广告。Facebook 已经使用了用户共享的人口数据信息。不过，Facebook 希望打造新的功能，追踪网站上的所有信息，就像谷歌抓取整个互联网信息并作出索引。对于Facebook 用户来说，这意味着，他们可以更加容易地找到埋藏在那些数以万亿计博文中的有用信息，这就像去年谷歌开始使用人工智能，试图真正理解用户查询，将真正相关的信息呈现在搜索结果中。正如公司博文所介绍的，文本，是Facebook 上流行的沟通方式。理解Facebook 上各种不同文本使用方式，有助于改善用户体验，无论是让更多用户喜闻乐见的内容呈现出来，还是过滤掉讨厌的内容，比如垃圾邮件。去年，Facebook 已经升级了自己的搜索功能，将更多的搜索结果包括进来。比如，搜索“taco（墨西哥卷饼），你会得到包括朋友发的taco照片或者与taco有关的新闻报道。不过，理论上，Deep Text 可以让搜索更进一步。DeepText是一款基于深度学习的文本理解引擎，每秒能理解几千篇博文内容，语言种类多达20多种，准确度近似人类水平。比如，当一些好友或者品牌上po 出与taco有关的内容是，它可以分析出他们到底在说什么，然后给出最有用的结果。比如，如果你想要知道哪里可以买到好的taco，它可能会分析你朋友当中关于taco相关的博文中的内容，给你推荐一家可以吃到taco的餐馆。如果你在查询taco对健康有哪些好处，他会推荐这方面的最新科学文章。DeepText 充分利用了几个深度神经网络结构，包括卷积和循环（recurrent）神经网络，并能完成以单词、字符为基础的学习任务。我们使用 Fb Learner Flow 和 Torch 进行模型训练。通过 FBLearner Predictor 平台（提供可扩展且可靠的分布式架构），轻松点击按键就能调用训练过的模型。Facebook 的工程师们能够通过DeepText 提供的自助服务结构，轻松打造新的 DeepText 模型。为什么采用深度学习？文本理解包括多项任务，比如，通过一般分类来决定某篇博文内容是否与篮球有关——以及识别实体，比如演员名字以及其他有意义的信息。不过，想要接近人类的理解水平，我们需要让计算机学会理解一些事情，比如俚语和语义消歧。比如，如果某人说，「我喜欢 blackberry 」，这是指水果还是电子设备？理解 Facebook 上的文本需要解决两个难题：棘手的体量上的挑战以及语言难题，传统自然语言理解技术在这两个问题上没效果。使用深度学习，我们可以更好地了解多种语言文本，在使用标签数据方面，也比传统自然语言理解技术高效地多。DeepText 以深度学习为基础，并延伸了其中思想，深度学习最初源自 Ronan Collobert 以及 Yann LeCun 的 Facebook AI Research。1.更加快速地理解更多语言Facebook 社区确实全球化，因此，对 DeepText 来说，尽可能多地理解不同语言很重要。传统自然语言理解需要丰富的、建立在复杂工程学以及语言知识上的预处理逻辑。当人们使用俚语或不同拼写方式交流同一想法时，即使在同一种语言中，也会存在变化。使用了深度学习，我们就可以减少对语言依赖性知识的依靠，因为系统可以从文本中学习，几乎不需要预处理。这有助于我们以最小的工程学成本迅速解决多语言问题。2. 更加深入地理解在传统自然语言处理方法中，语词被转为一种机器算法可以理解的形式。比如，「brother」可能用一个完整ID表示，比如4598，而「bro」可能会使用另一种表示，比如 986665。这种表征方式要求训练数据中，每一个会被看到、有具体拼写的单词都要得到理解。如果使用深度学习，我们就可以使用「词嵌入（word embeddings）」，一个保存单词之间语义联系的数学概念。因此，合理计算后，我们就可以看到「brother」和「bro」的词嵌入距离很近。这类表征方式可以让捕捉到更为深入的单词语义意思。使用字嵌入，我们还可以理解不同语言中的相同语义表达。比如，英语的「Happy birthday」和西班牙语的 「feliz cumpleaños」，在共同的嵌入空间中，彼此应该非常接近。通过将语词和短语映射到一个共同的嵌入空间，DeepText 就能建造起与语言无关（ language-agnostic）的模型。3.标签数据的匮乏书面语言，尽管具有上面提到的诸多变化，但是，通过使用无监督学习，我们也可以从未标签文本中提取出许多结构。深度学习为充分利用这些嵌入提供了好的框架，通过使用小规模的标签数据组，就能进一步精细化它们。这是胜过传统方法的显著优势，后者通常需要大量人类标签过的数据，这不仅低效，也很难适应新任务。在许多情况下，无监督学习和监督学习的结合，可以显著提升效果，因为弥补了标签数据组的不足。Facebook 上的探索我们已经在一些 Facebook 的使用体验中，测试 DeepText 了。例如，Messenger 现在能够更好地了解某个人可能想去某个地方。DeepText 被用于感知用户意图和提取要点，当用户说「我刚从出租车里出来」时，它能够理解这句话与「我需要一辆车」的区别，从而不会误解成用户在找出租车。DeepText 帮助 Messenger 识别用户用车需求，并建议用户使用Uber或Lyft不过，鉴于 Tay 事件效应，Facebook 机器学习团队的工程主管 Mehanna 并没有确认公司是否已经将Deep Text 用于 M，一款以人工智能为基础的虚拟助手。不过，他确实说，Deep Text 「正在 Messenger 上缓慢而更加广泛地铺开。」我们也开始使用高精确度、多语言的 DeepText 模型，来帮助人们寻找他们需要的工具。例如，用户可能会发一条状态说「我的自行车 200 美元出售，有感兴趣的吗？」通过提炼售卖物品和价格等信息，DeepText 能够发现这条状态是关于售卖某样东西的，并向用户推荐在 Facebook 平台上的相关产品.通过理解博文内容，提取其中意图、情感和实体（比如，人物、地点和事件），DeepText 有望进一步提升FB 体验，使用混合的内容信号，比如文本和图片并自动去除会被拒绝的内容，比如垃圾邮件。许多名人和公众人物都在使用 Facebook 与大家交流，这些互动往往会产生几百甚至上千条评论。要从这些不同语言的评论中找出最有关联的内容，同时保证评论质量，到现在还是一个挑战。所以， DeepText 还有可能解决的另一个难题就是，找出关联性最高或最有质量的评论。下一步我们不会停止改进 DeepText 的脚步，我们也在与 Facebook 的人工智能研究小组合作，探索它的应用。以下是一些例子。1.更好地了解人们的兴趣所在个性化 Facebook 用户体验的任务之一，就是向用户推荐他们感兴趣的内容。为了做到这一点，我们必须首先能够将任何文本与某一特定话题相关联，而这需要大量的标签数据。虽然这类数据集很难手动生产，但是，我们正在尝试通过公开的 Facebook 页面，来生成含有半监督标签的大型数据集。 我们有理由假定，这些页面上的信息将代表一个专门话题——例如，Steelers 页面的状态会包括 Steelers 橄榄球队的信息。我们用这类内容训练一个我们称为 PageSpace 的大众兴趣分类器（a general interest classifier），而它的技术核心就是 DeepText。反过来，这也将进一步改善其他 Facebook 体验中的文本理解系统。也就是说，团队会使用匹兹堡 Steelers 的页面来学习人们如何谈论美式足球以及 Steelers。所有这种数据会帮助团队建立起一个了解人类在线聊天方式、以及语词与句子联系的人工智能系统。2.文本的和视觉内容的综合理解人们经常会发一些含有图片或视频的状态，并用文字来描述相关内容。在这类情况下，了解用户意图离不开对文本和图像内容的共同理解。例如，你的朋友发了一张自己的小宝宝的照片，然后在正文里写「第 25 天」。无论是单看图片，还是仅阅读文本，都没办法搞清楚这篇博文到底什么意思。但是，如果一起分析图片和文本，系统就可以根据经验猜出内容，这些经验告诉系统，孩子是用户贴出图片的一部分，而且这位用户每天都会贴出这样的图片，这张图片不过是其中一分部。这样，系统就能正确将这张博文划分到标题为「家庭新闻」的类别中，并将它展示给过去那些对用户”家庭新闻“感兴趣的好友们。将图像和文本结合之后，我们能很清楚地知道，这条状态分享了家庭新添成员的信息。我们正在与 Facebook 的图像内容分析团队合作，来构建能够将文本和图像信息相结合的深度学习架构。3.新深度神经网络架构我们在持续地开发和寻找新的深度神经网络架构。双向循环神经网络（BRNNs）看起来可能会很有希望，因为它们有两个目标，通过循环（recurrence）获得单词间的语境依存（contextual dependencies），以及通过卷积捕捉位置不变的（position-invariant）语义。比起用以分类的常规卷积或循环神经网络，我们发现 BRNNs 在分类时的错误率更低；有时错误率甚至只有 20%。将深度学习技术应用于文本理解，会继续提升 Facebook 的产品和用户体验质量，而反过来也是如此。对文本理解系统来说，Facebook 产生的非结构化数据，是它们从语言中自动学习的绝好机会，因为使用不同语言的人都会自然用到它，而这也会进一步推动最先进的自然语言处理技术。Hussein Mehana 说，「朝着打造能智能地与人类交流的机器，我们又迈出了一步。」不过，对于 Facebook 最受欢迎的产品，从Messenger 到 新闻推送来说，Deep Text 带来的变革到底有多深，还有待观察。
产业;;Facebook推出人工智能引擎DeepText引言：前几天，有新闻报道在查举不良图片方面，Facebook 的人工智能战胜了人工。今天，这家公司人工智能研究团队与应用机器学习团队合作，推出了一款文本理解引擎 DeepText ，试图让它理解用户贴出的每篇文章。媒体预测，这款人工智能引擎将会深刻变革公司核心产品体验。 Clarifai CEO Matthew Zeiler 曾说，谷歌真不是一家搜索公司，而是机器学习公司。谷歌 CEO 也多次表示，公司正在践行「AI 优先」的理念。Facebook 或许与之殊途同归？Facebook 的搜索世界比不上谷歌的大，不过，其规模仍然蔚为可观。有超过十亿用户每天都会刷Facebook，网络服务器上每天有数万亿的状态更新，活动邀请，相册以及视频。Facebook 正坐拥日益增长的海量数据。公司一直希望通过真正理解这些信息，将那些拥有共同兴趣的人有效连接起来，帮助用户找到正在寻找的东西，卖出更多的广告。Facebook 已经使用了用户共享的人口数据信息。不过，Facebook 希望打造新的功能，追踪网站上的所有信息，就像谷歌抓取整个互联网信息并作出索引。对于Facebook 用户来说，这意味着，他们可以更加容易地找到埋藏在那些数以万亿计博文中的有用信息，这就像去年谷歌开始使用人工智能，试图真正理解用户查询，将真正相关的信息呈现在搜索结果中。正如公司博文所介绍的，文本，是Facebook 上流行的沟通方式。理解Facebook 上各种不同文本使用方式，有助于改善用户体验，无论是让更多用户喜闻乐见的内容呈现出来，还是过滤掉讨厌的内容，比如垃圾邮件。去年，Facebook 已经升级了自己的搜索功能，将更多的搜索结果包括进来。比如，搜索“taco（墨西哥卷饼），你会得到包括朋友发的taco照片或者与taco有关的新闻报道。不过，理论上，Deep Text 可以让搜索更进一步。DeepText是一款基于深度学习的文本理解引擎，每秒能理解几千篇博文内容，语言种类多达20多种，准确度近似人类水平。比如，当一些好友或者品牌上po 出与taco有关的内容是，它可以分析出他们到底在说什么，然后给出最有用的结果。比如，如果你想要知道哪里可以买到好的taco，它可能会分析你朋友当中关于taco相关的博文中的内容，给你推荐一家可以吃到taco的餐馆。如果你在查询taco对健康有哪些好处，他会推荐这方面的最新科学文章。DeepText 充分利用了几个深度神经网络结构，包括卷积和循环（recurrent）神经网络，并能完成以单词、字符为基础的学习任务。我们使用 Fb Learner Flow 和 Torch 进行模型训练。通过 FBLearner Predictor 平台（提供可扩展且可靠的分布式架构），轻松点击按键就能调用训练过的模型。Facebook 的工程师们能够通过DeepText 提供的自助服务结构，轻松打造新的 DeepText 模型。为什么采用深度学习？文本理解包括多项任务，比如，通过一般分类来决定某篇博文内容是否与篮球有关——以及识别实体，比如演员名字以及其他有意义的信息。不过，想要接近人类的理解水平，我们需要让计算机学会理解一些事情，比如俚语和语义消歧。比如，如果某人说，「我喜欢 blackberry 」，这是指水果还是电子设备？理解 Facebook 上的文本需要解决两个难题：棘手的体量上的挑战以及语言难题，传统自然语言理解技术在这两个问题上没效果。使用深度学习，我们可以更好地了解多种语言文本，在使用标签数据方面，也比传统自然语言理解技术高效地多。DeepText 以深度学习为基础，并延伸了其中思想，深度学习最初源自 Ronan Collobert 以及 Yann LeCun 的 Facebook AI Research。1.更加快速地理解更多语言Facebook 社区确实全球化，因此，对 DeepText 来说，尽可能多地理解不同语言很重要。传统自然语言理解需要丰富的、建立在复杂工程学以及语言知识上的预处理逻辑。当人们使用俚语或不同拼写方式交流同一想法时，即使在同一种语言中，也会存在变化。使用了深度学习，我们就可以减少对语言依赖性知识的依靠，因为系统可以从文本中学习，几乎不需要预处理。这有助于我们以最小的工程学成本迅速解决多语言问题。2. 更加深入地理解在传统自然语言处理方法中，语词被转为一种机器算法可以理解的形式。比如，「brother」可能用一个完整ID表示，比如4598，而「bro」可能会使用另一种表示，比如 986665。这种表征方式要求训练数据中，每一个会被看到、有具体拼写的单词都要得到理解。如果使用深度学习，我们就可以使用「词嵌入（word embeddings）」，一个保存单词之间语义联系的数学概念。因此，合理计算后，我们就可以看到「brother」和「bro」的词嵌入距离很近。这类表征方式可以让捕捉到更为深入的单词语义意思。使用字嵌入，我们还可以理解不同语言中的相同语义表达。比如，英语的「Happy birthday」和西班牙语的 「feliz cumpleaños」，在共同的嵌入空间中，彼此应该非常接近。通过将语词和短语映射到一个共同的嵌入空间，DeepText 就能建造起与语言无关（ language-agnostic）的模型。3.标签数据的匮乏书面语言，尽管具有上面提到的诸多变化，但是，通过使用无监督学习，我们也可以从未标签文本中提取出许多结构。深度学习为充分利用这些嵌入提供了好的框架，通过使用小规模的标签数据组，就能进一步精细化它们。这是胜过传统方法的显著优势，后者通常需要大量人类标签过的数据，这不仅低效，也很难适应新任务。在许多情况下，无监督学习和监督学习的结合，可以显著提升效果，因为弥补了标签数据组的不足。Facebook 上的探索我们已经在一些 Facebook 的使用体验中，测试 DeepText 了。例如，Messenger 现在能够更好地了解某个人可能想去某个地方。DeepText 被用于感知用户意图和提取要点，当用户说「我刚从出租车里出来」时，它能够理解这句话与「我需要一辆车」的区别，从而不会误解成用户在找出租车。DeepText 帮助 Messenger 识别用户用车需求，并建议用户使用Uber或Lyft不过，鉴于 Tay 事件效应，Facebook 机器学习团队的工程主管 Mehanna 并没有确认公司是否已经将Deep Text 用于 M，一款以人工智能为基础的虚拟助手。不过，他确实说，Deep Text 「正在 Messenger 上缓慢而更加广泛地铺开。」我们也开始使用高精确度、多语言的 DeepText 模型，来帮助人们寻找他们需要的工具。例如，用户可能会发一条状态说「我的自行车 200 美元出售，有感兴趣的吗？」通过提炼售卖物品和价格等信息，DeepText 能够发现这条状态是关于售卖某样东西的，并向用户推荐在 Facebook 平台上的相关产品.通过理解博文内容，提取其中意图、情感和实体（比如，人物、地点和事件），DeepText 有望进一步提升FB 体验，使用混合的内容信号，比如文本和图片并自动去除会被拒绝的内容，比如垃圾邮件。许多名人和公众人物都在使用 Facebook 与大家交流，这些互动往往会产生几百甚至上千条评论。要从这些不同语言的评论中找出最有关联的内容，同时保证评论质量，到现在还是一个挑战。所以， DeepText 还有可能解决的另一个难题就是，找出关联性最高或最有质量的评论。下一步我们不会停止改进 DeepText 的脚步，我们也在与 Facebook 的人工智能研究小组合作，探索它的应用。以下是一些例子。1.更好地了解人们的兴趣所在个性化 Facebook 用户体验的任务之一，就是向用户推荐他们感兴趣的内容。为了做到这一点，我们必须首先能够将任何文本与某一特定话题相关联，而这需要大量的标签数据。虽然这类数据集很难手动生产，但是，我们正在尝试通过公开的 Facebook 页面，来生成含有半监督标签的大型数据集。 我们有理由假定，这些页面上的信息将代表一个专门话题——例如，Steelers 页面的状态会包括 Steelers 橄榄球队的信息。我们用这类内容训练一个我们称为 PageSpace 的大众兴趣分类器（a general interest classifier），而它的技术核心就是 DeepText。反过来，这也将进一步改善其他 Facebook 体验中的文本理解系统。也就是说，团队会使用匹兹堡 Steelers 的页面来学习人们如何谈论美式足球以及 Steelers。所有这种数据会帮助团队建立起一个了解人类在线聊天方式、以及语词与句子联系的人工智能系统。2.文本的和视觉内容的综合理解人们经常会发一些含有图片或视频的状态，并用文字来描述相关内容。在这类情况下，了解用户意图离不开对文本和图像内容的共同理解。例如，你的朋友发了一张自己的小宝宝的照片，然后在正文里写「第 25 天」。无论是单看图片，还是仅阅读文本，都没办法搞清楚这篇博文到底什么意思。但是，如果一起分析图片和文本，系统就可以根据经验猜出内容，这些经验告诉系统，孩子是用户贴出图片的一部分，而且这位用户每天都会贴出这样的图片，这张图片不过是其中一分部。这样，系统就能正确将这张博文划分到标题为「家庭新闻」的类别中，并将它展示给过去那些对用户”家庭新闻“感兴趣的好友们。将图像和文本结合之后，我们能很清楚地知道，这条状态分享了家庭新添成员的信息。我们正在与 Facebook 的图像内容分析团队合作，来构建能够将文本和图像信息相结合的深度学习架构。3.新深度神经网络架构我们在持续地开发和寻找新的深度神经网络架构。双向循环神经网络（BRNNs）看起来可能会很有希望，因为它们有两个目标，通过循环（recurrence）获得单词间的语境依存（contextual dependencies），以及通过卷积捕捉位置不变的（position-invariant）语义。比起用以分类的常规卷积或循环神经网络，我们发现 BRNNs 在分类时的错误率更低；有时错误率甚至只有 20%。将深度学习技术应用于文本理解，会继续提升 Facebook 的产品和用户体验质量，而反过来也是如此。对文本理解系统来说，Facebook 产生的非结构化数据，是它们从语言中自动学习的绝好机会，因为使用不同语言的人都会自然用到它，而这也会进一步推动最先进的自然语言处理技术。Hussein Mehana 说，「朝着打造能智能地与人类交流的机器，我们又迈出了一步。」不过，对于 Facebook 最受欢迎的产品，从Messenger 到 新闻推送来说，Deep Text 带来的变革到底有多深，还有待观察。
"nan;;【日报】亚马逊Echo产品线迎来新成员、AI模拟川普讲话、德意志银行看好VR......
亚马逊Echo产品线迎来新成员、AI模拟川普讲话、李世石志在全胜、德银看好VR、以假乱真的3D打印花朵、吕贝松加盟打造美剧《人工智能》……机器之心日报，精选一天前沿科技优质内容。

亚马逊Echo产品线迎来两款“语音控制数字助理”新成员
周四的时候，亚马逊发布了两款基于Alexa的声控数字助理新品，分别是Echo Dot和Amazon Tap。Echo Dot是初代Echo的小型化版本，可通过有线或蓝牙无线的方式连接用户的扬声器（虽自带一个小扬声器，但声音明显不够大）。此外，它还使用了相同的“远场”语音识别技术，能够在距离相当远、甚至嘈杂的环境中“拾取”指令。

至于Amazon Tap，它就是一款内置了Alexa功能的便携式蓝牙扬声器（通过Wi-Fi运作）。


MIT推出DeepDrumpf，AI来模拟共和党候选人川普
Donald Trump是共和党的候选人，一向以口无遮拦著称，MIT CSAIL的博士后Bradley Hayes通过算法打造了一个人工智能来模仿川普的讲话，通过分析川普最近几场胜利的讲话，发现了川普的讲话模式。你能分辨出这是川普还是AI写的？


围棋人机大战在即，李世石：除了5：0取胜，其他无意义

在谷歌预测胜负结果五五开的情况下，李世石认为自己将以4：1或者5：0获胜，如不出现失误，将100％获胜。“虽然谷歌DeepMind公司人工智能的实力相当不错而且水平持续提高，但至少这次我有获胜的信心，”他说。在李世石看来，阿尔法在创造力方面尚无法与人类匹敌，这一点他很有自信。在接受韩国JTBC电视台专访时，李世石说：“最重要的是在5盘棋比赛中，如果我以4：1获胜，谷歌也会认为自己赢了。他们只要赢一局就会自认为战胜了人类，所以除了以5：0战胜它以外，其他都没有意义。”

传英特尔正在开发AR设备 将搭载实感3D技术
英特尔公司正在开发一款支持旗下 RealSense 3D 相机技术的虚拟现实头戴设备。对于英特尔公司来说，增强现实或许是一个能让他们受益的机会，因为这项技术需要用到微处理器、专门的图形处理芯片和 3D 相机组件等等。而为了能够在这一领域站稳脚跟，英特尔已经收购至少五家致力于开发增强现实技术的公司。


以章鱼为灵感的柔性机器人“皮肤”
康奈尔大学的工程团队此前曾以头足纲生物为灵感成功创建了新型柔性显示屏。

最近，该团队出版在《Science》上的最新论文描述了研究人员如何创建能够感受压力的高度灵活、色彩变幻的“皮肤”。这项发现在弹性屏幕、柔性机器人领域具有非常重要的意义。通过检测光线并响应搅动肌肉，该“皮肤”能够迅速改变颜色和表面纹理以配合周围环境。类似的人造材料目前还不能进行完美的伪装，但是能够创建折叠、滚动和拉伸的的电子显示设备。该项目的研究者表示已经发现了多种方式来实现这一点。


以假乱真的3D打印花朵

研究人员可以通过铸造、 3D扫描、数字化提炼，3D打印出石膏模型，从中可以创造出各种颜色模式的硅胶兰花。这种技术赋予他们无以伦比的自由制作各种假花。他们将人工花朵放在真实兰花的旁边，修改真假花朵，改它们的颜色和模式，增加或消除味道，甚至用人工和自然花瓣制造了几朵“弗兰肯斯坦”花（如图），足以以假乱真。已经有研究人员使用这种3D打印花朵来研究花曲率如何影响授粉，这种技术对授粉生态学研究有巨大帮助。未来，我们或许可以随意设计人工花朵，不仅是花的形状、质地，颜色模式，还有花瓣软硬，等等。

Oculus创始人：苹果Mac性能差 所以暂不支持VR
Oculus创始人帕尔默·勒基（Palmer Luckey）表示，旗下Rift VR头戴设备未来是否会对Mac系统提供支持，其中关键在于苹果是不是将要发布一款性能足够优秀的电脑。勒基认为苹果通常都不考虑在产品中使用高端GPU，而是依赖英特尔的集成GPU处理能力。Mac电脑当前对于绝大多数普通用户，甚至部分专业用户来说已足够好，但由于缺乏游戏性能，即使价格高昂也并不能支持VR的计算要求.

智能T恤变身X射线机 可以透视人体器官

Curiscope公司设计了一款智能T恤，能让用户通过手机及平板的app或虚拟现实设备看到人体内部的构造，效果如X射线机一般。通过这款设备，人们不但能看到人体的骨骼、器官和血管，还可探索了解特定身体部位和领域，从而轻松拥有一位3D生物老师。

德意志银行报告：虚拟现实正如07年的智能手机
德银十分看好VR市场，列举了推动虚拟现实发展的3大关键趋势。在硬件端，整个行业正在向着“全面呈现”的阶段挺进，移动平台将在今后几年追赶桌面平台；互动程度将与内容的吸引力紧密相连；开发大量硬件的作用也将止步于此。

德意志银行表示，尽管前途一片光明，但虚拟现实市场化的挑战依然存在。其中之一就是如何实现全沉浸感，使大脑认为你身处在全新的虚拟世界中。但归根结底，内容才是关键。“最重要的在于，要在全面呈现的环境中创造内容需要有合适的故事情节，而现在还没有多少内容能够做到这一点。”



索尼成立“未来实验室”：这里有你要的黑科技
索尼将成立一个名为“未来实验室”(Future Lab)的全新研发项目，希望将一些产品原型向公众开放，以期获得反馈，并确认该公司的设想。第一组项目共包含3个概念设计，都与开放式耳机有关。第一个是围巾式可穿戴设备，内置开放式扬声器，可以对语音提示做出响应。索尼表示，将这款设备围在脖子上之后，该设备便会利用Virtualphones Technologies的声像定位技术，用一个声音斗篷将用户围住。第二个原型产品是一款开放式耳机，但不需要在耳朵中塞入任何东西。


吕克·贝松将打造《人工智能》 首次任美剧主创

吕克·贝松将担任《人工智能》的联合编剧、联合主创和执行制片人，该剧的另一位联合编剧是《攻壳机动队》（Ghost in the Shell）的编剧比尔·惠勒（Bill Wheeler)。《人工智能》讲述的内容是一个智能机器人从实验室逃脱，同时它开始在世界上实施一个神秘计划。于是，“人工智能”实验的创建者们只能组建一个专家小组，来追寻这个智能机器人，在努力应对其快速的军事攻击的同时，还要向全世界警告这个迫在眉睫的危险。

新型无线脑机接口：猴子可用思想控制轮椅

北卡罗来纳州杜克大学研究员近日宣布已成功开发出可让猴子用思想控制轮椅的新型无线技术。研究人员开发了新的脑机接口，将比头发更细的微丝植入猴子大脑皮层的两个区域用于检测脑部信号。同时利用贴在猴子头皮的无线BMI设备记录微丝所检测的脑部区域神经元信号。当猴子产生向目标前进的想法时，电脑可解析其大脑活动信号并控制轮椅前进。研究人员称，这种无线技术对失去对身体控制、无法移动的瘫痪及肌萎缩侧索硬化症患者来说是一个令人激动的福音。

盘点电影里的VR文化史
VR（Virtual Reality，即虚拟现实，简称VR），是由美国VPL公司创建人拉尼尔（Jaron Lanier）在20世纪80年代初提出的。其具体内涵是：综合利用计算机图形系统和各种现实及控制等接口设备，在计算机上生成的、可交互的三维环境中提供沉浸感觉的技术。然而早在这之前，现代文学和电影里，人们已对虚拟现实有了很多想象。


机器之心编译出品"
"机器人;;瑞士科学家创造出1.4毫米厚的可穿戴「第二皮肤」很多机器人系统都存在着自相矛盾的设计准则，因此这个“软性气动装置(SPAs) ”将会是一个有前途的解决方案。“高转矩或力量”常常意味着更重或者更大体积的设备，这不实用并且与可穿戴机器人的目标相悖。&nbsp;“充气人工肌肉”(PAMs) 的原理，从60年代就被应用于为“机械矫正器”提供动力，运用此原理的SPAs是一种可以产生弯曲动作（同时不局限于单一方向和动作）的软性解决方案，并可以应用到更广泛的领域。“机械矫正器”(机械外骨骼)让那些由于各种各样原因受创伤的病人可以恢复运动能力，但是很多的这类设备穿戴起来不太舒服并且很笨重，所以还没有成为普及型的应用。要想让这类设备成为日用的、实用的东西，它们表面的触觉界面必须要轻巧、柔顺、安全并且有大量的感知和刺激点才行。一个由RRL, EPFL 和NCCR Robotics组成的团队，近日出品了一个“软性气动装置(SPAs) 皮肤”，内嵌“压电式传感器（PZT）”，它可以处理这些问题并且提供“震动触觉反馈”。“软性气动装置(SPAs) 皮肤”可以把双向的触觉信息传递到简单的、灵敏的可穿戴界面。通过创造这种SPAs界面并且将其设计和穿戴到皮肤上，就有可能创造出一种合成的“第二皮肤”，这个“第二皮肤”轻薄且有弹性，这样传感器就可以布置在手臂的所有位置了，类似神经穿过你的皮肤。当穿戴者弯曲他们的手臂，这种皮肤和集成的触觉反馈系统会同时伴随联动。“软性气动装置(SPAs) 皮肤”有两层，一个底部的传感层（&nbsp;sensor layer）和一个上部的促动层（&nbsp;actuator layer）。促动层由两层硅薄板构成，两层之间有一个罩板以防止粘连。包括集成的传感层，最终的设计是1.4毫米厚。为了产生促动，空气会在层级间泵入，形成直径为3-4毫米的气泡，这样可以产生高达0.3N的动力，这听起来还是很小的力，但是人类日常手掌所产生的压力与此相当。传感层是用压电陶瓷元素制成，嵌入到硅薄板里，这样可把机械压力转换成电压。这种电压然后用于测量震动的强度，震动是从促动器和SPA 皮肤接触到的外部界面压力产生的。“软性气动装置(SPAs) 皮肤” 产生一定频率范围内的“震动触觉反馈”。当有物体接触到皮肤时，力作用到外部界面，与此同时内嵌的传感器可以侦测到由促动器而来的这些震动。根据这个被侦测到的传感信息，促动器会随后主动控制震动的强度。换句话说，这个“第二皮肤”可以侦测到它正在接触什么东西，并且随之调节震动，这样的“感觉”（皮肤触觉）会是连续的。“软性气动装置(SPAs) 皮肤” 提供了高度可定制化和可穿戴化的物理界面，同时具有多点震动触觉信号的闭合回路控制设施。它可被应用到人类身体的任何地方。如上文所描述的，它可以成为一个即插即用的反馈机制部件单元，应用到给那些失去运动能力的病人进行训练用的康复设备里，或者是虚拟现实游戏中提供触感。注：NCCR全称为The National Centre of Competence in Research ，是由瑞士国家科学基金会创立的一个全国性组织。宗旨是开发创新的、人性化的机器人技术，促进人类的生活质量提高。NCCR研发能与人类生态共生的机器人，让机器人能够同时帮助个人和社会。NCCR主要致力于三类机器人的研究：可穿戴机器人、救援机器人和教育机器人。参考文献：H.A. Sonar and J. Paik, “Soft Pneumatic Actuator Skin with Piezoelectric Sensors for Vibrotactile Feedback“, Frontiers in Robotics and AI, doi:10.3389/frobt.2015.00038"
"机器人;;【投稿】日本正在建设机器人之城机器人助手参与到医疗、工业和农业等行业，这将会成为日本在发展中的机器人城市“Cybernic City”的一大特色。Cyberdyne这个创业公司是日本机器人城市“Cybernic City”的主要执行者，该公司期望在2020年之前创造出一些实际可见的进展成果。Cyberdyne公司是日本一家专注于外骨骼机器人的创业公司。而这个被称为“Cybernic City”的机器人城市，将坐落于筑波市，有84057平方米的面积。Cyberdyne 公司在2015年用5468万美元购买了这块地方。“Cybernic City”将具备老年人的住家，一个研究中心、医院、广场和公园。这个构想是要让机器人成为日常生活的助理。“我们可以有很多途径部署这个技术，例如，我们可以与商业机构合作让机器人来运送产品，或者让机器人帮助上了年纪的农民种庄稼。”Cyberdyne公司的董事长山海嘉之说，他也是筑波大学的教授。“我们希望在2020年东京奥运会之前，创造出一些实际可见的进展成果。”还不知道在“Cybernic City”机器人城市里拥有一个家需要多少成本，但是如果有了发展成果后，这会是一场让人类与机器人互动相处的、巨大的社会实验。在2015年11月，Cyberdyne公司的“HAL混合辅助假肢”套组，一种外骨骼机器人，被日本政府官方认可为一种医疗设备，并且被批准用于保险范围。“HAL&nbsp;混合辅助假肢”被证明可以帮助“连续神经肌肉疾病患者”，包括脊椎性肌肉萎缩症和腓骨肌肉萎缩症，的下肢康复。这个外骨骼机器人套组可以为肢体运动提供额外的动力，该产品将让全世界3400多个患者受益。注：Cyberdyne Inc. 公司简介：
是一家非上市公司，专注于医疗和助理机器人。它位于日本茨木市学园南D25-1。Cyberdyne 将Sankai教授以及他在筑波大学实验室的发明加以商业化。这个公司的旗舰产品是「HAL&nbsp;混合辅助假肢」套组，它可以通过阅读透过皮肤的神经信号，给予并且/或者增强人类的运动机能。编译者：全浩。"
"神经科学;;猴子也能开车了！——开启“意念操控”的未来《科学报告》（Scientific Reports）（自然集团的一个期刊）上面，有研究者近日描述了一种可以让猴子用它们的“意念”来控制轮椅运动的方法。这种利用大脑植入设备来控制轮椅的成果，可以应用到让那些瘫痪病人控制他们的轮椅。该方法未来除了控制轮椅，还可以用来操控其他的人造假肢。之前，其他的研究团队曾经试图用无创式设备（noninvasive devices ）来实现这个任务，但是一种新的植入式（implantable devices）“脑机接口（BMI）”装置提供了更微妙的操控。杜克大学神经工程学中心的Miguel Nicolelis领导这个研究小组。恒河猴的大脑是最接近人类的，他们在恒河猴大脑中植入了这种装备，记录猴子大脑中负责运动和感觉的两个区域的神经信号。

为了吸引猴子运动，研究人员在房间的中间放了一盆葡萄。当猴子们用“意念”思想：要朝着那一盆葡萄运动的时候，BMI设备会把脑信号转换成轮椅的运动。

“这方法让猴子们花了一阵子来尝试适应，并且有些猴子会比其他的要聪明，”Nicolelis说。但最终大部分的猴子理解和熟悉这个方法，并且如果应用到人类，这会简单很多。他认为，未来这个设备会成为动物身体的一种延伸。图注释：猴子坐在一个机器轮椅上。脑机接口（BMI）装置记录猴子的大脑活动信号，并无线传递给一个接收器，让轮椅朝着猴子意图要去的方向运动。有趣的是，随着猴子们持续地使用这个设备，它们开始计算，要到那盆葡萄的距离是多少？这种脑活动也被记录了下来。“这和刚开始训练时候的信号不同，这反映出猴子们开始精通这项任务了。”Nicolelis教授对媒体说，“这很惊奇。这证明大脑对一个设备（这个案例里面是轮椅），还有这个设备与周边环境的空间关系的巨大的吸收同化能力，”

这个项目只是专注于轮椅实验，但研究人员解释说这个核心的概念可以被应用到其他的辅助设备上，例如人造假肢。下一步，利用轮椅作为开端，研究者会给一些瘫痪的病人做测试。

类似的一些基于可穿戴脑电图（EEG）的无创式设备（noninvasive devices ）也存在，但是有更多的局限性，例如大部分研究基于对脑电波的采集，信号需要有线模式传导，而且对使用者的自身身体条件有一定要求。之前的方法还不能提供像新的植入式装置这样更精细的控制能力。这种新装置需要做手术植入到大脑中，Nicolelis 教授说这种手术只是微小的创伤，并且因为其重大的优势，还有对生命能力的提高，他相信许多人会接受这种方式和设备。有一些植入物存在猴子的大脑中已经七年之久，教授认为还可以存留更久。

通过利用该装置来记录更多的神经元信号，Nicolelis 教授和他的团队将持续提高大脑植入装置的精准度。这项目中，300个神经元被尝试记录下来，他们这团队之前曾经可以一次同时记录高达2000个神经元的信号。神经元越多地被记录，运动的精准度就越高。全浩编译，全浩为机器之心专栏作者。"
nan;;测谎仪：微软机器学习的品牌推广崛起之路最近，微软的Jennnifer Marsman 在他自己的老板身上测试了一下自己设计的测谎仪。&nbsp;「你觉得你所在的公司是全世界最好的公司吗？」&nbsp;「当然！」&nbsp;「哈！根据测谎仪的反应，这话有点心虚。」&nbsp;「今年会提拔我吗？」&nbsp;「当然！」&nbsp;「这话听起来倒不假。」&nbsp;不过，微软可不是在玩执法游戏。37 岁的Marsman是个「重量级技术布道者」（principal developer evangelist），她的工作就是不遗余力地推广机器学习——人工智能的一种形式，利用数据预测所有事，从季度销量到奶牛什么时候怀孕等等。（译者注：技术布道师是最前线也是最重要的「翻译者」，他们能够把技术以易懂的方式解释给来自不同领域的人，以此获得他们对产品或技术的支持。这需要又懂技术又能挖掘出技术背后故事的人才，他们能够激发起人们对于一个产品的激情。）&nbsp;Marsman与她的测谎仪Marsman 设计的测谎仪将算法和 14 个分列排布的用来监测脑电脑的头戴式设备结合起来一起工作，这就像是聚会上的一个小把戏。Marsman 借此向软件开发者展示如何使用微软 Azure 机器学习（Azure Machine Learning）工具。她在微软扮演着重要角色，微软在机器学习领域起步早，但是现在面临着来自Google 和亚马逊机器学习商业化的竞争。&nbsp;这样的风险相当高。接下来的几年，机器学习将会改变世界——会使得计算机智能程度呈指数级增长，并帮助削减公司成本，预测哪些值得投资，哪些值得大笔投资。彭博社智库（Bloomberg Intelligence）分析员 Anurag Rana 称这项技术「是区分软件公司发展好坏的最重要因素。」离开机器学习，他说：「你都无法卖出产品。」虽然微软已经在机器学习领域耕耘了至少 20 年，但是 Office 和 Windows 这类部门一度小心谨慎地利用其预测功能。「很多人的反应就是『我们知道怎么去做，为什么你还要用数据质疑我的观点？』」华盛顿大学计算机科学教授 Pedro Domingos 如此表述，他写了一本关于机器学习的书——《算法大师》（The Master Algorithm）。&nbsp;&nbsp;当微软尝试用 Bing 搜索赶超 Google 的时候，微软才真正拥抱机器学习技术。两年前，Satya Nadella担任微软 CEO，在此之前，他就为搜索部门定下了工程和技术战略，并把机器学习技术向魔法粉一样洒落在公司涉及的所有产品中。「机器学习深深嵌入了微软公司，微软现在处于这样的位置，」Domingos 说。「他们正大力投资机器学习，以使得该领域不那么荒芜。」&nbsp;Joseph Sirosh与 Google 和苹果使用机器学习改善自家产品一样，微软将这项技术融入到自身的运营中。这不仅仅是节省成本，帮助公司更好运作；微软自身使用这技术越多，向客户解释和销售就更容易。「客户很困惑，」Joseph Sirosh 说，2013 年，微软把他从亚马逊挖来，负责微软机器学习工程。「在一片不解声中前行颇具挑战。同时，内部也困难重重，销售人员要说服消费者并向他们讲解所有的使用场景。」&nbsp;微软首席财务官 Amy Hood 的财务部门已经开始依赖算法——使用算法预测销售数据，预测在给定时间段内的授权数量。「结果表明非常非常精准，」Sirosh 说，「Amy Hood 是机器学习的超级粉丝，知道机器学习模型预测地季度数据后，她也能睡个好觉。」&nbsp;微软还用算法预测随着数据中心的快速扩张，还需要采购多少服务器，并帮助销售人员确定重点客户。Sirosh表示，甚至之前的老产品，如 2002 年收购的一款财会软件都得到了机器学习的加持。微软的 Cotrana 分析套件（Cotrana Analytics Suite）可以让用户自己动手打造这样一类工具。&nbsp;25 岁的Ram Shankar Siva Kumar自称自己是数据牛仔（data cowboy），是 Azure 安全数据科学（Azure Security Data Science）团队的一员。他使用机器学习算法来预测微软网络中的可疑行为。一旦知晓需要寻找的目标，微软的安全团队能很快找到攻击源，而 Kumar 必须在任何人知道这一情况之前找到他们。&nbsp;为了训练算法识别有害行为的能力，他有偿鼓励微软红色团队（Microsoft&#39;s Red Team）的黑客去攻击网络以及来自微软安全中心的危险报告，用实际的攻击去训练算法。这能帮助他建立模型以识别真正的漏洞。&nbsp;各行各业正在使用微软的技术。日本农民用技术追踪奶牛，奶牛准备受孕时走动会更频繁，所以他们能让奶牛在最佳的时间受孕。一家澳大利亚的酒厂也使用类似的算法预测葡萄产量。一家距离微软大约 1 小时车程的医院使用 Azure 工具找出哪些心脏病患者更有可能需要再住院检查。挪威 eSmart 系统利用 Azure 机器学习预测能源网使用量，并在需求高的时候关闭家用供暖。&nbsp;&nbsp;Matt McIlwain 是西雅图 Madrona 风险投资集团（Madrona Venture Group）总经理，他认为微软的机器学习技术不比竞争对手的技术差，甚至更好。但是他也认为微软仍然缺乏品牌感知，目前正在迎头赶上。「人们如何发现微软真的有很棒的机器学习技术？」他说。「微软必须将自己推销出去。」&nbsp;这正是 Jennifer Marsman 的切入点。她遍历全球，展示她的测谎仪并大力宣传机器学习的潜在用途。其中医疗应用讨论颇多。人们已经问到使用该技术预测癫痫、监控依赖辅助生活设施的老人并决定在比赛中受伤的运动员是直接去医院还是回到场上继续比赛。「我在公司有着最酷的工作。」
"机器人;;关于这个逆天的Atlas拟人机器人，你需要知道更多波士顿动力发布新一代双足机器人Atlas，表现惊艳谷歌旗下的机器人公司Boston Dynamics发布了新一代Atlas视频，将人形机器人的发展带到了更高的高度，视频中新Atlas进行了户外行走、搬盒子、自主稳定和自主站立等任务，虽然还不尽完美，但和上一代比起来，新款机器人可以说在上一代的基础上实现了技术飞跃。关于这款机器人，有几点需要特别注意：新版本Atlas高5.9英尺（1.75 m ），重180磅（82 kg ），比前一代高6.2英尺（1.9m）重345磅（156kg）的型号更短更轻。

Atlas为户外和室内应用设计。它是电力驱动和液压制动的。它的身体和腿中使用了传感器来保持平衡，传感器位于其四肢以防侧翻，有些传感器甚至能够识别箱子或门上类似QR的编码。还在头部使用了激光雷达和立体传感器以避开障碍物、评估地形和帮助导航。

Atlas是绑了一个外部电源来供电的，而这一版本则是电池供电，更时尚、更安静、更灵活，所以比起上一个版本，新Atlas看起来看轻盈，走起路来健步如飞。

看起来波士顿动力认为电机还无力驱动180磅机器人完成行走的任务，所以他们继续使用了更为复杂（通常也更混乱）的液压系统。其它有足机器人也同样这么做，看起来这似乎是在电力的高效和液压的高功率之前作出的妥协。

其动态平衡让我们想起了早期的BigDog，但Atlas是依靠双足行走的，这实在太强了，因为其肢体在保证移动速度的同时还需要支持上身。

我们目前还不清楚目前这款机器人的自动化程度有多高。在户外行走时，其激光雷达看起来并没有太多旋转，这意味着很有可能有人在遥控它。一些搬盒子的过程看起来是自动的，但我们肯定要关注在该机器人将盒子码在架子上时背后发生着什么。

它会翻倒，但它不仅不会死，还能自己站起来。机器人下面垫了一些软垫，而一段视频也不能透露更多关于其稳定性的信息，但和其它人形机器人比起来，它确实优秀太多了（比如CHIMP机器人）。「这十分令人惊讶，」加州大学伯克利分校的机器人学教授Ken Goldberg说，「它们的运动真的流畅了许多。」机器人格外流畅的运动会让他觉得很奇怪，特别是当人们用曲棍球棒戳Atlas时。他还表示：「当机器人遇到具有冲击力的突发事件（我们称之为『刺激』）时，对系统来说相应是非常困难的。」Atlas的反应尤其令人印象深刻，因为研究人员推的是它的胸部，即重心的位置。Atlas双足机器人在自主平衡方面取得了巨大进步尤其值得注意的是其在自主平衡上取得的进步。Atlas是双足人形机器人，其运动稳定性一直是学术界研究的难题。在去年DARPA机器人挑战赛这样的顶尖赛事里，参赛团队的机器人面临的最大难题是让自己保持直立，那些世界一流的实验室做出的双足机器人步态在平地上仍是小心翼翼，而且还经常摔，当然，也不能自己站起来。看一下这些机器人摔倒的视频，你就能想象出让机器人平衡站立和正常行走是多么困难的事情。这些摔倒视频看起来令人捧腹，但对于这些价值百万美元的机器人来说，由于平衡能力不足导致的摔倒动作可能会带来毁灭性的打击——仪器、电机和其他部件造成了严重损坏。因此，如何增加机器人的平衡能力，成为所有机器人公司所面临的最严峻的问题。从本次波士顿公司发布的视频来看，他们很好的解决了这个问题，波士顿动力公司对此没有进行详细说明，但从公司创始人 Marc Raibert 在2015年8月份的FAB 11大会演讲中可以看出一些端倪。他在现场展示了一段视频，那时的 Atlas 已经能够做到了在树林中快速行走。与那个在几个月前 DARPA 机器人挑战赛中行走缓慢、摔的很惨的 Atlas 判若两人。Raibert 说，关键在于他们的机器人可以通过快速移动、选择新的落脚点来实现动态平衡。在左边是Atlas腿的一个版本。右边则是波士顿动力“未来的愿景”：这只脚将采用3D 打印，将所有的液压元件直接打印到其结构中。这只脚看上去有很多仿生的元素，比如“类动脉式的液压管道布局”、看上去很像骨头的支架等。我们并没有看到这条腿的实物图片，但听上去波士顿动力已经造出来了一个。Marc Raibert信心满满的说：「我现在还不能给你们展示机器人，但我们在很努力地推进这个项目，并且我认为到年底你们将看到使用类似这种技术制作的波士顿动力机器人。」虽然推迟了几个月，但Atlas还是做到了。除了Atlas，也有一些机器人团队很好的解决了机器人平衡的问题。在2015 DARPA 机器人挑战赛中，许多参赛团队的机器人使用了Atlas，他们通过安装他们自己的软件并修改来让机器人保持平衡。来自WPI-CMU的阿特拉斯机器人Warner是诸多Atlas中唯一一个没有摔倒或需要重启的机器人。在决赛的两次尝试中，他们都成功走到最后，拿下八分中的七分。这样优异表现的背后，是CMU机器人学院Christopher Atkeson教授组对稳定步态的研究成果，尤其是组里博士生冯思远的工作，冯思远在3D行走方面的论文曾在13年的仿人机器人国际会议Humanoids上获得过大会最佳论文（Best Paper）的荣誉。Atlas展示了双足机器人优秀的平衡能力，但总有一些极端情况会让它失去平衡，如何应对？那就让它们优雅的摔倒。伍斯特理工学院的Matt DeDonato指出：「大多数的（机器人挑战赛）参与者，都会关注机器人保持直立而不是关注找出更好的摔倒方式，尤其是当每次摔倒，都会有大量的时间惩罚」。在与卡内基梅隆大学合作中，为了减小损坏，当检测到摔倒时，Matt DeDonato的队伍操控的阿特拉斯机器人都会关掉自身的执行器，然后跛行前进。在整个DAPRA挑战中，DeDonato的队伍保持着机器人始终站立。但是DeDonato指出：「随着机器人的商业化，需要研究这个领域，毕竟机器人总会有摔倒的时候」。对此，波士顿动力创始人Marc Raibert指出：「当他的队伍开发一个四足机器人BigDog时，就开始思考怎样保护一个即将摔落的机器人。最初的想法是当检测摔倒时，让机器人的四肢失灵」。他说：「当四肢碰到地面时，四肢如同长的杠杆，力量会直接作用在连接处。我们的确摔坏过BigDog的一些腿，所以我们重新对BigDog编程。当出现摔倒时，就松动它四肢的连接处。我们现在做的机器人都会检测当他们失去平衡时，对应做出什么反应。」佐治亚理工学院研究者们从人类摔倒的行为中总结出一种算法，让一个不平衡的机器人找出怎样扭曲它的身体，使得它能减小与地面的碰撞力。为了驱散摔倒的动力，这种算法会计算出机器人摔倒与地面产生的一系列接触点。他们用一个小的人形机器人BioloidGP来测试算法，用Atlas来模拟实战。研究成员Karen Liu表示，还会基于人类的条件反射给机器人建立一套类似的神经系统。波士顿动力的机器人家族波士顿动力是一家致力于机器人快速运动以及平衡能力研究的机器人公司，主要关注机器人的快速运动能力、负重能力和拟人行为。该公司在1992年从MIT剥离出来，自分离后便一直从事发军事项目的研发工作，并获得了DARPA的资助，为美国国防部、美国陆军部队、海军部队和海军陆战队提供军用机器人及相关技术咨询服务。产品最突出的特点是模拟人类行为，主要应用于国防任务测试和极端环境救援等领域。2013年12月，公司被谷歌收购。除了今天我们看到的逆天的新一代Atlas，波士顿动力还有其他几款仿生机器人。1）大狗机器人（Big Dog）Boston Dynamics设计了大狗（Big Dog）机器人，这是一个四脚机器人，能够穿越泥地和雪地，以5英里/时的速度慢跑。它的体型与一只大狗或小驴差不多大，最初由DARP研发A提供资金。它的主要用途是在复杂地形中载重。大狗体内装有由发动机驱动的液压作动系统，四肢上装有特殊材料制成的减震器，每迈出一步的能量都能被有效循环至下一步，保证能源动力在长途跋涉中利用效率最高，其平衡力绝佳、能负载约180公斤武器装备翻山越岭、还能解读语言和视觉命令，因此，机器人大狗曾有望成为未来战场的利器。2010年至今，这一由美国军方与波士顿动力合作研发的项目已经耗资4200万美元。几年前，美军甚至声称将在阿富汗战场上测试和使用大狗机器人。却不想，去年的一场大型实地试验使「大狗」的缺点暴露无遗。「部队认为大狗太吵，会导致他们暴露目标。」美军陆战队作战实验室发言人欧尔森表示。此外，一旦发生故障，这款机器狗的维修十分困难，因此不适合投入实战部署，最终将其转入技术储备。对此，波士顿动力创始人 Marc Raibert 回应到：「LS3这个项目是为了验证多足机器人参加战斗的可行性，所以陆战队砍掉该项目并不代表机器大狗就夭折了。」2）Spot谷歌旗下的Boston Dynamics为美国海军陆战队开发了这个机器狗Spot。它重达160磅（约73千克），用一个连在笔记本电脑上的游戏手柄来控制，操控半径可达500米。Spot以电力驱动，相对安静。在此之前，波士顿动力发布的Spot机器狗也展现了出色的平衡能力，它重约72.5公斤，由电和液压装置驱动，能够行走、小跑、上楼梯，甚至被踢之后还能恢复姿势。但其负载作用远低于大狗机器人，并不能在战场上使用。虽然无法在战场上使用，但Spot可以用来送圣诞礼物。2015年圣诞节，波士顿动力用三只Spot bots扮演圣诞老人的驯鹿，拉着一个雪橇蹦蹦跳跳地走来了……3）PetmanPetman是Boston Dynamics开发的人形机器人，用于化学防护服的测试。Petman可以模拟士兵在各种极端压力下可能做出的动作并以此测试防护服的耐用性，它同时可以根据人体生理学来控制调节防护服内的温度、湿度以及模拟人体出汗，从而达到更好的测试效果。Petman是Boston Dynamics开发的人形机器人，用于化学防护服的测试。Petman可以模拟士兵在各种极端压力下可能做出的动作并以此测试防护服的耐用性，它同时可以根据人体生理学来控制调节防护服内的温度、湿度以及模拟人体出汗，从而达到更好的测试效果。4）CheetahCheetah豹机器人是第一个能够自动奔跑和越过障碍物的四脚机器人。DARPA为这个机器人的研发提供了资金，目前是全世界最快的机器人，时速能超过29英里。波士顿动力「虐待机器人」的黑历史The verge记者Rich McCormick称，波士顿动力公司在生产仿生机器人方面有着悠久历史，他们的科学家也一直「虐待」机器人，脚踢、嘲讽和戏弄。这种「不明智」的行为又出现在了公司下一代 Atlas机器人的介绍视频中，它能够大步走过雪地，抬起箱子，打开门，或者有一天——谋杀人类。他说「但愿Atlas还没能力分辨和追踪那些虐待它的人类面孔，否则它们可能会成为机器人崛起时期的第一批反对力量。」《连线》记者Nick Stockton也表示了同样的「担忧」，他说，我发誓 Atlas迟早会颠覆现状，而下一件事就是末日审判。加州大学伯克利分校机器人学教授Ken Goldberg也说：「这肯定会引发『恐怖谷』效应，当它被欺负的时候，我们大多数人都会认为它会反击，然后用一束激光消灭了那些欺负它的人。」如果你看到机器人被欺负时感到不舒服，那么恭喜你，这引发了你强烈的共鸣。早在波士顿动力的研究者脚踢机器狗Spot时就引起了很多人的不适。英国University of Sheffield人工智能和机器人名誉教授Noel Sharkey说「导致这种行为不道德的唯一原因是机器人能够感觉到疼痛。」动物权益组织 PETA也给出了他们的观点，PETA每天都在处理虐待动物问题，因此我们不会因为这样的事情而睡不着觉。英国University of Sheffield人工智能和机器人名誉教授Noel Sharkey说「导致这种行为不道德的唯一原因是机器人能够感觉到疼痛。」毕竟踢一只四足机器人要比踢一只活生生的狗好很多。就像一位推友所说，机器狗归根结底还是机器人，不是真实的狗。在视频的最后，Atlas从一把未锁住的门逃了出来，也许是想对那些曾经虐待它的人们予以反击。Nick Stockton开玩笑说到：他打电话向Boston Dynamics确认这些配置，但是没有人接，我只能认为机器人已经屠杀了所有人。参考内容：http://www.engadget.com/2016/02/23/boston-dynamics-presents-the-next-generation-atlas-robot/http://spectrum.ieee.org/automaton/robotics/humanoids/next-generation-of-boston-dynamics-atlas-robothttp://paleofuture.gizmodo.com/the-new-atlas-robot-is-incredible-and-its-definitely-go-1760908062?utm_campaign=socialflow_gizmodo_twitter&amp;utm_source=gizmodo_twitter&amp;utm_medium=socialflowhttp://www.wired.com/2016/02/boston-dynamics-new-robot-wicked-good-getting-bullied/http://www.theverge.com/2016/2/23/11103684/boston-dynamics-atlas-video-kickinghttp://recode.net/2016/02/23/watch-googles-latest-robot-deftly-deal-with-snowy-trail-abusive-co-worker/微信公众号机器人学家：《极致稳定,走向实用!波士顿动力新版Atlas视频发布》、《波士顿动力的人形机器人在山地上快跑起来了，等等更新》"
科技预言;;加来道雄：科学将如何彻底改变21世纪？加来道雄（1947- ）是纽约市立大学大学城市学院理论物理的Henry Semat教授。(Henry Semat ，1954年出版第一本「介绍原子与原子核物理」教科书，其办公室在纽约市立大学。获得以他命名的荣誉席位是对物理学家工作的认可)。加来道雄也是弦场论的联合创始人和著名科普学家。他于1972年在加州大学伯克利分校获得博士学位。&nbsp;在加来道雄的新书《 Visions: How Science Will Revolutionize the 21st Century》中，他向我们阐述了那些将彻底改变人类未来的当代科学。他首先指出了20世纪科学的三大主题：原子，计算机和基因。这些科学革命最终的目的是完全了解物质，心智（mind）和生命。实现这些目标的进度一直是惊人的，就在过去几年内新增的科学知识已经超出了人类历史上的总和。我们不再以被动的姿态观察自然，并且转身变成了高效的自然指挥官；我们从发现自然规律进步到了当家做主。&nbsp;量子研究的革命也催生了另外两个革命。在1925年以前，没有人了解原子；而今天，我们可以全面地描述物质世界。我们的理解建立在三个基本的假定上：1）能量不是连续的，而是发生在被称为「量子」的独立单位中；2）亚原子粒子具有波和粒子的双重特性；3）这些波/粒子的波动遵循薛定谔方程，并决定某件事发生的概率。在标准模型中，我们可以预知从夸克到超新星的属性。人类现在已经理解了物质，甚至也许能够在本世纪之内实现对它们的随意操控。&nbsp;计算机革命始于20世纪40年代。当时的技术很原始，但十年内激光技术的成熟将电脑的发展推向了指数增长。今天在指甲盖大小的地方就可以有几千万个晶体管。随着芯片的普及，日常生活将发生很大的变化。过去，我们惊叹于智能；未来，我们可能创造并控制它。&nbsp;生物分子革命始于发现DNA双螺旋结构的20世纪50年代。我们意识到人类的遗传代码被写在细胞DNA上。生物分子学的技术让我们可以像读书一样理解生命的代码。随着「人类用户指南」的出现，科学和医学经历了不可逆转的变革。我们将能根据意愿来指导生命，而不是观察它。&nbsp;因此，人类正在从观察阶段进入实践理解的阶段。我们就像降落在地球上的外星人，正在观察一盘棋局。仅是了解游戏规就需要很长时间，而知道这些规则也不能即刻变成下棋的大师。我们喜欢掌控感，并且已经明白了物质，头脑和生命，但还不是万物的主人。不久，我们将会是主人。&nbsp;真正推动这些革命的是以上这些科学发现的相互关联，它们彼此敦促的方式。量子理论通过晶体管和激光催生了计算机；通过X射线的晶体学和化学键理论催生了生物分子革命。虽然简化论（reductionism）和专业性为这些领域支付了大量红利，但是，每个领域难解的问题已经迫使它们回头联系在一起，呼吁彼此的协同。如今，现在计算机可以破译基因，而对DNA的研究让使用有机分子创造新的计算机体系结构成为可能。加来道雄把这个现象称做「科学的交叉滋养（cross-fertilization）」，它保证了科学前进步伐的不断加快。 &nbsp;在未来十年，加来道雄预期看到相关科学活动的爆炸式增长，其中包括器官再造和治愈癌症。到了21世纪中期，他预期看到老龄化的减缓，纳米技术的巨大进步，星际旅行与核聚变技术的实现。到本世纪结束时，我们将创造新的生物，并且殖民太空。我们将会看到Kurzweil和Moravec所描述的愿景变成现实—人类将通过再造器官，基因操控，或者与电脑融合来延长寿命。&nbsp;所有这些会将我们引入何方？回答方式之一，看看天体物理学家根据利用能源的方式，给假设文明贴上的标签：I型，II型和III型文明。I型文明能控制地面能源，改造天气，开采海洋和地表下的能源。II型文明则掌握了恒星的能量，能够使用太阳驱动机器，探索其他星系。最高等级的III型文明既然已经耗竭自己恒星能量，它使用的是星际能量。能源可以存在于一个星球，恒星，或者星系中，而不同的文明类型对应着不同使用资源的文明能力。&nbsp;依据我们控制资源的能力每年约3%的增长率，加来道雄预估人类可以期望在一到两个世纪的时间内成为I型文明，在800年内成为II型文明，在10万年内成为III型文明。不过在此刻，我们是一个使用动植物化石的0型文明。加来道雄预测人类将在22世纪末成为I型文明，并跨出进入太空的第一步。与Kurzweil和Moravec的预期相同，加来道雄相信技术将帮助人类在机器人的身体或虚拟现实里保存自己的大脑，实现长生不老。进化将取代我们，正如我们取代所有在进化斗争中死去的生命才能存活下来一样。当代人们的工作是推进进化。
"nan;;【日报】SpaceX海上回收火箭再度失败、沃森人工智能进入苹果手表健康应用、R2-D2机器人之父去世、中国发射量子卫星、沃森人工智能进入苹果手表健康运用、神奇的Wintergatan Marble Machine、SpaceX海上回收火箭再度失败、Meta推出面向研究人员的Meta2、R2-D2机器人之父去世……机器之心日报，精选一天前沿科技优质内容。
中国发射量子卫星对加密学意味着什么？


中国计划在今年7月发射量子科学实验卫星，要将量子通信从理论变成现实，量子加密在理论上被认为是无法破解的。卫星的发射将标志着中国量子通信网络的完成，该网络还包含了2000公里长的北京至上海量子光纤线路。500公斤重的量子卫星将测试量子纠缠现象，它由量子密钥通信器、量子纠缠发射器、纠缠源、处理单元和激光通信器构成。卫星将在中国和欧洲的两个地面站之间中继传输量子密钥。
IBM将沃森人工智能带入苹果手表睡眠健康应用当中
IBM宣布为iPhone和Apple推出一款应用程序SleepHealth。



SleepHealth收集的数据将被存储在IBM沃森健康云当中，搭载了机器学习功能的AI - 沃森将依次比较和分析数据，识别模式，并将结果提供给研究人员，希望能为特定的睡眠相关问题更好的解决方案。和其它睡眠追踪程序追踪用户夜间醒来次数不同，这款应用程序是建立在IBM沃森健康云上，这是IBM与苹果和强生公司合作开发，并连接苹果的开源框架ResearchKit。
Magic Leap还没做到的，这家AR创业公司正在率先实现
制造一个能将数码图像精准呈现如现实一样的AR眼镜很困难，还要让用户方便操作就更加困难了。一家相比之下资金薄弱的AR创业公司Meta（2千3百万美金的投资对比MagicLeap的14亿美金）他们推出了一款面向开发人员的AR眼镜 –Meta 2。



Meta2所呈现出的清晰的3D图像可以被轻松地拿捏，移动和触碰。Meta期望购买Meta2的开发人员将会创造出更多更复杂程序，把这个平台变得更加实用。Meta预计在几年之内推出一款面向广大消费者的版本。“我们的目标是推出一款沉浸感超强而且很好玩的产品”,Meta的CEO梅伦·格里贝茨（Meron Gribetz）说。

[embed]http://v.qq.com/cover/5/540qt609a7l2u0c.html?vid=q0019wjhznw[/embed]
量子计算机将能分解任意大数
MIT和 Innsbruck大学的计算机科学家组装了一台5量子比特的量子计算机，它有朝一日将能分解任意大数，破解常用的RSA公钥加密算法。在一项最新研究中，Chuang和他的团队想要创造一台分解大于 15的数的量子计算机，这种量子计算机能稳定储存量子比特。他们的量子计算机原型使用了一系列离子，用电场固定离子的位置，用激光脉冲进行操作。他们用4 个量子比特去执行Shor算法去分解数字，1个量子比特用于输出。Chuang称他们的原型能放大去分解任意大数。研究报告发表在《科学》期刊上。
Wintergatan - Marble Machine：两千颗钢珠的精妙算法
瑞典音乐家马汀·默林打造出他专属的新乐器——Wintergatan Marble Machine。从外表看起来，Wintergatan Marble Machine就像是个有着复杂装置的巨型音乐盒，位于侧边的摇杆是音乐盒的启动开关，启动后，机器内部的2000颗小钢珠就会开始沿着漏斗、管子、滑轮四处移动，同时唤醒盒内的电颤琴、贝斯、鼓、铙钹等乐器，合奏出一首悦耳动听的乐曲，有了Wintergatan Marble Machine，默林几乎一个人就能组成一个小型乐团。


谷歌用大数据画出救命地图，对抗寨卡病毒


世界卫生组织日前宣布，寨卡病毒进入全球紧急状态。Google表示，利用地图化的数据了解和预测寨卡病毒的传播会是一种有效的途径。该公司已经组建了一支包含工程师、设计师和数据科学家的志愿团队，计划通过处理不同来源的天气、旅游、和疾病数据来测绘和预测病毒的传播。Google表示，希望这种开源平台能够帮助政府和公共卫生组织实时监测和预测疫情，合理进行资源分配和第一时间响应情况。
大疆精灵4首发上手体验视频

这款熊孩子专用搜索引擎 完成了谷歌的心愿
谷歌曾计划开发一款儿童版的搜索引擎，最终由于种种原因没能实现。现在，一家初创公司终于完成了谷歌的这一心愿。这款专为儿童打造的搜索引擎名为“Kiddle”。

Kiddle在两个方面保障了其安全性，一是基于Google的安全搜索引擎，另外则是通过人工编辑干预。除了在内容屏蔽方面下足功夫外，Kiddle还声明不会收集任何个人信息，所有日志每隔24小时便会自动删除。
SpaceX 海上回收火箭再度失败
美国当地时间的 3 月 4 日下午六点，SpaceX 的猎鹰 9 号火箭再次携带卫星升空，不过在返程并尝试海上回收猎鹰 9 号的过程中，火箭没有准确降落到驳船中心，直播信号中断，海上回收火箭实验宣告再次失败。在尝试海上回收失败后，Elon Musk 随即在 Twitter 上表示了原因：火箭在海上平台硬着陆，并没期待这次能够成功，不过下次着陆应该是个很好的机会。

[embed]http://v.qq.com/cover/e/el7mouselxpimp4.html?vid=h0019miluq0[/embed]
《星战》R2-D2机器人打造者Tony Dyson逝世 享年68岁
《星战》R2-D2机器人原型打造者Tony Dyson被发现死于马耳他戈佐岛自家公寓中，享年68岁。Dyson在职业生涯中共打造了8个R2-D2机器人原型，并拥有一家称为The White Horse Toy Company的玩具公司。Dyson此前还曾参与《超人2》《太空城》等电影的创作。Dyson曾表示能打造R2-D2机器人是他人生经历中“最精彩的一部分”。


 科学家在深海发现“幽灵般”的八足生
近日，美国国家海洋和大气管理局（NOAA）的科研人员成功发现了目前尚未被人类认知的“幽灵般的八足生物”。该生物是深海探测器“俄刻阿诺斯探索者”(Okeanos Explorer)号执行今年首次任务，在内克岛（Necker Island）附近发现的。科学家初步认为这是incirrate octopods家族成员之一，是目前人类已经发现的最深的八足生物。


3D打印定制矫形器帮助手部残疾男子实现抓握动作
近日波兰弗罗茨瓦夫大学的研究人员制作了一款3D打印矫形器，其目的是通过创建康复矫形器来引导轻度残疾患者的肢体运动。 他们也成功帮助一名33岁手部残疾的男子实现抓握动作。她的设计包含了70多个3D打印部件，并使用ZMorph3D打印机及不同颜色的ABS材料打印而成。



机器之心编译出品"
"深度学习;;NTM-Lasagne：基于Lasagne的神经图灵机函数库过去几年，递归神经网络（RNN）已经成为序列建模中的主要玩家。由于其高效性与灵活性，人们很容易认为，它们将是序列学习的未来。然而，深度学习的研究十分的迅速，以至于没人能够知道未来会是怎样。实际上，近期深度学习领域的创新中，给现存架构添加某种形式的外部存储器的想法已经带来了有前景的结果，特别是在自然语言处理（NLP）方面。很大程度上都出于复制神经科学家的理论化概念的需要，后者也是归纳推理和发明新概念的动力。在这里，我们将主要将目光集中于记忆增强神经网络（memory-augmented neural networks）早期例子中的一个：神经网络图灵机。我们将会了解它的运行原理细节，以及如何能适于完成学习算法任务。用以建造我们的神经网络图灵机库的Snips也是开源，上等的。它包括了代码、预训练模型以及在这篇博文中所包括的例子。Memory增强神经网络无论是递归还是前馈神经网络，所有的神经网络都有一个特征，它们会将数据映射为抽象表征。然而，从外部环境中添加知识——例如为NLP添加词典——很困难。比起人工增加RNN隐藏状态大小，我们更愿意任意增加加入模型的知识量，同时对模型本身做出最小限度改变。基本上，我们能用独立存储器——作为一种神经网络能够按需读写的知识库——来增强模型。你可以把神经网络视为CPU，而且将这种新的外部存储器视为RAM。对于保持读/写的快速运行来说，记忆结构的选择非常关键，无论存储器大小如何。深度学习社区多推荐多重设计。例如，神经图灵机（ Neural Turing Machines），还有神经网络随机存取机（Neural Random Access Machines）(Kaiser et al., 2015)和神经网络GPU (Kaiser et al., 2015)，使用了带有读写磁头的磁带。Grefenstette et al., 2015，作者使用诸如栈或（双端）队列结构的连续版本。这些Memory增强神经网络的一个有趣副作用便是跟踪中间计算的能力。举个例子，在NLP的QA问题中，当模型边度故事边记住它到最后回答问题，会有很有价值。例如，Memory Networks(Sukhbaatar et al., 2015）与Dynamic Memory Networks（Kumar et al., 2015)，利用了存储器而在QA任务上表现良好。为RNN添加额外存储器并不是什么新主意。实际上，长短期记忆神经网络（LSTMs）已经有了一个基础存储器细胞，每时间步（time-step)储存信息于此。为了介绍LSTM，我推荐一步步阅读它们运作的细节，包括存储细胞的作用。长话短说，这种细胞的主要功能就是简化RNN的学习，那么，较之LSTMs,给如此低水平的处理机制添加存储器的意义何在？答案就是结构。LSTM通常有一个存储器中信息的分布式表征。这本身不是问题，经验已经表明他们肯定能记住数据结构。与LSTM不同，Memory-增强神经网络鼓励（但并不是必要的）存储器的本地变化。这正好不仅有助于找到训练数据的结构，还可以泛化超出LSTM泛化能力的序列，例如算法任务中更长的序列（我们会在下面看多许多例子）。你可以发现Memory-增强神经网络超过LSTM的价值所在：想象下你在一个party中，试着在所有宾客都在说话的时候搞清楚主人叫什么。一些人也许知道他的名，一些也许知道他的姓，甚至宾客们也许只知道他的姓或名的一部分。最后，就像LSTM一样，你能够通过收集来自不同宾客信号回收信息。但是，你能够想象，如果一开始就有一个宾客知道他的整个姓名，这将会简单得多。神经网络图灵机（下面简称为NTM）在它们各自领域中，可计算理论和机器学习已经推动了计算机能力的发展。前者定义了计算机计算的能力，而后者则让计算机执行那些对于人类简单而对于计算机则看似不可能的任务，例如计算机视觉。艾伦·图灵在1940年就开始研究计算和人工智能前景密不可分的联系。他建立了一个经典计算模型，通过一个或读或写信号的磁头在无限存储磁带上运行。尽管这个抽象的计算机有着非常低水平的界面，但它强大到足够到模拟任何算法。神经网络图灵机（NTM）就是从这两个领域受到启发，博众家之长。值得注意的是，神经网络图灵机和RNN之间有着有趣的连接。后者以图灵完备（Turing-complete）而闻名（Siegelmann，1995）。这意味着就像用图灵机一样，任何算法都能靠一个RNN用细心挑选的参数进行编码（虽然这样的参数也许不能从数据中学习到）。NTM可以被看作是图灵机的可微版本。与图灵机相似，它有主要两个成分：一个（有限）存储磁带，以及一个控制器，负责打造与外部世界之间的交互界面（例如，输入序列与输出表示）和通过读写头的存储器。据说，这个架构可微，在控制器与处理机制都是可微的意义上。模型的参数能够利用随机梯度下降（Stochastic Gradient Descent）学习。下面我们就详细描述这些组成部分。控制器控制器是一个神经网络，提供输入的内部表示，通过读写头与存储器相互作用。值得注意的是，这种内部表征与最终储存在存储器中的并不完全相等，后者是这种表征的一种函数。对于神经网络机来说，控制器的类型就是最重要架构选择的代表。这种控制器可以是前馈或递归神经网络。前馈控制器比起一个递归控制器要快速得多，并提供更多的透明度。但这意味着付出低表现力的代价，因为它限制了NTM每时间步所能执行的计算类型。读/写机制读写头让神经网络图灵机更加有趣。它们是仅有能够直接与存储器互动的成分。从内部来说，每个读写头的行为都被它自身的权重向量所控制，在每一时间步得到刷新。每个向量上的权重与在记忆中的位置一致（权重向量总和为1）。为1的权重尽在相应存储位置聚焦NTM所有的注意力。为0的权重则与记忆位置无关。不仅如此，我们还让这些权重符合两个要求：它们应该支持存储器上的本地变化（读或写），同时保持它们的更新可微，因为我们想要训练NTM端对端。为了这个目的，权重向量通过一系列中间平滑操作进行更新。每一个更新都有四个操作：内容处理、插值、卷积位移（ convolutional shift）和锐化。它们都取决于控制器所产生的参数。更精确地说，这些参数是控制器释放的隐藏状态的函数。在内容处理的操作中，NTM将注意力集中于「靠近」关键的存储器位置，因此让模型能够回收存储中的特殊信息。粗略地说，有点像《C语言指导》。以内容为基本的权重继而以之前插值操作时间步中的权重向量为门控。如果门为0值，那么内容处理就跳过。反之，门为1，那么之前的权重就被忽略。卷积位移继而平滑地将权重左移或右移，与经典图灵机的读写头位移非常相似。最终，移动向量被锐化，尽可能针对性地获取一个权重向量。要记住，没有一个操作能够在存储中真正本地改变，尽管重点在于生成稀疏权重。其结果就是你得到「模糊」权重向量，无力查询整个存储。一旦读写头刷新了自己的权重向量，那么，它就准备在存储器上运行。如果它是一个读取头，那么会输出记忆位置的权重结合：读取向量。后者接着在下一个时间步反馈回控制器。如果它是一个写头，那么记忆内容就会稍微修改（取决于 权重），抹去或添加向量，两者都由控制器生成。NTM-Lasagne基准与样例由谷歌DeepMind的论文所启发，我们检测了在算法任务上NTM库。在每个实验中，我们的目标都是仅通过观察一系列输入和输出样例来学习算法。更具体地说，我们仅仅为神经网络图灵机提供随机输入，以及从我们想要学习的算法中所要得到的预期输出。就算法任务的本质而言，并没有提供给NTM预先的知识。从某种意义上说，由于训练数据可以通过已知算法无限生成，所以学习任务的数据可以很便利(convenient)的获得，理论上无限准确的训练数据要比实际应用场景中有噪音且有限的训练数据具有更大优势。训练NTM过程的例子。给模型随机输入序列，每一步都更新其参数。输入图像代表了模型在这个训练阶段的输出，以及与期望输出相对应的差值。模型读取输入和写出输出时存储器的状态相应地展示在右侧。该灵感来源于A. Graves在NIPS的动画。我们在这里主要关注NTM理解算法概念的能力，意味着NTM应该能够归纳各种长度的序列，包括超出训练中所看到的更长的序列。这就是我们所谓的泛化（拟合）性能（generalization performance）。下面所有实验的代码可以使用该数据库，以及预训练模型，因此你可以自己进行测试。所有的超参数（hyper-parameters）与架构细节也都可以获得，并且我们将会在这里简单介绍。如果你不希望读这些技术上的细节，你可以跳过下面的环节。在所有这些样例中，我们利用一个有100单元前馈控制器的单层神经网络图灵机。如最初的论文中所写的那样，1对读写磁头控制着存储器的128个位置。我们发现一个非常有用的关键事情是校正激活（线性校正单元ReLU）。后者展示了比典型的双曲正切激活（typical tanh activation）具有更好的泛化（拟合）性能，并且帮助获得序列的分散表示。复制Copy任务是一个最基本的算法任务，我们用它测试了NTM从储存和从存储器获取信息的能力。目标是将输入序列再生为输出。当然，这个任务仅仅测试了处理机制提供的小部分操作。指出这一点很重要：我们并不是在试着学会变成自动编程员，旨在立刻重新构建整个输出。反之，NTM一次只读取输入序列中的一项，一次也只写出一项输出。将它看做在读一本书（逐字地），然后必须从记忆当中复述出来。这就有挑战性得多。更加有挑战性的是我们并不仅仅对NTM复制与受训所用相似序列的能力，而是有效的学习复制算法并泛化更长的序列。为了与读书的比喻相对应，让我们把它比喻成我们去试着复述一本口袋小书，但是最终口袋小书，但是最终变成了复述一整本《奥德赛》。在这个例子中，我们用小于等于5个随机序列训练神经网络图灵机，而它却展示了对于多达120项测试序列完美的泛化能力。实际上，这并不令人惊讶，因为NTM真正触碰到了记忆的基线，因此无法再泛化更长的序列。重复性复制为了测试更复杂的算法，检查NTM是否能够学习简单算法原函数是一件有趣的事，就像循环一样。在重复性复制任务中，NTM收到了一个输入序列，以及所需复本的表征。目标是在输入特定次数的序列时重现所需数据。与谷歌DeepMind相反，我们利用了复制次数的一元表示（例如重复二进制标志）而不是单纯的[0,1]，这样的表示虽然适合于训练，但是却非常依赖于标准化，并没有为泛化带来帮助。实际上，他们的论文里也给出了相似的效果。注意到NTM读取原始输入序列而并没有得到任何关于数据和复制次数位置的暗示。模型在训练时需要自己找出相关的信息。相关联想相关联想任务是一个更加前沿的例子，学习基本的请求/回答系统。利用内容处理的优势，这个任务可以让我们测试NTM是否能够学习与C语言相似的指针。在这个简单的例子中，NTM被赋予由多个二进制向量组成的项，以分隔符以及在输入序列尾部的请求项分开。而目标是为了获取紧随输入序列请求项的答案。再一次，NTM无法获得数据性质的暗示。特殊的是，它必须去理解这些项由特殊的二进制标志分开，并从实际数据与请求分隔符区分出来。Dyck语句除了上面所提到的所有回归的例子，我们还对测试神经网络图灵机在分类任务中的能力很感兴趣。从正式语言中得到启发，我们可以仅通过几个例子测试某些语言的识别能力。在复杂性上最好的折衷方法是去测试NTM在由括号字符串组成的语言（也叫做Dyck语句）表现如何。Dyck语句已经被大范围研究过，并且与组合学的很多目标非常相关。在递归神经网络的环境中，它们非常有趣：典型完整的括号字符串涉及到长期依赖性，也被称为RNN的阿基琉斯之踵。一个非常简单的算法可以用来检查是否一个括号组成的语句是Dyck语句，这个算法包括了一个栈，并像下述描述。经验证明NTM实际上能够编写这样一个程序的代码。然而，与之前的例子相反，NTM利用读写头并不是完全在内存中存储信息，而是作为跟踪栈状态的方式。这展示了NTM并不仅仅能够利用内存作为线性存储，还能够执行具有长期依赖性的复杂计算，无论它的内容如何。结论正如我们在文中解释的，与LSTM泛化能力相比，神经网络图灵机展示了其不可测量的前景。其在外部存储中存储信息和本地修改的方式让它成为了处理需要推理的问题很好的解决方法。我们希望随着这篇文章一起公开的库能够帮助深度学习社区在探索这个有趣领域上有更多的进步。到现在为止，这是自谷歌DeepMind最初的论文发表以来，首个这种质量级别的能够重现复制、重复性复制和相关联想任务的开源库。在深度学习的推广上已经有了很多的进步，尤其是卷积神经网络。NTM打开了更进一步的新可能性，去理解概念是如何创造的。毕竟，算法就是计算机的概念。这是一个人工智能新的时刻：试着去教计算机他们能做的事情，就像我们学习它们一样。让我们拭目以待吧！"
日报;;【日报】FB测试无人机、谷歌迷幻绘图机器人、脑机接口新突破2016世界移动通信大会（MWC2016） 精彩集锦、脑机接口又获新突破、IBM Watson能从你写的文字中识别出情绪、日本将出动无人机处理部队……机器之心日报，精选一天前沿科技优质内容。2016世界移动通信大会（MWC2016） 精彩集锦： Facebook将于今年测试其互联网无人机MWC 2016上，Facebook CEO 扎克伯格谈到了他们的互联网无人机计划，Facebook计划在今年晚些时候来测试其互联网无人机 Aquila。Aquila 由太阳能驱动，Aquila拥有非常宽的机翼，能够在 6000-9000 英尺的高空维持 3-6 个月的飞行，将在高空提供用户可以搜寻得到的 WiFi 和 4G 信号。如果这个项目如计划中的进展实施，Facebook 将会与运营商进行合作，Facebook 希望能尽快通过这个计划来加快互联网基础建设的脚步，以此让更多的人来利用互联网！联想谷歌巴塞罗那艺术博物馆演示Project Tango应用Project Tango是一套集成了计算机视觉、图像处理和视觉传感器的复杂系统，它所具备的能力被认为可以彻底开创增强现实和虚拟现实的新时代。在MWC 2016期间，联想和谷歌低调地在西班牙巴塞罗那加泰罗尼亚国家艺术博物馆(Museu Nacional d&#39;Art de Catalunya）举办了一场媒体活动，展示和透露更多Project Tango技术和设备的细节。展示中，在庞大的宫殿式艺术博物馆中，通过Project Tango能够快速地在室内进行导航，而且通过定制软件和Project Tango传感技术的帮助，你能够迅速在设备中看到你的好友此时正在哪个地方参观，快速地切换下个目的地的途点信息，而且还能够结合视觉传感器，在屏幕中直接显示实景AR增强现实信息。谷歌展示迷幻绘图机器人在此次大会上，谷歌创意实验室团队展示了是一个迷幻绘图机器人，它根据Android智能手机拍摄的照片，绘制出抽象线条照片。整套系统是Android智能手机连接到代号IOIO的绘图系统，来控制由电机驱动的画笔，其绘图结果是由算法生成的，准确地绘制出类似手机照片的抽象图案，创建一张图片大约需要五分钟。该款机器人并不是一个商业项目，只是谷歌工程师的好玩之作，但它展示了一部Android智能手机可以完成的任务。富士通为奶牛创造可穿戴设备富士通的这款产品名字叫做「牛类发情期探测系统」（Estrus Detection System for Cattle，EDSC）。这套系统将穿戴于奶牛的膝盖处，它会像计步器一样记录下奶牛每天行走的步数。当奶牛处在发情期时，它们每天行走的步数最多将达到正常情况下的6倍。这就意味着通过这套可穿戴设备计数就可以让奶农明白何时应当为某只奶牛配种。据介绍，这款奶牛的可穿戴设备可以帮助探测「发情期的进程」，避免「浪费一半的配种机会」，还可以帮助奶农在合适的时间培育下一代奶牛。同时，这套系统还可以防止奶牛因发情而对牧场设施造成破坏，可以帮助奶农检测到早期的奶牛疾病。&nbsp;植入电极实现假肢精细运动功能，脑机接口控制假肢技术又获新突破近日，约翰·霍普金斯大学在癫痫患者脑部植入了一个可以控制假肢的电极阵列，通过映射控制每个手指动作的脑区，第一次实现了通过脑部来控制假肢的单个手指，实现假肢的精细运动功能。该研究已发表在Journal of Neural Engineering上。他们首先通过脑外科手术，将128电极传感器阵列（大概信用卡大小）植入患者大脑控制手和手臂动作的部分，每个传感器监测脑部直径1毫米的圆形面积。然后要求患者移动自己的手指，来观察手指运动过程中，大脑哪些部位被「点亮」。此外，他们还将小型振动蜂鸣器放置在患者指尖，以测量触觉引发的脑部电信号。基于动作信号和触觉信号的数据，对机械假肢进行编程，并将电极连接到患者脑部，要求患者用“思考”的方式来移动机械假肢的手指。开始，控制的精确程度达到76%，当无名指和小指连接在一起时，精确度明显提升，达到88%。研究人员解释说，控制的小指和无名指大脑的一部分重叠，所以大多数人这两个手指是一起动的。此外，研究人员还表示，截肢患者无需提前培训就能熟悉这个设备。人工智能将参与美空军决策美国空军研究实验室正在大力发展人工智能技术，其中一项重点项目是人工智能决策系统，它能融合各方面的情报、监视和侦察信息，随后快速分类相关数据。如今通常是由情报人员注视长达数小时的全动态图像，煞费苦心地挑出可能存在重要价值的片段，再将危险信息上报至指挥中心。同时美空军还在研究人工智能控制的无人驾驶车辆、无人机如何与有人驾驶战机相互配合。美空军研究实验室已研究出将载人与无人飞机组合搭档的方法。据报道，美空军计划在2022年举行一次演练，让自主无人战机与有人驾驶飞机协同飞行演练，它将展示如何自行导航、适应出人意料的天气以及在没有操作人员指示情况下根据需求规划飞行路径。IBM Watson超级电脑能从你写的文字中识别出情绪近日，IBM对于华生的软件系统进行了升级，安装了最先进的「语气分析工具（Tone Analyzer）」，这一工具可以通过人类书写的文字，分析出情绪信息甚至能识别出用户的性格特性，另外，通过语音转换软件，还能够做出拥有针对性语调的答复。IBM这一成果表明，未来的人工智能将不会是一种冷漠的技术，它能够识别人类的各种情绪，从而做出更加类似于人类的回应和反馈。性爱机器人离我们越来越近了吗？目前，最接近完全人形的机器人是位于美国加州的厄比斯创意公司(Abyss Creations)推出的一款性爱玩偶。该公司制造并销售一款名为「Real Doll」的玩偶，能逼真地模拟人类角色，具有各种各样精细的人体特征(比如皮肤上的雀斑)和「个性」供你定制。「Real Doll」这种玩偶非常昂贵，每一个的售价在5000美元到10000美元之间，具体价格取决于你预定的定制特征。但是，玩偶就只是玩偶，它们不是具有吸引力的性伴侣，也不是性爱机器人。至少现在还不是。性爱机器人——不是玩偶也不是设备——的前景要比我们想象的复杂得多。瑞士科学家研发人工智能搜救无人机 可助寻找野外失踪者瑞士科学家正在研发一种可以追踪丛林中行走痕迹的无人机，这种无人机将如同经验丰富的搜寻者一样，协助搜救在丛林里远行时迷路的人。该无人机项目目前仍处于初始阶段，但或许未来该无人机将可以协助搜救工作，寻找迷路的人或登山运动员。美国《企业家》杂志官网称，这种具有人工智能的无人机与其他机型不同，它可以在树木之下飞行，并追踪行走踪迹，还可以辨别出覆盖着灌木丛的小路，而且速度比人类更快，效率比人类更高。IBM日本联合Bandai Namco和Aniplex共同再现刀剑神域VRMMO虚拟现实游戏日本动漫《刀剑神域（Sword Art Online）》中设定在2022年在VR设备广泛使用的世界中，不少人接触了一款Sword Art Online的VRMMO游戏，开发者茅场晶彦创造了一个奇幻逼真的沉浸式游戏世界，主角们在游戏中产生了羁绊，爱情等真实的感情。而现在，IBM日本宣 布联合Bandai Namco和Aniplex共同再现这款VRMMO虚拟现实大型多人在线游戏的现实版本，宣布名为Sword Art Online: The Beginning的计划，采用IBM的云端服务Softlayer和深度分析技术再现庞大逼真的游戏环境。日本将出动无人机处理部队 用网兜捕获可疑飞机日本警视厅将在本月28日举行的东京马拉松中首次动用「无人驾驶航空器处理部队(IDT)」。日媒称，该部队将采用大型无人机来捕获可疑的小型无人机。据悉，将在举行马拉松比赛的重点路段部署数台无人机待命。该部队由接受过无人机操纵训练的机动队员组成，能采用大型无人机机身上拖挂的2米长、3米宽的网兜捕获可疑小型无人机。另外，日本警视厅将在本次比赛中试验性引入「善玉无人机」，以从空中监视赛道和沿线是否有可疑人物，并通过「自动翻译喇叭」用英语等4国语言进行广播疏导，还将导入防止踩踏事件发生的拥堵分析系统等。通过验证实际效果，讨论今后是否正式投入使用。研利用果园腐烂苹果制成的高性能环保钠离子电池近日，德国卡尔斯鲁厄理工学院(Karlsruhe Institute of Technology，KIT)的研究人员利用腐烂苹果打造出一种高性能的环保钠离子电池。 这种电池首先被用于栅极存储，在经过进一步研发后能被用于便携式电子产品和低端电动车。Stefano Passerini教授和Daniel Bucholz博士带领的研究小组成功通过烘干这些苹果并提炼其中95%的碳含量后创造了一种「硬碳」，并用其来打造一种高性能的电极材料。 这种新型碳材料电池阳极能达到230mAh/g比容量，在1000次充放电后都保持着相对稳定的水平，其库伦效率能保持在99.1%左右。此外，研究人员还开发了一种更高性能的电池阴极材料，在600次充放电后其库伦效率能保持在惊人的99.9%。机器之心编辑整理。
"人工智能;;专访DeepMind创始人Demis Hassabis引言：该篇文章是《卫报》对DeepMind创始人Demis Hassabis的深度专访，全面且深刻的还原了这位天才的性格、生活，以及对人工智能的热情和野心。他有着近乎传奇的早期经历，在国际象棋、游戏设计、计算机科学和神经科学等多个领域取得的成就形成了他从事人工智能伟大研究的完整拼图，他称自己为科学与创造力的结合体。Hassabis带领DeepMind进行开创性的人工智能研究，破解围棋这一历史难题，研究成果在极短的时间内两次登上《Nature》封面。而更加重要的是，DeepMind开创了一种科学研究与创业团队完美结合的机制。DeepMind在积极探索人工智能研究和应用的同时，在人工智能伦理研究方面也走在了全世界前列。Hassabis更是通过一次长谈说服了霍金，让他不再对人工智能大放厥词。Hassabis就像DeepMind的AlphaGo一样，像个超人一样保持高强度的工作和学习节奏，他把人工智能当成为之毕生奋斗的事业，也是他生活中的一部分。而Hassabis将和他的DeepMind继续朝着「创造解决世界上一切问题的通用人工智能」这一目标前进。寻找未来：Demis Hassabis 摄影：David EllisDemis Hassabis举止温和，面容谦逊，而当他告诉我他正在为「破解智能难题，然后用其来解决一切问题」的使命而奋斗时又格外认真。其他任何人说出这句话，听起来都十分可笑，但这句话从他的口中说出就另当别论了。39岁的Hassabis是一位前国际象棋大师、游戏设计员，他的人工智能研究创业公司DeepMind在2014年被谷歌以6.25亿美元收购。

他是移民后代，在伦敦芬奇利一所公立综合学院上学，分别取得了剑桥大学和伦敦大学学院（UCL）的计算机科学和认知神经科学学位。与他一起工作过的人们认为他是一个「有远见」的管理者。Hassabis认为他发现了一种「让科学研究更有效率」的方法，并提到他正在领导一个「21世纪的阿波罗项目」。他长相如此平凡，是那种你在街上不会看第二眼的人，但Tim Berners-Lee曾经向我这么形容他：他是这个星球上最聪明的人之一。每次我们打开Siri或者收到Android的推送时，都会感到人工智能已经在我们身边。从短期来说，谷歌的产品将毫无疑问的从Hassabis的研究中获利，尽管这些技术所带来的个性化、搜索、YouTube、语音和人脸识别等产品的提升都没有被定义为真正「人工智能」（Hassabis对此笑称到：「它只是软件，对吧？它只是一个能运行的东西。」）。但从长期来说，Hassabis正在开发的技术并不仅仅局限于情感机器人和更加智能的手机，也不仅仅围绕着谷歌。Facebook、微软、苹果和许多其他科技巨头们都在如饥似渴的招揽人工智能博士生，在这场最新的科技竞赛中砸入数十亿美元。人工智能关注所有的事情，包括我们能想象到的，以及那些我们想象不到的。它确实听起来太过野心勃勃。大部分人工智能系统应用范围都很「窄」，训练预设程序的机器去执行特定任务，除此之外再没什么了。因此，IBM的深蓝能在国际象棋比赛中击败Gary Kasparov，但却在井字游戏中输给三岁孩童。而Hassabis正在把他从人脑中得到的启发用于构建首个「通用学习机器」：一套能像生物系统一样学习的灵活、自适应的算法，仅使用原始数据就能从头开始掌握任何任务。它就是通用人工智能（artificial general intelligence ，简称AGI），它的重点落于「通用」上。在Hassabis眼中，未来超级智能机器将与人类专家合作解决一切问题。「癌症、气候变迁、能源、基因组学、宏观经济学、金融系统、物理学等，太多我们想掌握的系统知识正变得极其复杂。」Hassabis指出：「如此巨大的信息量让最聪明的人穷其一生也无法完全掌握。那么，我们如何才能从如此庞大的数据量中筛选出正确的见解呢？而一种通用人工智能思维的方式则是自动将非结构化信息转换为可使用知识的过程。我们所研究的东西可能是针对任何问题的元解决方法（meta-solution）。」虽然寻找「元解决方法」也许要花费数十年时间，但它看起来正在迫近。2015年2月，世界顶级科学期刊《自然》将像素游戏《Space Invaders》作为其封面，右下角是「自我教学软件在玩游戏上达到了人类般的表现」。在这一期，DeepMind的论文描述了首个成功的通用「端对端」学习系统，他们的人工代理——一个针对于图像处理单元的Deep-Q网络算法——能够学习如何处理屏幕的输入值并理解其含义，并采取能实现所需结果的决策（在这种情况下，系统成为众多雅达利2600经典游戏，如太空侵略者、拳击、打砖块中的超级玩家）。这是一项让整个科技界都为之震撼的突破。Hassabis谈AlphaGo的开发接着，在上个月，DeepMind又占领了《自然》封面——在短期内获得如此成就非常惊人。这一次，它变本加厉的挑战上世纪70和80年代的复古游戏。围棋在中国有着超过2500年的历史，曾经出现在孔夫子笔下。围棋的分支系数非常大：每一颗棋子可能的走法数量超过了整个宇宙的原子数量，而且不像国际象棋，它无法用蛮力计算来得出结果。更加困难的是，想要写出围棋的评估函数是一件不可能的事，例如能够体现出谁处于优势位置以及优势多少的一套规则。反而，它取决于棋手的一些类似于「直觉」的东西：当被问到为何这样落子的时候，大师们通常的回答是「感觉如此」。很显然，计算机在做出这方面的判断时会表现很糟，围棋也因此被认为是人工智能领域「悬而未决的重大挑战」之一，大部分研究者预期还需要十年机器才能有希望破解它。DeepMind的新算法有着严格的同行评审证据，AlphaGo在去年秋季秘密的一场对决中以5:0击败了曾三次获得欧洲冠军的樊麾，并将在今年三月与世界冠军李世石对决。「令人瞠目结舌的进步」，帝国理工学院认知机器人学教授Murray Shanahan如此形容。「一个了不起的里程碑」，超人类主义哲学家Nick Bostrom也表示同意，后者写出的《 Superintelligence: Paths, Dangers, Strategies 》指出：如果通用人工智能可以出现，这将是一个无法比肩的事件——借用下谷歌工程主管Ray Kurzweil的话：这将是一次撕裂历史的断层。Bostrom告诉我在他牛津人类未来研究所的办公室中，AlphaGo的成就被认为「将过去几年间机器学习所取得的进步生动的表现了出来」。「这非常酷。」Hassabis很平淡的说到，我们在他的办公室讨论着最新的胜利。像平常一样，他穿着没有任何特点的黑色上衣、裤子和鞋子：实在难以想象这实习生装扮的家伙拿到了谷歌的8000万英镑。「围棋是一个终极目标：它是一个游戏的巅峰，有着最丰富的智力深度。它如此迷人与美丽，令我们感到兴奋不仅在于我们掌握了这个游戏，还在于我们还用漂亮的算法完成了它。」围棋游戏更像是艺术而非科学，他认为：「AlphaGo以十分人类的方式下围棋，因为它是以人类的方式进行学习，通过不停地游戏变得更加聪明，就像你我一样。」Hassabis也许看起来像个学生，但他更像一个骄傲的家长，AlphaGo是他职业生涯中所达到的最令人激动的成就。「比任何人所想象的都高了一个数量级，」他有些激动，「但对于我们来说，最好的在于这不是一个使用人工规则的专家系统。它借助于通用机器学习技术教会了自己如何掌握游戏。最终，我们想将这些技术用于重要的真实世界的问题，例如气候模型或者复杂的疾病分析，对吧？想想它下一步能够解决的问题真的非常令人激动！」气候建模，复杂疾病分析——开始想象下一步可能解决什么让人非常兴奋。——Demis Hassabis我与Hasssabis的首次相遇是在2014年夏天，那是DeepMind被收购的几个月后。自那以后，我观察过他在各种不同坏境中工作，过去八个月中我也为这篇文章在三个不同场合正式采访过他。那段时间我看着他从一位谷歌的人工智能天才成长为了一位引人注目的传播者，他找到了一种高效的向类似于我这样的非科学家描述他非常复杂的工作的方法——对此他有极富感染力的热情——以及为什么这很重要。谦逊和日具风度，他非常擅长打破DeepMind的方法；也就是说他们结合新老人工智能技术的方式——比如说，在围棋中结合使用传统分析走子的「树搜索」方法与现代近似于大脑神经元网络的「深度神经网络」——而且他们还和人工智能研究的不同领域有条理清晰的「联姻」。在DeepQ中，他们将深度神经网络与所有动物都有的通过大脑多巴胺驱动奖励机制的「强化学习」结合了起来。而在AlphaGo中，他们更进一步又增加了另一种更深度水平的强化学习以处理长期计划。接下来，他们将整合例如记忆功能等等——直到理论上达成每一个智能的里程牌。Hassabis说：「我们在存在多少这些能力的路线图上有一个想法。将所有这些不同领域结合起来是其中关键，因为我们对那些可以在一个领域内学习又能将知识应用到新领域的算法很感兴趣。」这听起来有一点他的个性。乍一看他的简历，可以发现他颇为业余的好奇心包含了从棋盘游戏到视频游戏到计算机编程到认知神经科学等一切，更别提人工智能了。事实上，他今日成就的取得是聚焦的结果：将自己在同代人少见的强大智力与他一生专研过的学科等各方面有意识地合成在一起。（简单点出他人生的亮点：8岁写出自己的电脑游戏；13岁收获国际象棋大师地位；17岁创造了第一款包含人工智能的视频游戏《主题公园》；20岁以两科优等成绩获得剑桥大学计算机科学学位；不久之后就成立了开创性的视频游戏公司Elixir；之后他在海马体和情景记忆上的开创性学术研究成为了他的「最后一块拼图」；2011年成立DeepMind。）他承认：「我非常容易感到无聊，而世界又如此有趣，有太多炫酷的事情可做。」（他还保持着五次获得智力奥林匹克运动会（Mind Sports Olympiad）精英赛Pentamind冠军的世界纪录，在该比赛中，挑战者需要在多个项目中互相挑战。）「如果我是一个体育运动员，我就会一直想成为一个十项全能选手。」欧洲围棋冠军樊麾与AlphaGo系统对弈不过体育的荣耀再也没有希望了。Hassabis是一位忠实的利物浦球迷，喜欢观看各种体育赛事，四岁那年他开始下国际象棋，不到一年就开始了全国比赛，不久之后又开始角逐于国际赛场。现在可以很明显地推测出，他的一生都将与心智有关。

1976年，他出生于伦敦北部，他有一位希腊-塞浦路斯混血的父亲和一位新加坡-中国混血的母亲，他是三个兄弟姐妹中最大的一个。他的父母都是教师，曾经还拥有过一家玩具店。他的妹妹是一位作曲家和钢琴家；他的弟弟研究创意写作。他的家庭并没有太多的科技色彩。「显然我是家里另类的害群之马，」他开着玩笑，回忆起当他还是一个小男孩时将自己的下棋奖金花在了一台ZX Spectrum 48K计算机上，然后又买了Commodore Amiga，他立即拆开了它并搞清楚了怎么编程。「我父母有点技术恐惧。他们真的不喜欢计算机。他们是那种随性的人。我的妹妹和弟弟也都走了艺术路线。他们没人真正深入学习过数学或科学。」他耸耸肩表示抱歉，「所以，是的，这很怪异，我也不知道这一切都由何而来。」他的公司在被谷歌收购时有50多人，现在的员工人数快到接近200，他们来自45个国家，占据了一整栋位于国王十字路的六层建筑。尽管有让他将公司搬往别处（可以推测肯定包括硅谷的山景城）的压力，但Hassabis决心他的公司应该保持在离他的根很近的地方。

「我是在北伦敦出生长大，」他提醒我，「我当然爱这座城市。这就是我要坚持留在这里的原因：我觉得没有任何理由说伦敦不能拥有一个世界级的人工智能研究所。而我也对我们现处的位置感到自豪。」这栋建筑所有房间都是以知识巨人：特斯拉、拉马努金、柏拉图、费曼、亚里士多德、玛丽·雪莱（他是她的粉丝？「当然，」他再次向我确认，「我读过好几遍《弗兰肯斯坦》。把这些东西铭记心中很重要。」）。建筑的第一层是一间咖啡厅，装配着裸露的砖墙和装有客用椰子水的冰箱，还能见到在世界上大部分雄心勃勃的科技公司里都能看到的桌上足球机和沙包。楼上则对原来的建筑进行过装修，是一个现代的开放式结构，楼上办公室带有一个阳台，在上面能够欣赏到伦敦屋顶的壮丽景色。DeepMinder会在星期五晚上聚会畅饮。一位员工热情洋溢地将这个活动描述为「用HIGH来结束一周」的方式。社交是生活中不可或缺的一部分：我被告知DeepMind有俱乐部、足球队、棋类游戏俱乐部。（「这一个相当有竞争力。」）一张可更换照片的挂图表明这里每一个人每一天都是办公桌轮用的。这是极其开放式的。我经过走道时看到这里的工程师——男性居多——打破了人们认为的这一类人在角落里书呆子式工作的刻板印象：这些家伙看起来健康、快乐又很酷。不得不说这里有一种智力的魅力在空气中回荡。这不奇怪。这个星球上最聪明的人正排着队想来这里工作；而到目前为止，这里的员工留存率是惊人的100%，尽管谷歌的最大竞争对手们对人工智能的关注正在加速，更不要说同样求贤如渴的世界各地的一流大学了。「我们实在是很幸运，」Hassabis说，他将他的公司比作阿波罗计划与曼哈顿计划，因为该公司的雄心壮志以及其所招募的人员的水平都在以前所未有的速度攀升。「每年我们能从每个国家获得最好的科学家。例如，我们将拥有赢得波兰物理奥林匹克竞赛的人，获得今年法国年度最佳数学博士的人。我们得到的想法比我们获得的研究人员还多，但与此同时，还有更多优秀人才前来，我们已应接不暇。所以我们正处在一个非常幸运的位置。唯一的限制是在不破坏这种文化氛围的基础上我们能吸纳多少人。」这种公司文化要比豆沙袋（用来踢的那种）、免费午餐、天台上的啤酒等表面上的公司活动要更加深入。Hassabis坚信，谷歌的收购完全没有让其偏离自己的研究路径，他说他花在DeepMind公司运作效率方面的时间一点也不比花在算法上的时间少，他认为他的公司「完美结合了最好的学术和最令人激动的创业，因此，公司充满着惊人的能量，催生了无数创造力与进步。」他屡次提到「创造力」，虽然他接受都是正规的科学训练，但他是「天生就富有创造力和敏锐直觉」的天才。他斩钉截铁地说：「从某种意义上来说，我不是一个标准的科学家。」DeepMind组织架构中至关重要的是被他称之为「粘合思维（glue minds）」的东西：充分掌握各个科学领域知识的学者们能「以别出心裁的方式快速找出有前途的跨学科交叉点。」应用正确的基准，这些粘合者能以小组的形式每几周就碰一次面，快速、灵活的将各种资源和工程师匹配到需要的地方。「因此，你将拥有一个令人难以置信的天才研究者，而且3-4名其他领域的研究者可以直接接过同一任务，基于自己的专业进行补充，这与学术界十分不同，」他描述道，「这样所带来的结果就是能很快地产生一些惊人的结果。」仅仅启动了18个月的AlphaGo项目就是这一理念的完美例证。每天晚上，Hassabis都会乘坐北线巴士准时回家，与家人共进晚餐。他们居住在伦敦北部的海格特，距离他长大的地方不远。他的妻子是一名意大利分子生物学家，研究阿尔茨海默症。他们有两个儿子，一个7岁，一个9岁。Hassabis会和他们一起看书玩游戏，或者辅导他们的家庭作业。（「他们都很优秀，但他们在科学和创新方面更像是我的对立面。」）像每个父亲一样，他会哄他们睡觉。然后在11点左右，大多数人都上床睡觉时，Hassabis会开始他称之为的「第二天」。每天和美国团队的电话会一般会持续到凌晨1点，之后就进入他一直持续到凌晨3、4点的「纯粹思考时间」：他会考虑公司的研究工作和接下来的挑战，或者写一份算法设计文档。他承认，实际上没有太多人工智能编程工作。「因为我现在的数学太生疏了。更多的是直觉式的思考。或者是关于公司战略的思考：如何将其规模化，如何管理，等等。或者是想一些当天在文章和新闻中看到的东西，思考我们的研究如何和那些东西结合起来。」这让我想到了AlphaGo,，它就在令人很难想象的拥有庞大计算能力的谷歌云端不停的练习、练习、再练习，每一秒、每一天都在进步，因为它学习的唯一方法就是永不停歇。「它会休息吗？」我问到。「不，它不会休息。即便在圣诞节期间也没有。」我有些犹豫：「它真的永远不需要休息吗？」「可能它就喜欢这样（永不停歇）」，他回复道，眼睛闪闪发亮。他说的没错。但Hassabis自己呢？「他绝对是个超人，」他的一名同事评价道。他休息吗？「很难，我从来没有将工作与生活对立起来，它们本来就是一体的。我喜欢阅读，看电影，听音乐，但这些东西都和我所做的工作有关。」（比如说，他是一个超级影迷，他提到了他的朋友Alex Garland，近期人工智能电影《机械姬》的导演；也提到他刚刚与美国电影制片人Brian Grazer一起开会，他认为Grazer是一个很酷的人，他们讨论的话题是什么？估计你已经猜到了——是人工智能。）「我的大脑已经完全被人工智能占据了。」那他的其他方面呢？孩子、朋友和正常生活？「毫无疑问，我会尽力去平衡生活，不然确实有些疯狂。」关于孩子们，最酷的地方是他们几乎成为能以相同方式占用你时间的唯一事情。他和朋友们保持密切联系：他和DeepMind的另一位联合创始人Shane Legg相识于伦敦大学学院，他们都是PhD，对彼此比较了解，Mustafa Suleyman是他的发小。他还讲了一个在剑桥和同事Dave Silver相识的过程，在业余时间他会教Silver玩棋类游戏——包括特别古老的中国棋类。我注意到，David Silver是DeepMind AlphaGo团队的主要程序员，也是最近Nature论文的第一作者。「是的，Dave和我认识很久了，我们曾梦想在我们的有生之年做这件事（用人工智能解决围棋），所以（既然我们现在已经在做），当年19岁的我们应该很欣慰，我们已经走到了这一步。」他主动补充到：「事实确实如此，我没有太多的正常生活。每一个醒着的时刻，我都在思考问题，或许在梦中也是如此。因为这太令人兴奋了，它如此重要，这就是我最令我充满热情的事情。」从他眼里我看到了像孩子般天真无邪的对梦想的执着。「我感觉自己很幸运，我无法想象还有什么问题能比我研究的更加有趣，因此我会每天都在思考它们。每个时刻我都在做自己真正信仰的事情。不然我为什么要做这些呢？人生如此短暂。」如果对人工智能的忧虑真的像史蒂夫·霍金、比尔·盖茨、埃隆·马斯克、Jaan Tallinn 和 Nick Bostrom 等伟大的科学人物所说的那样，那生命会变得更加短暂。从无节制的AGI武器到对技术奇点恐惧的担忧都会导致一场「智能爆炸（intelligence explosion）」，即机器将有能力进行无限循环的自我进化，它们将能超过人类大脑的智力，也超出我们的控制力。当超级智能灾难开始显现，历史就不再是一个可靠指标，我们将无法预见到应该何时从人工智能军备竞赛中全身而退，直到这一切开始发生。罗伯特·奥本海默（原子弹之父）有句名言：「当你在某项技术上尝到甜头时，你会继续前行，只有当你获得技术上的成功后才会去考虑应该如何对待它。」几十年之后，Bostrom也提到：「如果有一种方法可以保证高级人工智能永远不会伤害人类，那这种智能就已经被创造出来了。如果没有任何办法去做出这种保证，那它们也有可能被创造出来。」霍金近期总结到：「在创造人工智能方面取得的成功将会是人类历史上最重要的事情。不幸的是，这也可能是最后一件。」「这么说吧，我希望不会。」Hassabis不动声色的说到。在他看来，公众对于通用人工智能的危言耸听阻碍了极具潜力的近期收益，并且本质上就错了，至少时间尺度上有问题。「我们距离那种能够达到人类级别的通用智能还得好几十年，」他提醒我，「我们才爬到梯子的第一级，只是在玩游戏。」他认可有一些「合理风险需要我们现在去思考」，但显然这些并不是科幻小说里的那些反乌托邦式的场景，在那些小说里，超级智能机器总是会无情的除掉它们的人类造物主。另外，他坚信，当涉及减少通用人工智能的潜在危险时，DeepMind同样走在了前列。虽然不像那种类似政府领导的阿波罗或曼哈顿之类的项目需要接受官方审查，但这家公司的操作相当透明。它更倾向于发布它的代码，而和谷歌的此次交易的协议中还附带一个条款：禁止将该技术应用于军事或情报用途。Hassabis和他的同事们在推动2015波多黎各人工智能大会召开方面发挥了重要作用，并在呼吁将此项技术应用于「善举」并在「避免潜在危害」的公开信上公开签字。他们最近联合组织了另一场在纽约的同类会议，而他们公司内部的道德董事会和咨询委员会目前也召集完毕（尽管是秘密进行的）。Murray Shanahan表示：「Hassabis完全了解人工智能的安全系数，他当然不是天真无知，更不是把头埋进沙子里的鸵鸟。」「DeepMind在鼓励讨论这些事情方面是行业的领先者，」Bostrom对此表示了赞同，「在参与一些需要应对长期挑战的研究方面亦是如此。」我让Hassabis列出他认为的最主要的长期挑战有哪些。「由于这些系统变得越来越复杂，我们需要思考如何充分利用它们，以及它们又能将什么东西进行优化，如何进行优化，」他回复道：「技术本身是中立的，但它是一个学习系统，所以不可避免的，它们会承担一些价值体系的印记和设计者的文化，所以我们需要非常小心翼翼地思考这些价值观。」关于超级智能的问题，他说到：「我们需要确保目标精确详细，并且没有什么模糊的地方，不会随着时间的流逝而发生变化。但在所有的系统中，最顶层目标仍然由它的设计者确定。这可能需要系统自己想办法达成目标，但它不能自行创造目标。」他的语气让人放心。「看吧，这些是有趣又有难度的挑战。因为这些全新的强大技术需要符合伦理和有责任感地使用，而这就是我们积极呼吁讨论和研究这一事宜的原因，所以当那个时间窗口到来时，我们能够已经做好了准备。」这到底是个怎样的时刻？当机器变成超级智能？还是机器超越了人类？他笑了，「不不不，我是说，在那之前。」（我知道他在开玩笑，尽管他的同事Shane Legg曾经在2011年明确表示：「我认为人类灭绝可能会发生，而技术可能会是罪魁祸首之一。」）Hassabis声明：「我的意思是，当这些系统更加强大，而不仅仅是玩游戏，我们会将它们应用在更加具体、实际和重要的事情上，比如说医疗健康领域。然后，我们需要确保我们知道它们的能力能够发展到什么地步。」他冲我咧嘴一笑，「这将阻止机器掌管世界这一场景的发生。」Hassabis很爱笑。他非常友好，又极具说服力。他说的每件事都似乎都很有道理，而且并不自负，但谁知道呢：也许通用人工智能会在我们的掌控之下。但很多人持怀疑态度。「显然，如果出现了一种在各方面都超过人类的数字智能，那『助理』这个词就不再是个正确的描述了。」埃隆·马斯克争辩道，他最近将人工智能技术方面的进步描绘成人类在「召唤恶魔」。这位SpaceX创始人、特斯拉和PayPal联合创始人也是DeepMind的早期投资者之一，但并非为了赚钱。「我不在乎为了投资而投资，」他告诉我，「我把钱投给DeepMind的唯一原因就是想要更加了解人工智能的进展和危害。如果我们不认真对待人工智能，一旦发生了什么不好的事情，银行存款也会变得毫无意义。」「埃隆是最聪明的人之一，和他交谈很令人享受，」Hassabis不偏不倚的回应说，「我真的认为像他这样的人喜欢人工智能是件非常酷的事，因为这足以说明这是件大事。」他表现的成熟老练，但其他领域的科学家对人工智能公开的随意评论显然激怒了他：毕竟你从来不会听到他对粒子物理大放厥词。「通常，我发现那些没有真正研究人工智能的人们并不完全理解这些。他们通常没有跟很多人工智能专家深入交谈，他们的思想实验就随着他们的想法跑偏了，因为他们都是基于那些我认为并不正确的设想。」他再一次提到，他成立的内部伦理委员会和咨询董事会——由不同科学和哲学学科方面的领袖组成——将会管控通用人工智能技术的未来使用。他坚决维护他现阶段保持继续探索的决定。「之前从未有人走到过这一步，所以在接受大众监督之前，我们必须筛选做一些探索性工作。」他表示，这一初始阶段是关于「让所有人都跟上进度，然后在下一阶段我们就能够讨论真正的算法和应用了。对很多涉及其中的人来说，这并不是他们的核心区域。我们需要他们的专业知识，但他们需要更好的了解究竟发生了什么。」斯蒂芬·霍金被当作一个「跟上进度」的鼓舞人心的例子被提及，他们最近在剑桥进行了私人谈话。「显然能够跟他见面就已经是非常不可思议的荣誉了，」他表示，并拿出他的手机给我看他的自拍。「我们只安排了一个小时，但他有那么多问题以致于我们最后交流了四个小时。这导致他错过了午餐，所以他的看护对我不太高兴。」Hassabis指出，在那次会面之后，霍金就不在媒体面前提及「任何人工智能煽动性言论」了。最惊奇的是，在他上月的BBC Reith讲座中，他推断的人类威胁清单中并没有包括人工智能。「可能真的会有些用吧，听到更多实用的东西，更多我们可能创造出的真正系统，以及我们对这些系统的检查和控制，」Hassabis表示。「一旦你理解了这项工程，这一切看起来就更容易理解了，也更加合理。」当然，在我身上还看不到任何希望，但他真的相信霍金变了吗？「我认为最终会的，他会非常放心的。他有着非常风趣的干幽默，就在我离开前，我问他，『那么你认为如何？』他打出了『我祝你好运。』之后，调皮地冲我眨眨眼，又补充道，『但不要太好运。』」Demise Hassabis向我露出会心一笑。「我认为，『我可以认为我赢了。』」"
